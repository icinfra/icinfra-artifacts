[ { "title": "Toggle Layers Visibility", "url": "/posts/toggle-layers-visibility/", "categories": "icenv", "tags": "skill", "date": "2025-06-03 16:00:00 +0000", "snippet": "按指定的数字编号，对它对应的层进行toggle; =============================================================================; SKILL 脚本：为 M0–M16 图层（及对应 pin、VIA）设置“切换可见/隐藏”快捷键; ============================================...", "content": "按指定的数字编号，对它对应的层进行toggle; =============================================================================; SKILL 脚本：为 M0–M16 图层（及对应 pin、VIA）设置“切换可见/隐藏”快捷键; =============================================================================;;; CCSpteToggleVisible: 对传入的图层列表执行“切换可见/隐藏”操作procedure(CCSpteToggleVisible(lppList \"l\") let(() foreach(lpp lppList pteSetVisible(lpp !pteIsVisible(lpp)) ); foreach ); let); procedure;; 以下为单行 hiSetBindKey 调用hiSetBindKey(\"Layout\" \"&lt;Key&gt;0\" \"CCSpteToggleVisible(list(\\\"M0 drawing\\\" \\\"M0 pin\\\" \\\"VIA0 drawing\\\"))\")hiSetBindKey(\"Layout\" \"&lt;Key&gt;1\" \"CCSpteToggleVisible(list(\\\"M1 drawing\\\" \\\"M1 pin\\\" \\\"VIA1 drawing\\\"))\")hiSetBindKey(\"Layout\" \"&lt;Key&gt;2\" \"CCSpteToggleVisible(list(\\\"M2 drawing\\\" \\\"M2 pin\\\" \\\"VIA2 drawing\\\"))\")hiSetBindKey(\"Layout\" \"&lt;Key&gt;3\" \"CCSpteToggleVisible(list(\\\"M3 drawing\\\" \\\"M3 pin\\\" \\\"VIA3 drawing\\\"))\")hiSetBindKey(\"Layout\" \"&lt;Key&gt;4\" \"CCSpteToggleVisible(list(\\\"M4 drawing\\\" \\\"M4 pin\\\" \\\"VIA4 drawing\\\"))\")hiSetBindKey(\"Layout\" \"&lt;Key&gt;5\" \"CCSpteToggleVisible(list(\\\"M5 drawing\\\" \\\"M5 pin\\\" \\\"VIA5 drawing\\\"))\")hiSetBindKey(\"Layout\" \"&lt;Key&gt;6\" \"CCSpteToggleVisible(list(\\\"M6 drawing\\\" \\\"M6 pin\\\" \\\"VIA6 drawing\\\"))\")hiSetBindKey(\"Layout\" \"&lt;Key&gt;7\" \"CCSpteToggleVisible(list(\\\"M7 drawing\\\" \\\"M7 pin\\\" \\\"VIA7 drawing\\\"))\")hiSetBindKey(\"Layout\" \"&lt;Key&gt;8\" \"CCSpteToggleVisible(list(\\\"M8 drawing\\\" \\\"M8 pin\\\" \\\"VIA8 drawing\\\"))\")hiSetBindKey(\"Layout\" \"&lt;Key&gt;9\" \"CCSpteToggleVisible(list(\\\"M9 drawing\\\" \\\"M9 pin\\\" \\\"VIA9 drawing\\\"))\")hiSetBindKey(\"Layout\" \"Shift&lt;Key&gt;0\" \"CCSpteToggleVisible(list(\\\"M10 drawing\\\" \\\"M10 pin\\\" \\\"VIA10 drawing\\\"))\")hiSetBindKey(\"Layout\" \"Shift&lt;Key&gt;1\" \"CCSpteToggleVisible(list(\\\"M11 drawing\\\" \\\"M11 pin\\\" \\\"VIA11 drawing\\\"))\")hiSetBindKey(\"Layout\" \"Shift&lt;Key&gt;2\" \"CCSpteToggleVisible(list(\\\"M12 drawing\\\" \\\"M12 pin\\\" \\\"VIA12 drawing\\\"))\")hiSetBindKey(\"Layout\" \"Shift&lt;Key&gt;3\" \"CCSpteToggleVisible(list(\\\"M13 drawing\\\" \\\"M13 pin\\\" \\\"VIA13 drawing\\\"))\")hiSetBindKey(\"Layout\" \"Shift&lt;Key&gt;4\" \"CCSpteToggleVisible(list(\\\"M14 drawing\\\" \\\"M14 pin\\\" \\\"VIA14 drawing\\\"))\")hiSetBindKey(\"Layout\" \"Shift&lt;Key&gt;5\" \"CCSpteToggleVisible(list(\\\"M15 drawing\\\" \\\"M15 pin\\\" \\\"VIA15 drawing\\\"))\")hiSetBindKey(\"Layout\" \"Shift&lt;Key&gt;6\" \"CCSpteToggleVisible(list(\\\"M16 drawing\\\" \\\"M16 pin\\\" \\\"VIA16 drawing\\\"))\");; 提示信息printf(\"图层切换快捷键（Toggle）已设置完成:\\n\")printf(\"数字键 0-9: Toggle M0-M9（三层：drawing、pin、VIA）\\n\")printf(\"Shift+0: Toggle M10（三层：drawing、pin、VIA）\\n\")printf(\"Shift+1–Shift+5: Toggle M11–M15（三层：drawing、pin、VIA）\\n\")printf(\"Shift+6: Toggle M16（三层：drawing、pin、VIA）\\n\")" }, { "title": "Privacy Policy for Cadence EDA Downloader", "url": "/posts/privacy-policy-for-cadence-eda-downloader/", "categories": "icenv", "tags": "eda", "date": "2025-05-28 16:00:00 +0000", "snippet": "English VersionIntroductionThis Privacy Policy describes how the Cadence EDA Downloader Chrome extension (“we”, “our”, or “the extension”) handles your information. We are committed to protecting y...", "content": "English VersionIntroductionThis Privacy Policy describes how the Cadence EDA Downloader Chrome extension (“we”, “our”, or “the extension”) handles your information. We are committed to protecting your privacy and being transparent about our practices.Information CollectionThe Cadence EDA Downloader extension does not collect, store, or transmit any personal information about users. All data processed by the extension is stored locally on your device and is not sent to any external servers or third parties.Use of PermissionsOur extension requests certain permissions, including: Storage: To store tool information and download progress locally on your device Tabs: To interact with the Cadence Downloads website in your browser Downloads: To manage downloads from the Cadence website Scripting: To extract tool information from the Cadence website Web Navigation: To ensure proper functionality on the Cadence Downloads websiteThese permissions are used solely to provide the core functionality of the extension and improve user experience. They are not used to collect any user data.Data StorageAll information is stored locally on your device using Chrome’s storage API. This information includes your preferences and tool metadata to improve your experience when using the extension.Third-Party SharingWe do not share any information with third parties because we do not collect any user data.Changes to This PolicyWe may update this Privacy Policy from time to time. We will notify users of any changes by updating the “Last Updated” date at the top of this policy.ContactIf you have any questions about this Privacy Policy, please contact us at wanlin.wang@foxmail.com .中文版本引言本隐私政策描述了 Cadence EDA Downloader Chrome 扩展程序（以下简称”我们”、”我们的”或”扩展程序”）如何处理您的信息。我们致力于保护您的隐私并对我们的做法保持透明。信息收集Cadence EDA Downloader 扩展程序不收集、存储或传输任何用户个人信息。扩展程序处理的所有数据都存储在您的本地设备上，不会发送到任何外部服务器或第三方。权限使用我们的扩展程序请求以下权限： 存储：在您的设备上本地存储工具信息和下载进度 标签页：与浏览器中的 Cadence 下载网站进行交互 下载：管理来自 Cadence 网站的下载 脚本注入：从 Cadence 网站提取工具信息 网页导航：确保在 Cadence 下载网站上正常运行这些权限仅用于提供扩展程序的核心功能并改善用户体验。它们不用于收集任何用户数据。数据存储所有信息都使用 Chrome 的存储 API 存储在您的本地设备上。这些信息包括您的偏好设置和工具元数据，用于改善您使用扩展程序时的体验。第三方共享我们不与第三方共享任何信息，因为我们不收集任何用户数据。政策变更我们可能会不时更新本隐私政策。我们将通过更新此政策顶部的”最后更新”日期来通知用户任何更改。联系方式如果您对本隐私政策有任何疑问，请通过 wanlin.wang@foxmail.com 联系我们。" }, { "title": "Cadence EDA Downloader User Guide ", "url": "/posts/cadence-eda-downloader-user-guide/", "categories": "icenv", "tags": "eda", "date": "2025-05-28 16:00:00 +0000", "snippet": "OverviewCadence EDA Downloader is a Chrome Extension designed to simplify the process of downloading tools from the Cadence Downloads website. It provides features such as filtering tools, batch do...", "content": "OverviewCadence EDA Downloader is a Chrome Extension designed to simplify the process of downloading tools from the Cadence Downloads website. It provides features such as filtering tools, batch downloads, and progress monitoring to enhance user experience.交流群效果图Features Automatic Tool Detection: Automatically detects tools available on the Cadence Downloads page. Filters: Filter tools by platform, status, or search keywords. Batch Downloads: Download multiple tools simultaneously with the “Download All” feature. Progress Monitoring: View active downloads, queued items, and completed downloads. Local Database: Stores tool information locally for quick access.InstallationDeveloper Mode Clone or download the repository. Open Chrome/Edge and navigate to chrome://extensions/ or edge://extensions/. Enable “Developer mode” in the top right corner. Click “Load unpacked” and select the directory containing this extension. The extension should now appear in your browser’s toolbar.UsageStep 1: Login to Cadence DownloadsLog in to Cadence Downloads using your credentials.Step 2: Open the ExtensionClick the Cadence EDA Downloader icon in your browser toolbar to open the extension interface.Step 3: Filter ToolsUse the filter options to narrow down the list of tools based on your requirements (e.g., platform, status).Step 4: Start DownloadsSelect individual tools or use the “Download All” button to start downloading. Monitor progress in the extension interface.Cadence EDA Downloader 用户指南概述Cadence EDA Downloader 是一个 Chrome 扩展，旨在简化从 Cadence 下载网站下载工具的过程。它提供了筛选工具、批量下载和进度监控等功能，以提升用户体验。功能 自动工具检测：自动检测 Cadence 下载页面上的可用工具。 筛选功能：按平台、状态或搜索关键字筛选工具。 批量下载：使用“全部下载”功能同时下载多个工具。 进度监控：查看正在下载的文件、排队项目和已完成的下载。 本地数据库：将工具信息存储在本地以便快速访问。安装开发者模式 克隆或下载此代码库。 打开 Chrome/Edge 并导航到 chrome://extensions/ 或 edge://extensions/。 在右上角启用“开发者模式”。 点击“加载未打包的扩展程序”，选择包含此扩展程序的目录。 此扩展程序现在应该出现在浏览器的工具栏中。使用方法第一步：登录 Cadence 下载网站使用您的凭据登录 Cadence 下载网站。第二步：打开扩展程序点击浏览器工具栏中的 Cadence EDA Downloader 图标以打开扩展界面。第三步：筛选工具使用筛选选项根据您的需求缩小工具列表（例如，按平台或状态）。第四步：开始下载选择单个工具或使用“全部下载”按钮开始下载。在扩展界面中监控下载进度。" }, { "title": "Cadence Support Downloader: Privacy Policy", "url": "/posts/cadence-support-downloader-privacy-policy/", "categories": "ic", "tags": "tools", "date": "2025-05-23 16:00:00 +0000", "snippet": "IntroductionThis privacy policy outlines how the Cadence Support Downloader Chrome extension collects, uses, and protects your data. Our extension is designed with privacy in mind, keeping all your...", "content": "IntroductionThis privacy policy outlines how the Cadence Support Downloader Chrome extension collects, uses, and protects your data. Our extension is designed with privacy in mind, keeping all your data local to your device.Data Collection and StorageCadence Support Downloader collects and stores the following information locally on your device: Download History: Records of articles you’ve downloaded, including titles, dates, and file information Web Activity: Limited information about pages visited on the Cadence Support portal to track which articles have been processed User Activity: Download status and interactions with the extension interfaceLocal Storage OnlyAll data collected by this extension is: Stored exclusively on your local device Never transmitted to external servers Never shared with third parties Accessible only to you through the extension’s interfaceData UsageWe use the locally stored data solely for the following purposes: Tracking which articles you’ve already downloaded to prevent duplication Providing you with a searchable history of your downloads Allowing you to manage your downloaded content Enhancing the functionality of the extensionData ControlYou have complete control over your data: Clear your entire download history at any time through the settings gear icon Delete individual articles from your history Your data is automatically deleted if you uninstall the extensionPermissionsThe extension requests the following permissions: activeTab: To interact with Cadence Support pages scripting: To extract article information and download content downloads: To download and organize files storage: To save your download history locally cookies: To maintain authentication with Cadence Support Host access (support.cadence.com): To download content from the Cadence Support portalThird-Party ServicesThis extension does not: Use any third-party analytics services Share data with external parties Include any tracking technologies Connect to any external APIs except the Cadence Support websiteUpdates to Privacy PolicyAny future updates to this privacy policy will be reflected in the extension’s documentation and noted in version updates.Contact InformationFor questions about this privacy policy or the extension: Email: wanlin.wang@foxmail.com Website: https://www.icinfra.cnLast Updated: May 24, 2025Cadence Support Downloader is not affiliated with Cadence Design Systems. All trademarks belong to their respective owners." }, { "title": "Keysight SOS List Changes Since a Given Point", "url": "/posts/keysight-sos-history-from-date/", "categories": "icenv", "tags": "sos", "date": "2025-05-22 16:00:00 +0000", "snippet": "需求SOS工具，需要审计从某个时刻开始所有的提交。方法在sos界面点击Project-&gt;Audit Trail，它可以以GUI/HTML/Text的方式显示。实测GUI和HTML可以，但Text方式没有弹出来，可能是需要配置好相应的文本编辑器。", "content": "需求SOS工具，需要审计从某个时刻开始所有的提交。方法在sos界面点击Project-&gt;Audit Trail，它可以以GUI/HTML/Text的方式显示。实测GUI和HTML可以，但Text方式没有弹出来，可能是需要配置好相应的文本编辑器。" }, { "title": "How to Export and Import Docker Images Between Hosts", "url": "/posts/export-import-docker-images-between-hosts/", "categories": "博客", "tags": "jekyll, github", "date": "2025-05-22 16:00:00 +0000", "snippet": "🐳 Docker 镜像迁移操作指南📌 场景说明将本地 Docker 镜像导出为文件，拷贝到另一台主机，然后加载使用。适用于无网络或跨环境部署场景。🔧 步骤一：保存本地镜像为 tar 文件# 语法：docker save -o &lt;保存路径&gt;.tar &lt;镜像名&gt;:&lt;标签&gt;docker save -o myimage.tar myapp:latest 💡 示例...", "content": "🐳 Docker 镜像迁移操作指南📌 场景说明将本地 Docker 镜像导出为文件，拷贝到另一台主机，然后加载使用。适用于无网络或跨环境部署场景。🔧 步骤一：保存本地镜像为 tar 文件# 语法：docker save -o &lt;保存路径&gt;.tar &lt;镜像名&gt;:&lt;标签&gt;docker save -o myimage.tar myapp:latest 💡 示例： docker save -o myapp.tar myapp:1.0.0 🚛 步骤二：将镜像文件复制到目标主机方法一：使用 scp（推荐）scp myapp.tar user@remote_host:/path/to/destination/方法二：使用 U 盘/移动硬盘 或其他方式传输🔄 步骤三：在目标主机加载镜像docker load -i /path/to/destination/myapp.tar 💡 镜像加载完成后，可通过 docker images 查看是否成功导入。✅ 可选：运行导入的镜像容器docker run -it --rm myapp:1.0.0📝 其他说明 若不确定镜像完整名，可以用 docker images 查看。 如果镜像较大，考虑使用 gzip 压缩再传输： docker save myapp:1.0.0 | gzip &gt; myapp.tar.gz 在目标主机上解压加载： gunzip -c myapp.tar.gz | docker load " }, { "title": "Cadence Support Downloader: User Guide and Documentation", "url": "/posts/cadence-support-downloader-user-guide/", "categories": "icenv", "tags": "eda", "date": "2025-05-22 16:00:00 +0000", "snippet": "Cadence Support Downloader 帮助指南地址https://chromewebstore.google.com/detail/cadence-support-downloade/hmdaleneajcddlklbaniiimlgdkdgenk交流群效果交流群概述Cadence Support Downloader 是一个 Chrome 扩展程序，用于简化从 Cadenc...", "content": "Cadence Support Downloader 帮助指南地址https://chromewebstore.google.com/detail/cadence-support-downloade/hmdaleneajcddlklbaniiimlgdkdgenk交流群效果交流群概述Cadence Support Downloader 是一个 Chrome 扩展程序，用于简化从 Cadence Support 搜索结果中下载 PDF 和附件的过程。它可以帮助您将下载内容组织到文件夹中，并跟踪您已经下载的内容。功能特点 自动从搜索结果页面提取文章 下载每篇文章的 PDF 文档和附件 将下载内容整理到以文章标题命名的文件夹中 跟踪下载历史，避免重复下载相同内容 通过直观的界面管理下载历史 在下载过程中查看详细的下载统计信息 支持多个并发下载，加快处理速度安装方法 从 Chrome 网上应用店安装： 在 Chrome 网上应用店中找到该扩展程序 点击”添加到 Chrome”并确认安装 扩展图标将出现在 Chrome 工具栏中 手动安装（开发者模式）： 下载扩展程序文件 打开 Chrome，访问 chrome://extensions/ 在右上角启用”开发者模式” 点击”加载已解压的扩展程序”并选择扩展程序文件夹 扩展程序将出现在 Chrome 工具栏中 使用方法基本用法 登录 Cadence Support 网站 搜索您需要的内容（例如”RAK”、”Virtuoso”等） 在搜索结果页面，点击浏览器工具栏中的 Cadence Support Downloader 图标 点击”Download”按钮开始下载过程 扩展程序将： 识别当前页面上的所有文章 过滤掉您已下载的文章 为新文章下载 PDF 和附件 将文件整理到以每篇文章名称命名的文件夹中 下载过程 扩展程序将在弹出窗口中显示进度 您将看到活动下载和下载队列中的项目 状态消息将出现在日志部分 完成后，您可以在浏览器的默认下载位置找到您的下载内容下载历史 点击”History”按钮查看您的下载历史 每个条目显示： 文章标题 下载日期 已下载文件列表 您可以使用搜索框搜索历史记录 对于每篇文章，您可以： 打开原始文章页面 重新下载单个文件 复制文件 URL 到剪贴板 在新标签页中打开文件 从历史记录中删除单个文章 管理下载 停止下载：点击”Stop”按钮取消活动下载 清除历史记录：在历史记录部分，点击”Clear Download History”删除所有历史记录 搜索历史记录：使用搜索框在历史记录中查找特定文章或文件故障排除内容脚本未就绪错误如果您看到”Content script not ready. Please refresh the page and try again”： 等待自动恢复过程完成 当您看到”Content script injected. Please try downloading again”时，再次点击”Download” 如果问题仍然存在，刷新页面并重试下载失败如果文件下载失败： 检查您是否仍然登录 Cadence Support 确保您有稳定的互联网连接 尝试从历史记录部分单独下载文件 查看扩展程序日志中的错误消息许可协议页面扩展程序会自动处理访问某些文章时可能出现的许可协议页面： 当检测到许可协议页面时，扩展程序将自动处理 这个过程不需要用户交互 下载将自动继续其他常见问题 未找到文章：确保您位于 Cadence Support 搜索结果页面 下载卡住：点击”Stop”并重试，或刷新页面 文件名称奇怪：文章标题中的一些特殊字符可能会被替换为安全替代字符 扩展程序无响应：重启 Chrome 或从 chrome://extensions/ 重新加载扩展程序有效使用技巧 处理多个页面：浏览搜索结果页面并在每个页面上使用扩展程序以下载更多内容 使用搜索功能：当您有大量下载历史时，使用搜索框查找特定文章 定期清理：如果下载历史变得太大，请定期清理 查看日志：日志部分提供了有关下载过程的有用信息 使用替代下载方法：对于有问题的文件，尝试从历史记录部分使用”Open in new tab”隐私和数据存储 所有下载历史记录都存储在您的浏览器本地 不会向外部服务器发送数据 清除浏览器数据或扩展程序数据将删除您的下载历史记录支持和反馈如果您遇到问题或有改进建议，请通过 wanlin.wang@foxmail.com 联系扩展程序开发者。Cadence Support Downloader 在 MIT 许可下发布。此扩展程序与 Cadence Design Systems 没有官方关联。Cadence Support Downloader Help GuideOverviewCadence Support Downloader is a Chrome extension that streamlines the process of downloading PDFs, and attachments from Cadence Support search results. It helps you organize your downloads into folders and keeps track of what you’ve already downloaded.Features Automatically extract articles from search result pages Download PDF documents and attachments for each article Organize downloads into folders named after article titles Track download history to avoid downloading the same content twice Manage download history through an intuitive interface View detailed download statistics during the download process Supports multiple concurrent downloads for faster processingInstallation Install from Chrome Web Store: Navigate to the extension in the Chrome Web Store Click “Add to Chrome” and confirm the installation The extension icon will appear in your Chrome toolbar Manual Installation (Developer Mode): Download the extension files Open Chrome and go to chrome://extensions/ Enable “Developer mode” in the top-right corner Click “Load unpacked” and select the extension folder The extension will appear in your Chrome toolbar How to UseBasic Usage Log in to the Cadence Support website Search for your desired content (e.g., “RAK”, “Virtuoso”, etc.) On the search results page, click the Cadence Support Downloader icon in your browser toolbar Click the “Download” button to start the download process The extension will: Identify all articles on the current page Filter out articles you’ve already downloaded Download PDFs and attachments for new articles Organize files into folders named after each article Download Process The extension will show progress in the popup window You’ll see active downloads and items in the download queue Status messages will appear in the log section Once complete, you can find your downloads in your browser’s default download locationDownload History Click the “History” button to view your download history Each entry shows: Article title Download date List of downloaded files You can search your history using the search box For each article, you can: Open the original article page Download individual files again Copy file URLs to clipboard Open files in a new tab Delete individual articles from history Managing Downloads Stop Downloads: Click the “Stop” button to cancel active downloads Clear History: In the history section, click “Clear Download History” to remove all history Search History: Use the search box to find specific articles or files in your historyTroubleshootingContent Script Not Ready ErrorIf you see “Content script not ready. Please refresh the page and try again”: Wait for the auto-recovery process to complete When you see “Content script injected. Please try downloading again”, click “Download” again If the issue persists, refresh the page and try againDownload FailuresIf files fail to download: Check if you’re still logged in to Cadence Support Ensure you have a stable internet connection Try downloading the file individually from the history section Look for error messages in the extension logLicense Agreement PagesThe extension automatically handles license agreement pages that may appear when accessing certain articles: When a license agreement page is detected, the extension will automatically process it This happens without requiring user interaction The download will continue automaticallyOther Common Issues No articles found: Make sure you’re on a Cadence Support search results page Downloads stuck: Click “Stop” and try again, or refresh the page Files with strange names: Some special characters in article titles may be replaced with safe alternatives Extension not responding: Restart Chrome or reload the extension from chrome://extensions/Tips for Effective Use Process multiple pages: Navigate through search result pages and use the extension on each to download more content Use the search function: When you have a large download history, use the search box to find specific articles Regular cleanup: Periodically clear your download history if it grows too large Check the log: The log section provides useful information about the download process Use alternative download methods: For problematic files, try using “Open in new tab” from the history sectionPrivacy and Data Storage All downloaded history is stored locally in your browser No data is sent to external servers Clearing your browser data or extension data will remove your download historySupport and FeedbackIf you encounter issues or have suggestions for improvement, please contact the extension developer at wanlin.wang@foxmail.com.Cadence Support Downloader is licensed under the MIT License. This extension is not officially affiliated with Cadence Design Systems." }, { "title": "Lumerical job scheduler integration (Slurm, Torque, LSF, SGE) ", "url": "/posts/Lumerical-job-scheduler-integration-Slurm-Torque-LSF-SGE/", "categories": "icenv", "tags": "job, lsf", "date": "2025-05-22 16:00:00 +0000", "snippet": "Lumerical 与作业调度系统集成 (支持 SGE, Slurm, Torque, LSF)概述本指南介绍了如何将 Lumerical CAD 的 Job Manager 与一些常见的作业调度系统（如 SGE、Slurm、Torque 和 IBM LSF）进行集成。 完成这些步骤后，在集群上运行仿真将与在本地计算机上运行一样无缝。 您只需点击“运行”，作业就会自动提交到作业调度系统的队列...", "content": "Lumerical 与作业调度系统集成 (支持 SGE, Slurm, Torque, LSF)概述本指南介绍了如何将 Lumerical CAD 的 Job Manager 与一些常见的作业调度系统（如 SGE、Slurm、Torque 和 IBM LSF）进行集成。 完成这些步骤后，在集群上运行仿真将与在本地计算机上运行一样无缝。 您只需点击“运行”，作业就会自动提交到作业调度系统的队列中（如果需要，文件会自动传输），Lumerical 作业管理器会定期更新仿真的当前状态和进度，完成后，结果会自动加载到您当前的 CAD 会话中。已知限制 作业管理器的“退出但不保存”和“退出并保存”选项目前不受支持。 这适用于单个仿真以及将作业调度器作为资源的参数扫描。 点击“强制退出”时，已提交的作业不会被取消，需要手动取消。 当使用通过 SSH 进行文件上传和下载功能时，传输状态不会反映在作业管理器的状态视图中。 作业管理器窗口在后台下载文件期间将保持打开状态，并在该过程完成后关闭。要求 Lumerical Products 2020a R3 (或更新版本) Ansys Lumerical 2023 R2.2 (或更新版本) 用于基于用户的配置 集群需安装以下任一作业调度系统：Slurm、Torque、LSF、SGE，并配置好 X11 显示以及已安装并配置好许可证服务器的 Lumerical 产品。 如果使用 AWS ParallelCluster，请参阅 AWS-ParallelCluster 文档了解详情。资源配置 添加/编辑资源： 在 Lumerical CAD 的“资源配置” (Resource Configuration) 界面中，添加或编辑一个新的资源。 如果队列已配置为处理可用许可证的数量，则将容量 (Capacity) 设置为 0 (无限)；否则，将其设置为许可证服务器上可用的最大求解引擎许可证数量。 高级资源设置： 编辑高级资源设置 (advanced resource settings)，从“作业启动预设” (Job Launching Presets) 中选择您的作业调度系统（例如 Slurm）。 注意事项： 预设会自动填充示例设置，可能不适用于您的特定集群。 请修改提交命令 (submission command) 以确保使用正确的节点数和每节点进程数，并更新提交脚本 (submission script) 以适应您集群和仿真需求的 Lumerical 计算环境。 使用 Slurm 提交作业时，请确保设置了请求计算集群资源的标志（例如 CPU、GPU 和内存），例如通过 --cpus-per-task、--gpus-per-node 和 --mem。 否则，仿真可能会失败或无法使用所有可用硬件。 有关请求资源的标志的更多信息，请参阅 Slurm 的 sbatch 文档。从本地计算机向作业调度系统提交作业如果您希望从本地计算机启动作业以获得更无缝的体验，可以按照与在集群上配置资源相同的步骤在本地计算机上配置 Lumerical，并通过设置 job_scheduler_input.json 文件来启用 SSH。 通过 JSON 文件进行配置的功能是在 Lumerical 2023 R2.2 版本中引入的。 对于之前的版本，您需要修改与您的作业调度系统相对应的 .py 文件。 job_scheduler_input.json 模板文件可以在 Lumerical 安装目录中找到： Windows (默认安装路径): C:\\Program Files\\Lumerical\\v251\\scripts\\job_schedulers Linux (默认安装路径): /opt/lumerical/v251/scripts/job_schedulers job_scheduler_input.json 文件内容模板：{ \"user_name\":\"\", \"use_ssh\":0, \"use_scp\":0, \"cluster_cwd\":\"\", \"master_node_ip\":\" &lt;master-node-ip&gt; \", \"ssh_key\":\"~/.ssh/ &lt;private-key&gt; .pem\", \"path_translation\": [\"\",\"\"]}重要步骤： 将 job_scheduler_input.json 文件复制到您用户的 “home” 文件夹下对应的 Lumerical 配置路径： Linux: ~/.config/Lumerical Windows: %APPDATA%\\Lumerical 然后编辑该文件，填入您的作业调度系统设置。job_scheduler_input.json 参数说明： 参数 描述 user_name 您在主节点上的用户名。如果留空，将使用 import getpass; getpass.getuser() 动态分配用户名。 use_ssh 如果设置为 1，则使用 ssh* 在主节点上运行提交命令。 use_scp 如果设置为 1，仿真文件将使用 scp* 复制到主节点。 cluster_cwd 当 use_scp=1 时，仿真文件将被复制到的共享文件夹路径，例如 \"\"\"/cluster_path/of_simulationfile/\"\"\"。 master_node_ip 用于远程连接和作业提交的主节点的 IP 地址或主机名。 ssh_key 用于无密码连接的私钥文件的位置。 path_translation 可用于在 Windows 共享文件系统与 Linux 集群之间转换路径。使用 Unix 风格的路径分隔符 /，例如 \"\"\"path_translation\"\": [\"\"local_path/of_simulationfile/\"\", \"\"/cluster_path/of_simulationfile/\"\"]。 要从本地计算机向 Linux 集群提交作业，请将 use_ssh 和 use_scp 设置为 1，并将 master_node_ip 设置为节点的 IP 地址。 此方法将使用 scp* 将您的仿真文件复制到远程服务器，使用 ssh* 启动作业，并在结束时将所有生成的文件复制回您的本地计算机。注意：在 Windows 上，您需要确保 SSH 和 SCP 已添加到系统的 PATH 环境变量中。 根据 Windows 的版本，您可以安装 Git Bash 或 OpenSSH for Windows。结果现在，您可以直接从 CAD 的作业管理器运行任何 Lumerical 仿真（单个、扫描、优化等）。作业调度系统提交脚本 (SGE, Slurm, Torque, LSF)作业调度系统脚本通常包含两个重要部分。 第一部分是设置作业运行的环境，第二部分是运行作业的命令。以下示例利用了 IntelMPI 和 OpenMPI 提供的 mpirun 脚本。 由于我们在执行前设置了环境，因此无需提供 mpirun 的完整路径。 这些脚本会自动读取作业调度系统设置的环境变量并执行相应的 mpiexec 命令。示例 1：AWS ParallelCluster 示例#!/bin/shmodule load intelmpimpirun /opt/lumerical/v251/bin/fdtd-engine-impi-lcl -logall -fullinfo fdtd_100mb.fsp示例 2：使用 MPI 环境脚本许多 MPI 发行版中都可以找到 mpivars.sh 或类似的脚本。 此脚本会为其 MPI 发行版设置相应的 MPI 变量。#!/bin/shsource /opt/intel_2019/compilers_and_libraries_2019.3.199/linux/mpi/intel64/bin/mpivars.shmpirun /opt/lumerical/v251/bin/fdtd-engine-impi-lcl -logall -fullinfo fdtd_100mb.fsp示例 3 (高级)：使用 Modules 管理软件版本您可以使用 Modules 来管理多个版本的 Lumerical 软件。 Modules 是集群管理中用于处理作业环境的常用工具。 您可以在这里找到有关如何创建 Modules 的更多信息：http://www.admin-magazine.com/HPC/Articles/Environment-Modules#!/bin/shmodule load intel-mpimodule load lumerical-2019bmpirun fdtd-engine-impi-lcl -logall -fullinfo fdtd_100mb.fsp各调度系统运行命令 Slurm: sbatch -N {nodes} --ntasks-per-node={ppn} {submit.sh} Torque: qsub -l nodes={n}:ppn={ppn} {submit.sh} SGE: qsub -pe mpi {nodes*ppn} {submit.sh} IBM Platform/Spectrum LSF: bsub -Ip -n {nodes*ppn} {submit.sh} 额外技巧：单命令提交作业您也可以使用单个命令提交作业：printf '#!/bin/sh\\nmodule load intelmpi\\nmpirun /opt/lumerical/v251/bin/fdtd-engine-impi-lcl -logall -fullinfo fdtd_1000000mb.fsp' | {job_scheduler_command}" }, { "title": "Cadence Support Downloader", "url": "/posts/cadence-support-downloader/", "categories": "icenv", "tags": "eda", "date": "2025-05-20 16:00:00 +0000", "snippet": "对RAK文章内含PDF和attachment下载，博主做了一个Chrome Extension来自动化获取。界面与效果如图，", "content": "对RAK文章内含PDF和attachment下载，博主做了一个Chrome Extension来自动化获取。界面与效果如图，" }, { "title": "Instructions for ST Package Setup", "url": "/posts/instructions-for-st-package-setup/", "categories": "icenv", "tags": "pdk", "date": "2025-05-11 16:00:00 +0000", "snippet": "这篇文档介绍了意法半导体（ST）内部使用的设计环境配置和管理方式，其中明确区分了系统管理员（CAD Administrator）和普通设计工程师的角色与任务，具体概括如下：一、管理员配置流程（System Administrator）管理员的主要职责是准备设计环境，使所有用户能够无障碍地使用 EDA 工具和库。管理员流程分为两种情况：1. Design Kit 完整包 安装完成后，...", "content": "这篇文档介绍了意法半导体（ST）内部使用的设计环境配置和管理方式，其中明确区分了系统管理员（CAD Administrator）和普通设计工程师的角色与任务，具体概括如下：一、管理员配置流程（System Administrator）管理员的主要职责是准备设计环境，使所有用户能够无障碍地使用 EDA 工具和库。管理员流程分为两种情况：1. Design Kit 完整包 安装完成后，会创建特定目录： &lt;ST_AREA&gt;/SETUP/SETUP_&lt;ID_delivery&gt;/ 目录中包含： .cdsinit 与 .cdsinit.user（Cadence 环境初始化） cds.lib（库定义文件） .simrc 与 .simrc.user（仿真配置） csh_init（环境变量定义，核心文件，管理员必须修改） soft_init（EDA工具配置，管理员必须修改） .ucdprod（UnicadKernel 产品定义文件，无需修改） 重点文件说明： csh_init 文件 定义重要环境变量： ST_AREA：安装目录根路径 SETUP_DIR：当前配置目录路径 UCDPRJDIR：项目路径 .cdsinit.user、.simrc.user、cds.lib文件路径 如果使用 Keysight 的 Goldengate 仿真器，需定义变量opusver以确保 CSF机制正常工作。 soft_init 文件 包含各种 EDA 工具设置（Cadence、Mentor Graphics、Synopsys、Keysight） 需更新实际使用的工具配置，未使用的可注释掉。 管理员验证方法：source &lt;ST_AREA&gt;/SETUP/SETUP_&lt;ID_delivery&gt;/csh_init2. Addon 包（仅附加库或工具包，无 Design Kit） 若已安装基础 Design Kit，且包含 UnicadKernel： 仅需更新&lt;ST_AREA&gt;/SETUP/SETUP_&lt;ID_delivery&gt;/.ucdprod文件。 若未安装 UnicadKernel： 需要手动将新库添加到cds.lib中。 验证方式与完整包相同。二、用户配置流程（Design Engineer）用户端环境配置相对简单，管理员完成前述配置后： 用户进入自己的工作目录（不同于&lt;ST_AREA&gt;）： source &lt;ST_AREA&gt;/SETUP/SETUP_&lt;ID_delivery&gt;/csh_init 推荐方式：在用户工作目录中建立链接到上述csh_init文件，便于后续自动继承管理员配置的更新： ln -s &lt;ST_AREA&gt;/SETUP/SETUP_&lt;ID_delivery&gt;/csh_init . 运行上述命令后，自动在用户目录创建： .cdsinit .simrc cds.lib 用户每次启动环境时，会自动引用最新的.cdsinit与.simrc配置，即使用户在本地进行过修改，也会提示覆盖.ucdprod文件，接受即可。三、启动应用程序示例（Application launch）完成上述环境配置后，用户即可启动具体的 EDA 应用： 模拟设计： virtuoso &amp; 数字设计： encounter &amp; 以上即为意法半导体PDK的配置与使用过程，管理员负责初始环境部署与定制，普通用户则通过简单的命令继承管理员的配置，最终启动各自的设计工具进行工作。" }, { "title": "RHEL9 XFCE ETX Multiple Session Gray Screen Fix", "url": "/posts/rhel9-xfce-etx-multiple-session-gray-screen-fix/", "categories": "icenv", "tags": "etx", "date": "2025-05-10 16:00:00 +0000", "snippet": "RHEL 9 下 XFCE 在 OpenText ETX 多会话中出现灰屏问题的解决方案 参考资料： XFCE Forum - Cannot run multiple xfce4-session as same user Xfce Bugzilla - Bug 7502 背景在使用 OpenText Exceed TurboX（ETX）部署远程 Linux 桌面时，用户往...", "content": "RHEL 9 下 XFCE 在 OpenText ETX 多会话中出现灰屏问题的解决方案 参考资料： XFCE Forum - Cannot run multiple xfce4-session as same user Xfce Bugzilla - Bug 7502 背景在使用 OpenText Exceed TurboX（ETX）部署远程 Linux 桌面时，用户往往会配置轻量级桌面如 xfce4-session 以适配 RHEL 9 图形栈。但当同一用户尝试启动第二个会话时，桌面无法正确加载，常见表现为： 仅显示灰屏（无任务栏/窗口管理器） 不响应鼠标/键盘 关闭 Session 时无法正常退出根因分析根据社区讨论与官方 bug 跟踪，出现该问题的主要原因包括：1. xfce4-session 不支持并发运行多实例（同用户）XFCE 的 session 管理器（xfce4-session）会尝试通过 DBus 注册 session，如果同一用户已有运行中的 session，则第二个 session 会因为注册失败或资源锁冲突而退出或挂起。2. 环境变量继承导致资源冲突当启动第二个 ETX 会话时，若复用了以下关键环境变量，会话初始化将失败： DBUS_SESSION_BUS_ADDRESS XDG_RUNTIME_DIR XAUTHORITY DISPLAY这些变量与第一个 session 紧密关联，导致桌面组件（如 xfwm4、xfce4-panel）无法初始化或连接错误的 socket 文件。3. ~/.cache/sessions/ 下的 session 文件未隔离XFCE 会在该目录记录 session 状态，多 session 并发写入/读取会触发 race condition。解决方案✅ 使用干净环境变量启动 xfce4-session创建如下脚本（如 /nfs/etx/scripts/startxfce4-clean.sh）：#!/bin/bashenv -i /bin/sh -c \"export PATH=$PATH; export XAUTHORITY=$XAUTHORITY; export DISPLAY=$DISPLAY; export HOME=$HOME; export LOGNAME=$LOGNAME; export USER=$USER; /usr/bin/xfce4-session\"确保设置权限：chmod +x /nfs/etx/scripts/startxfce4-clean.sh在 ETX 中，将该脚本设置为会话的启动命令（launch command）。验证方式 启动第一个 ETX session，观察日志是否正常： tail -f ~/.xsession-errors 启动第二个 session，确认灰屏是否消失。 可对比前后 env 差异： env &gt; /tmp/env1 # 第一个正常env &gt; /tmp/env2 # 第二个失败diff -u /tmp/env1 /tmp/env2 总结在 RHEL 9 + ETX 环境中，使用 XFCE 桌面时遇到灰屏，绝大多数是由于环境变量未隔离引起的。通过 env -i 启动一个最小化的会话环境，可以彻底绕过 xfce4-session 多实例带来的冲突。附录：引用 XFCE Forum: https://forum.xfce.org/viewtopic.php?id=11046 XFCE Bugzilla: https://bugzilla.xfce.org/show_bug.cgi?id=7502" }, { "title": "桌面工具在HPC/芯片研发中的“集体失效”：跨机器使用为何频繁报错？", "url": "/posts/why-desktop-tools-break-in-multi-user-hpc/", "categories": "icenv", "tags": "tools", "date": "2025-05-07 16:00:00 +0000", "snippet": "桌面工具在HPC/芯片研发中的“集体失效”：跨机器使用为何频繁报错？ 当我们在 EDA 流程中，通过 SSH 登录多个服务器，打开 VS Code、LibreOffice 或类似桌面工具时，经常遇到 EACCES、socket 无法创建、配置目录不可写 等奇怪报错。这是为什么？随着芯片研发、验证和后仿等流程在 分布式计算资源（HPC 集群） 上逐渐常态化，越来越多开发者尝试将本地熟悉的桌面...", "content": "桌面工具在HPC/芯片研发中的“集体失效”：跨机器使用为何频繁报错？ 当我们在 EDA 流程中，通过 SSH 登录多个服务器，打开 VS Code、LibreOffice 或类似桌面工具时，经常遇到 EACCES、socket 无法创建、配置目录不可写 等奇怪报错。这是为什么？随着芯片研发、验证和后仿等流程在 分布式计算资源（HPC 集群） 上逐渐常态化，越来越多开发者尝试将本地熟悉的桌面工具（如 VS Code）迁移至远程服务器或容器中使用。然而，一旦使用方式突破“本地桌面”的使用假设，这些工具的“脆弱性”就暴露出来。一、问题现象在远程服务器或容器中启动 VS Code、LibreOffice 时，常见报错包括： ❌ EACCES: permission denied, /run/user/10000/...sock ❌ Failed to write user data ❌ 插件无法加载或被清空 ❌ 无法保存配置、窗口布局、最近使用列表等信息 ❌ 在多个机器上同时打开 VS Code 会互相覆盖配置或崩溃二、根因分析：工具的“设计假设” VS “实际使用环境”🎯 这些问题并不是 Bug，而是这些工具设计之初 “只考虑了本地桌面场景”： 设计假设 在 HPC/研发场景中的现实 每个用户有独占的 ~/.config 多用户共享 NFS Home，配置可能并发写入 每个会话绑定 systemd 启动的 /run/user/$UID 容器/远程 SSH 环境中该目录可能不存在或无权限 扩展、插件存放在 ~/.vscode/extensions 不同机器间不共享或被多个实例同时访问 IPC（语言服务器等）通过本地 UNIX socket 跨主机、NFS/AFS 挂载时 socket 无法工作或冲突 这些架构假设在单机桌面上运转良好，但在芯片设计或 HPC 场景中，我们的工作模式是： 👥 多用户、多实例共享同一套工具； 🌐 使用 NFS、AFS 等网络挂载的 Home 目录； 🧠 在不同节点并发运行 GUI 工具调试多个工程； 🧱 容器中运行 code-server，无法启动 systemd； 🔧 使用 SLURM/LSF 调度的后台机器上调试图形界面。此时，原本隐藏的问题就被“放大”了出来。三、现实需求：我们希望工具“像 CLI 一样可靠”在芯片研发中，使用者关心的是： 📂 工程环境能跨机器复用，配置不互相覆盖； 🔧 插件可控、可部署，最好能缓存或集中管理； 🧑‍💻 同一工具能开多个工程实例（多任务并发调试）； 🚀 不依赖 systemd、桌面环境、dbus 等底层机制； 📦 可容器化、自动化部署，支持 DevContainer、code-server 等远程方式。遗憾的是，VS Code、LibreOffice 等工具的架构并未为这些需求而设计。这种“使用者需求”与“开发者设计”的结构性不匹配，是许多使用痛点的根源。四、解决方向：绕过假设、控制状态针对这种设计错配，我们可以采用一些工程性手段进行“非侵入式适配”：✅ 重定向所有写入路径命令行参数指定：code \\ --user-data-dir=$HOME/.vscode-user-data \\ --extensions-dir=$HOME/.vscode-extensions或者设置环境变量：export XDG_RUNTIME_DIR=/tmp/runtime-$USERexport VSCODE_PORTABLE=$HOME/.vscode-portable也可写成wrapper，对用户透明：#!/bin/bashUSER_DIR=\"$HOME/.vscode-user-data\"EXT_DIR=\"$HOME/.vscode-extensions\"XDG_RUNTIME_DIR=\"/tmp/runtime-$USER\"mkdir -p \"$USER_DIR\" \"$EXT_DIR\" \"$XDG_RUNTIME_DIR\"chmod 700 \"$XDG_RUNTIME_DIR\"export XDG_RUNTIME_DIRcode --user-data-dir=\"$USER_DIR\" --extensions-dir=\"$EXT_DIR\" \"$@\" 避免触发 /run/user/$UID 和默认路径的写入冲突。✅ 使用独立配置副本隔离不同工程或节点在不同机器上用不同路径运行：code --user-data-dir=~/.vscode-data-node1 --extensions-dir=~/.vscode-ext-node1✅ 利用容器或 code-server 显式控制目录docker run \\ -v $HOME/dev:/home/coder/project \\ -v $HOME/.vscode-server:/home/coder/.vscode-server \\ -p 8080:8080 \\ codercom/code-server✅ 标准化部署：将 GUI 工具容器化封装为远程服务通过 devcontainer、VNC、XPRA、WebSocket proxy（如 vscode-web）方式将桌面工具“服务化”，避免 socket、用户空间路径的冲突。五、展望：需要“跨节点、并发、安全”的 GUI 工具我们期待的下一代开发工具应具备： 🧩 配置可组合（Configuration as Code）； 📦 状态可迁移（状态路径、插件、缓存可定制）； 🧵 多实例隔离（一个工具多个工程并发运行）； 🧑‍🤝‍🧑 支持多用户环境（共享 HPC 集群资源）； ☁️ 支持 remote-first / container-native 的架构理念。写在最后 VS Code、LibreOffice、Jupyter 等现代工具的崛起极大提升了桌面开发效率，但当它们被带入 HPC、芯片研发这样的“远程+共享+高并发”环境时，必须要考虑它们底层设计与实际需求之间的缝隙。解决这个问题，不只是做一些参数配置，更是让我们认识到：“为桌面而生”的工具，并不能天然胜任“集群化工作”。如果你所在团队也遇到类似工具“在集群中失效”的情况，欢迎交流讨论。" }, { "title": "重置Typora试用", "url": "/posts/restore-typora-trial/", "categories": "博客", "tags": "markdown", "date": "2025-05-05 16:00:00 +0000", "snippet": "最近安装了 Typora 但是没来得及试用就到期了。想重新试用下。打开CMD执行以下命令cd C:%HOMEPATH%\\AppData\\Roaming\\Typoradel typora.logdel profile.data", "content": "最近安装了 Typora 但是没来得及试用就到期了。想重新试用下。打开CMD执行以下命令cd C:%HOMEPATH%\\AppData\\Roaming\\Typoradel typora.logdel profile.data" }, { "title": "FLEXLM_DIAGNOSTICS 变量", "url": "/posts/flexlm-diagnostics/", "categories": "icenv", "tags": "lic", "date": "2025-05-05 16:00:00 +0000", "snippet": "FLEXLM_DIAGNOSTICS 是由 Revenera 公司在其 FlexNet Publisher（原名 FLEXlm）许可证管理系统中定义的一个环境变量，用于诊断和调试许可证检查过程中的问题。它的主要作用是让应用程序在启动时输出更详细的许可处理日志信息，帮助用户或系统管理员定位许可失败的具体原因。📌 变量功能简述FLEXLM_DIAGNOSTICS 用于控制诊断信息的输出级别。它主...", "content": "FLEXLM_DIAGNOSTICS 是由 Revenera 公司在其 FlexNet Publisher（原名 FLEXlm）许可证管理系统中定义的一个环境变量，用于诊断和调试许可证检查过程中的问题。它的主要作用是让应用程序在启动时输出更详细的许可处理日志信息，帮助用户或系统管理员定位许可失败的具体原因。📌 变量功能简述FLEXLM_DIAGNOSTICS 用于控制诊断信息的输出级别。它主要会影响如下行为： 应用程序启动后，在标准输出或错误输出中打印详细的许可证搜索路径、找到的 license 文件、服务器交互过程等信息； 帮助开发者或管理员了解许可证查找路径、失败原因（如 feature 不存在、过期、未启用等）； 通常与 LM_LICENSE_FILE 配合使用，可帮助调试许可证路径是否设置正确。🧪 常见使用方法设置变量的方式视操作系统以及shell类型而定：▪ Linux / macOS:export FLEXLM_DIAGNOSTICS=3 #for bashsetenv FLEXLM_DIAGNOSTICS 3 #for [t]csh▪ Windows（cmd 命令行）:set FLEXLM_DIAGNOSTICS=3🔢 可用的取值 值 描述 1 输出基本的诊断信息（license path、server status 等） 2 输出中等详细度的信息（包括 feature 检查失败的原因） 3 输出最详细的诊断信息，包括完整的许可证检查、路径、服务器交互细节 建议从等级 1 或 2 开始，如果问题难以定位，可以设置为 3。📋 示例输出（等级 3）FLEXnet Licensing error:-5,357 [Detecting lmgrd processes...] [Trying license file: C:\\licenses\\app.lic] [Checking in with license server: 27000@licserver] [Feature 'mytool' not found in license file.]🚨 注意事项 使用 FLEXLM_DIAGNOSTICS 可能会影响性能（尤其在大型程序启动时），不建议在生产环境长期开启； 某些工具（如 Cadence、Synopsys）也支持该变量，但实际效果取决于工具是否启用了该调试支持； 如果是脚本调用的程序，注意 redirect 标准输出到日志中便于查看。" }, { "title": "使用pip下载适用于不同Python版本的pip包", "url": "/posts/use-pip-to-install-python-packages-across-versions/", "categories": "icenv", "tags": "python", "date": "2025-04-28 16:00:00 +0000", "snippet": "经常有这样的需求，以一个Python版本下载pip包，放到另一个版本的Python里安装使用。C:\\Users\\ben\\Downloads\\pip-pkgs&gt;python3 --versionPython 3.11.9C:\\Users\\ben\\Downloads\\pip-pkgs&gt;python3 -m pip download --python-version 3.13 -d ....", "content": "经常有这样的需求，以一个Python版本下载pip包，放到另一个版本的Python里安装使用。C:\\Users\\ben\\Downloads\\pip-pkgs&gt;python3 --versionPython 3.11.9C:\\Users\\ben\\Downloads\\pip-pkgs&gt;python3 -m pip download --python-version 3.13 -d . pyyaml[notice] A new release of pip is available: 25.0.1 -&gt; 25.1[notice] To update, run: C:\\Users\\ben\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pipERROR: When restricting platform and interpreter constraints using --python-version, --platform, --abi, or --implementation, either --no-deps must be set, or --only-binary=:all: must be set and --no-binary must not be set (or must be set to :none:).提示如果使用”–python-version”则必须要指明”–no-deps”或”–only-binary=:all:”。理解一下，就是如果指定Python版本时，则它无法解析依赖树，要么不下载依赖，要么将所有的二进制下载下来。C:\\Users\\ben\\Downloads\\pip-pkgs&gt;python3 -m pip download --python-version 3.13 --no-deps -d . pyyamlCollecting pyyaml Downloading PyYAML-6.0.2-cp313-cp313-win_amd64.whl.metadata (2.1 kB)Downloading PyYAML-6.0.2-cp313-cp313-win_amd64.whl (156 kB)Saved c:\\users\\ben\\downloads\\pip-pkgs\\pyyaml-6.0.2-cp313-cp313-win_amd64.whlSuccessfully downloaded pyyaml[notice] A new release of pip is available: 25.0.1 -&gt; 25.1[notice] To update, run: C:\\Users\\ben\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip" }, { "title": "How to Configure DNS Forwarding with Microsoft AD DS and Dnsmasq", "url": "/posts/dns-forwarding-microsoft-ad-ds-dnsmasq/", "categories": "icenv", "tags": "dns", "date": "2025-04-28 16:00:00 +0000", "snippet": "问题在芯片研发环境， 有些EDA tools会后台发送使用数据至其公司后台，给公司带来信息安全风险（安全）。 EDA tools在使用时访问一个无法通信的地址时，会等待，导致工具性能低下（性能）。分析安全方面，业界的做法是防火墙隔离。当不可避免地需要在上网环境使用时，则可以针对其公司的二级域名及其子域名，全部劫持解析到一个不能访问的地址，以此降低风险。一般的做法是，穷举其用到的（二级、三...", "content": "问题在芯片研发环境， 有些EDA tools会后台发送使用数据至其公司后台，给公司带来信息安全风险（安全）。 EDA tools在使用时访问一个无法通信的地址时，会等待，导致工具性能低下（性能）。分析安全方面，业界的做法是防火墙隔离。当不可避免地需要在上网环境使用时，则可以针对其公司的二级域名及其子域名，全部劫持解析到一个不能访问的地址，以此降低风险。一般的做法是，穷举其用到的（二级、三级）域名并在DNS服务器加上A记录，但这样的做法是不完善的： 一方面无法保证穷举是否完全； 另一方面，EDA tool vendor也可能会在新版本更新子域名导致已添加的DNS A记录未覆盖到。性能方面，需要确保访问无法通信的地址能立即拒绝，提升工具性能。因此需要一个能自适应，或者覆盖完全的解决方案。架构这里设计一个架构，能够覆盖synopsys.com及其子域名的所有域名解析。+-----------------------+ +------------------------+| | | || 客户端 (Client) | 请求: synopsys.com | Microsoft AD DNS || +-------------------------&gt;| Server || | | |+-----------------------+ +------------------------+ | | | | | 转发查询 | | v | +------------------------+ | | | Forwarder 配置 | | synopsys.com -&gt; | | dnsmasq Server | | | +------------------------+ | | 请求解析 v +------------------------++-----------------------+ | || | | dnsmasq Server || 客户端 (Client) | 返回: 127.0.0.1 | 解析 synopsys.com 和 || |&lt;------------------------ | *.synopsys.com -&gt; |+-----------------------+ | 127.0.0.1 | +------------------------+" }, { "title": "Automated Cell and Library Renaming with Instance Master Updates in Cadence Virtuoso", "url": "/posts/automated-cell-and-library-renaming-with-instance-master-updates-in-cadence-virtuoso/", "categories": "icenv", "tags": "analog", "date": "2025-04-22 16:00:00 +0000", "snippet": "IntroductionIn large-scale analog/digital IC design projects, design reuse and project forking are common practices. These often require renaming of entire libraries and cell hierarchies to conform...", "content": "IntroductionIn large-scale analog/digital IC design projects, design reuse and project forking are common practices. These often require renaming of entire libraries and cell hierarchies to conform to new naming conventions (e.g., transitioning from Hi5800V100 to Hi5800V200). Manual renaming of cells and libraries, along with updating all hierarchical instance references, is a tedious and error-prone task. To address this, we have developed a robust SKILL-based automation script: CCSRenameAndUpdate.il.ObjectiveThe primary goal of this script is to: Batch rename cells using a specified prefix change. Rename entire libraries while preserving their internal structure. Recursively update all instance master references within layout, symbol, and schematic views.By automating this process, we ensure consistency, reduce manual intervention, and accelerate design preparation for derivative projects.Implementation OverviewThe script is implemented in three major steps, encapsulated in a top-level procedure: CCSRenameCellsAndInstancesByPrefix.Source code,;;--------------------------------------------------------------------;; File : CCSRenameAndUpdate.il;; Purpose : 使用官方 API 重命名前缀 + 更新 instance master（layout/symbol/schematic）;; Author : wanlin.wang;; Updated : 2025/04/22;;-------------------------------------------------------------------- ;; === Step 1: 使用 ccpRename 重命名 Cell ===procedure(renameCellPrefixByCCP(libList origPrefix newPrefix) let( (oldName newName srcSpec destSpec) foreach(libName libList foreach(cell ddGetObj(libName)-&gt;cells oldName = cell~&gt;name when(rexMatchp(strcat(\"^\" origPrefix) oldName) newName = rexReplace(oldName newPrefix 0) printf(\"Renaming cell: %s/%s -&gt; %s\\n\" libName oldName newName) srcSpec = gdmCreateSpec(libName oldName \"\" \"\" \"CDBA\") destSpec = gdmCreateSpec(libName newName \"\" \"\" \"CDBA\") let((dummySpecList) dummySpecList = gdmCreateSpecList() ccpRename( srcSpec destSpec t 'CCP_EXPAND_ALL 'CCP_UPDATE_COPIED_DATA dummySpecList ) ) ) ) ) )) ;; === Step 2: 重命名 Libraryprocedure(CCSRenameLibsByPrefix(libList origPrefix newPrefix) let((oldLibName newLibName src dst dummySpecList) foreach(oldLibName libList when(stringp(oldLibName) &amp;&amp; rexMatchp(strcat(\"^\" origPrefix) oldLibName) newLibName = rexReplace(oldLibName newPrefix 0) printf(\"Renaming library: %s -&gt; %s\\n\" oldLibName newLibName) srcSpec = gdmCreateSpec(oldLibName nil nil nil \"CDBA\") dstSpec = gdmCreateSpec(newLibName nil nil nil \"CDBA\") dummySpecList = gdmCreateSpecList() ccpRename( srcSpec dstSpec t ;; allow overwrite 'CCP_EXPAND_ALL 'CCP_UPDATE_COPIED_DATA ;; do not update references dummySpecList ) ) ) t )) ;; === Step 3: 遍历每个 cellView，更新实例的 master ===procedure(updateInstanceMasterReference(libList origPrefix newPrefix) let( (lib cell cellView cv inst master oldMasterName newMasterName oldLibName newLibName newMasterCv renamedLibList) ;; 创建重命名后的库列表 renamedLibList = list() ;; 初始化空列表 foreach(lib libList when(stringp(lib) &amp;&amp; rexMatchp(strcat(\"^\" origPrefix) lib) newLibName = rexReplace(lib newPrefix 0) ;; 替换库名 renamedLibList = cons(newLibName renamedLibList) ;; 将替换后的库名添加到新的列表中 printf(\"Library renamed: %s -&gt; %s\\n\" lib newLibName) ;; 新增日志打印 ) ) ;; 遍历每个新的库名 foreach(lib renamedLibList printf(\"Processing library: %s\\n\" lib) ;; 日志打印库 foreach(cell ddGetObj(lib)-&gt;cells printf(\" Processing cell: %s\\n\" cell~&gt;name) ;; 日志打印 cell foreach(cellView cell~&gt;views printf(\" Processing cellView: %s\\n\" cellView~&gt;name) ;; 日志打印 cellView when(member(cellView~&gt;name '(\"layout\" \"symbol\" \"schematic\")) cv = dbOpenCellViewByType(lib cell~&gt;name cellView~&gt;name \"\" \"a\") when(cv foreach(instHeader cv~&gt;instHeaders when(instHeader~&gt;cellName printf(\" Processing instance's master cellName: %s\\n\" instHeader~&gt;cellName) ;; 日志打印实例 oldMasterName = instHeader~&gt;cellName oldLibName = instHeader~&gt;libName ;; 打印 oldLibName 和 oldMasterName，帮助调试 printf(\" oldLibName: %s, oldMasterName: %s\\n\" oldLibName oldMasterName) ;; 如果库名匹配前缀，则继续更新 cell 名 when(stringp(oldLibName) &amp;&amp; rexMatchp(strcat(\"^\" origPrefix) oldLibName) newLibName = rexReplace(oldLibName newPrefix 0) ;; 如果 master 名匹配前缀，则替换 master 名，否则保持原名 newMasterName = oldMasterName when(stringp(oldMasterName) &amp;&amp; rexMatchp(strcat(\"^\" origPrefix) oldMasterName) newMasterName = rexReplace(oldMasterName newPrefix 0) ) printf(\"Updating instance in %s/%s/%s: %s/%s -&gt; %s/%s\\n\" lib cell~&gt;name cellView~&gt;name oldLibName oldMasterName newLibName newMasterName) ;; 通过dbSetInstHeaderMasterName来替换实例的master dbSetInstHeaderMasterName(instHeader newLibName newMasterName nil) ) ) ) dbSave(cv) dbClose(cv) ) ) ) ) ) )) ;; === 顶层函数 ===procedure(CCSRenameCellsAndInstancesByPrefix(libList origPrefix newPrefix) printf(\"&gt;&gt;&gt; Step 1: Rename Cells by Prefix...\\n\") renameCellPrefixByCCP(libList origPrefix newPrefix) printf(\"&gt;&gt;&gt; Step 2: Rename Libraries by Prefix...\\n\") CCSRenameLibsByPrefix(libList origPrefix newPrefix) printf(\"&gt;&gt;&gt; Step 3: Update Instance Master References...\\n\") updateInstanceMasterReference(libList origPrefix newPrefix) printf(\"&gt;&gt;&gt; All Done.\\n\"))Step 1: Rename Cells by PrefixProcedure: renameCellPrefixByCCP Iterates through all cells in the specified libraries. Detects cells with a given prefix using regular expressions. Renames matched cells to a new prefix using the official ccpRename API. Ensures that all data, including schematic/layout content, is copied and expanded (CCP_EXPAND_ALL and CCP_UPDATE_COPIED_DATA).ccpRename( srcSpec destSpec t 'CCP_EXPAND_ALL 'CCP_UPDATE_COPIED_DATA dummySpecList)Step 2: Rename Libraries by PrefixProcedure: CCSRenameLibsByPrefix Operates on library names matching the specified prefix. Reconstructs a new name and uses ccpRename to duplicate and rename the entire library. Maintains internal cell structure but does not update references at this stage.Step 3: Update Instance Master ReferencesProcedure: updateInstanceMasterReference Opens each relevant layout, symbol, and schematic view in the renamed libraries. Iterates through instance headers to identify references to old libraries or cell names. If both the library and cell names match the original prefix, it updates the instance’s master path using dbSetInstHeaderMasterName.dbSetInstHeaderMasterName(instHeader newLibName newMasterName nil) Saves and closes each modified cellView after updates.Top-Level InvocationProcedure: CCSRenameCellsAndInstancesByPrefix Accepts a list of target libraries, original prefix, and desired new prefix. Sequentially calls the three core steps to complete the transformation.Example usage:CCSRenameCellsAndInstancesByPrefix( (list \"Hi5800V100_PLL\" \"Hi5800V100_TX\") \"Hi5800V100\" \"Hi5800V200\")ConclusionThe CCSRenameAndUpdate.il script provides a comprehensive, automated solution for prefix-based renaming across cells, libraries, and instance references. It significantly simplifies the process of adapting legacy designs to new project naming conventions, improving both design integrity and engineer productivity.This solution is particularly useful in IP reuse workflows, project fork management, and hierarchical tapeout preparations in Cadence Virtuoso environments.For integration, simply load the script into CIW, and invoke the top-level procedure with appropriate parameters." }, { "title": "根据文件中指定的映射关系批量重命名多个库，并更新（包括新库名称在内的）库列表下cell view的引用关系", "url": "/posts/rename-library-and-update-reference/", "categories": "icenv", "tags": "analog", "date": "2025-04-20 16:00:00 +0000", "snippet": "脚本说明我希望能够一次性重命名多个库。这些库的旧名称与新名称保存在一个文件中，格式如下：oldlib1 newlib1oldlib2 newlib2oldlib3 newlib3同时，我还希望更新其他引用了这些库中 cell 的库，使它们指向新的库名。我会将需要更新引用的库名称写在另一个文件中，一行列出所有库名，例如：SAMPLE MAJOR MINOR FINAL FORWARD那么，如何...", "content": "脚本说明我希望能够一次性重命名多个库。这些库的旧名称与新名称保存在一个文件中，格式如下：oldlib1 newlib1oldlib2 newlib2oldlib3 newlib3同时，我还希望更新其他引用了这些库中 cell 的库，使它们指向新的库名。我会将需要更新引用的库名称写在另一个文件中，一行列出所有库名，例如：SAMPLE MAJOR MINOR FINAL FORWARD那么，如何实现这些库的重命名和引用更新呢？用法说明你可以使用下面提供的 SKILL 脚本来完成这项任务。请将以下 SKILL 代码复制保存为文件 CCSren_libs.il，该代码也作为解决方案的附件提供。在 CIW 中加载脚本：load \"CCSren_libs.il\"创建库重命名映射文件，假设文件名为 oldLibToNewLibMapFile，格式如下：oldlib1 newlib1 oldlib2 newlib2 oldlib3 newlib3创建另一个文件，用来指定哪些库需要更新引用。假设文件名为 LibsToUpdate，内容格式如下：SAMPLE MAJOR MINOR FINAL FORWARD然后，在 CIW 中调用以下命令：CCSren_libs(\"oldLibToNewLibMapFile\" \"LibsToUpdate\")这将会完成库的重命名，并在目标库中更新引用关系。脚本代码;-----------------------x Copy from here x-------------------/************************************************************************** DISCLAIMER: The following code is provided for Cadence customers ** to use at their own risk. The code may require modification to ** satisfy the requirements of any user. The code and any modifications ** to the code may not be compatible with current or future versions of ** Cadence products. THE CODE IS PROVIDED \"AS IS\" AND WITH NO WARRANTIES, ** INCLUDING WITHOUT LIMITATION ANY EXPRESS WARRANTIES OR IMPLIED ** WARRANTIES OF MERCHANTABILITY OR FITNESS FOR A PARTICULAR USE. **************************************************************************/procedure(CCSren_libs(oldToNewLibFile libsToUpdateFile) let((src dst newName libList1 libSpecList ip str spec ip1 libList)\t ;; Read the name of libraries to be updated after rename ip1=infile(libsToUpdateFile) gets(str ip1) libList=parseString(str \" \\n\")\t ;; Read the set of old and new lib name and form a list of list with oldlib newlib pair ip=infile(oldToNewLibFile) libList1=list() while(gets(str ip)\tstr=parseString(str \" \\n\")\tlibList1=cons(str libList1) ) ;while ;; Operate on each pair of oldlib-newlib one by one\tforeach(lib libList1\t\tnewName=cadr(lib)\t\tsrc=gdmCreateSpec(car(lib) nil nil nil \"CDBA\")\t\tdst=gdmCreateSpec(newName nil nil nil \"CDBA\")\t\t\t\t;; replace the old lib name to new lib name in master library list\t\tlibList=subst(newName car(lib) libList)\t\t;; Cover the scenario of oldlib not in list, add newlib anyways\t\tunless(member(newName libList) libList=cons(newName libList))\t\t\t\t;; Create specList for libs to be updated\t\tlibSpecList=gdmCreateSpecList()\t\t\t\tforeach(lib1 libList\t\t\tspec=gdmCreateSpec(lib1 \"\" \"\" \"\" \"CDBA\")\t\t\tgdmAddSpecToSpecList(spec libSpecList)\t\t) ;foreach\t\tccpRename(src dst t 'CCP_EXPAND_COMANAGED 'CCP_UPDATE_FROM_LIBLIST libSpecList)\t) ; foreach oldToNewLibFile libList1 t ) ; let) ; procedure" }, { "title": "Rename CellName and Update Reference", "url": "/posts/rename-cellname-and-update-references/", "categories": "icenv", "tags": "analog", "date": "2025-04-20 16:00:00 +0000", "snippet": "Skill代码;;--------------------------------------------------------------------;; Function: CCSRenameCellAndUpdateReference;; Purpose : 在多库中批量重命名 cell 前缀，并更新实例引用;; Usage ：在 CIW load 这个脚本，然后运行 CCSRe...", "content": "Skill代码;;--------------------------------------------------------------------;; Function: CCSRenameCellAndUpdateReference;; Purpose : 在多库中批量重命名 cell 前缀，并更新实例引用;; Usage ：在 CIW load 这个脚本，然后运行 CCSRenameCellAndUpdateReference 这个 procedure;; Args : libList - list of library names to process;; origPrefix - the prefix to replace (string);; newPrefix - the new prefix (string);; Example : CCSRenameCellAndUpdateReference(;; (list \"libA\" \"libB\");; \"OLD_\";; \"NEW_\";; T;; );; Author : wanlin.wang;; Date : 2025/04/21;;--------------------------------------------------------------------procedure( CCSRenameCellAndUpdateReference( libList origPrefix newPrefix @optional (overwrite nil)) let( ( srcSpec destSpec newCellName ovrFlag libSpecList) if(overwrite then ovrFlag = `TRUE ; If overwrite is selected else ovrFlag = `FALSE ) ; if ;; 构建gdm spec list（for libList） ;; 1. 创建空的 specList libSpecList = gdmCreateSpecList() ;; 2. 遍历库名列表，生成并添加 spec foreach(libName libList let((libSpec) libSpec = gdmCreateSpec(libName \"\" \"\" \"\" \"CDBA\") gdmAddSpecToSpecList(libSpec libSpecList) ) ) ;; 遍历所有指定的 library foreach(libName libList ;; 获取该 library 下所有 cell 名称 foreach(cell ddGetObj(libName)-&gt;cells rexCompile(sprintf(nil \"^%s\" origPrefix)) if(rexExecute(cell~&gt;name) then newCellName = rexReplace(cell~&gt;name newPrefix 0) ;; 构造源和目标的 GDM spec srcSpec = gdmCreateSpec( libName cell~&gt;name \"\" \"\" \"CDBA\" ) destSpec = gdmCreateSpec( libName newCellName \"\" \"\" \"CDBA\" ) ;; 调用 ccpRename：展开所有层次，从 libSpecList 中更新引用 ccpRename( srcSpec destSpec ovrFlag `CCP_EXPAND_ALL `CCP_UPDATE_FROM_LIBLIST libSpecList ) );; end if ) ;; foreach cell ) ;; foreach libName ) ;; let) ;; procedure" }, { "title": "Why ANSYS does not utilize GPU for rendering when I use it over RDP?", "url": "/posts/question-why-ansys-does-not-utilize-gpu-for-rendering-when-i-use-it-over-rdp/", "categories": "icenv", "tags": "gpu", "date": "2025-04-16 16:00:00 +0000", "snippet": "当你通过 RDP（远程桌面协议）使用 ANSYS 时，可能会发现它并没有利用 GPU 进行图形渲染，导致图形性能变差。这是因为 Windows 默认在 RDP 会话中不会启用 GPU 渲染。🛠 解决方法：启用 RDP 会话的 GPU 加速要让 ANSYS 在远程桌面中也能使用 GPU，需要在远程主机上修改组策略：步骤如下： 打开本地组策略编辑器 按下 Win + ...", "content": "当你通过 RDP（远程桌面协议）使用 ANSYS 时，可能会发现它并没有利用 GPU 进行图形渲染，导致图形性能变差。这是因为 Windows 默认在 RDP 会话中不会启用 GPU 渲染。🛠 解决方法：启用 RDP 会话的 GPU 加速要让 ANSYS 在远程桌面中也能使用 GPU，需要在远程主机上修改组策略：步骤如下： 打开本地组策略编辑器 按下 Win + R，输入 gpedit.msc，然后回车。 导航到以下路径： 计算机配置 →管理模板 →Windows 组件 →远程桌面服务 →远程桌面会话主机 →远程会话环境 找到并启用以下策略： “为所有远程桌面服务会话使用硬件图形适配器” 启用策略后，重启远程主机 or 运行gpupdate /force生效。 ⚠ 注意事项： 某些 Windows 版本（如 Windows 10 LTSB）可能没有此策略项。 启用该设置后，在远程连接下，ANSYS 的图形性能会明显提升，因为它将开始使用显卡（GPU）加速渲染。如需确认是否生效，可通过任务管理器 → 性能 → GPU 观察远程会话期间 GPU 是否有负载。When using ANSYS over Remote Desktop Protocol (RDP), you may notice that the GPU is not utilized for rendering. This behavior occurs because, by default, Windows 10 does not enable GPU rendering over RDP sessions. As a result, graphical performance can be significantly degraded during remote sessions.Solution: Enable GPU Rendering for RDPTo allow ANSYS to utilize the GPU during RDP sessions, you need to modify the Group Policy settings on the remote (host) machine: Open the Local Group Policy Editor: Press Win + R, type gpedit.msc, and press Enter. Navigate to the following path: Computer Configuration → Administrative Templates → Windows Components → Remote Desktop Services → Remote Desktop Session Host → Remote Session Environment Locate and enable the policy named: “Use hardware graphics adapters for all Remote Desktop Services sessions” After enabling the policy, restart the remote machine to apply the changes. Note: This policy setting may not be available on certain editions of Windows 10, such as the Long-Term Servicing Branch (LTSB) citeturn0search0.By enabling this setting, you should observe improved graphical performance in ANSYS during RDP sessions, as the GPU will be utilized for rendering tasks." }, { "title": "SmartTotem GUI", "url": "/posts/smarttotem-gui/", "categories": "icenv", "tags": "emir", "date": "2025-04-13 16:00:00 +0000", "snippet": "启动图形配置界面选择工艺、项目以及Flow填写并生成user.config管理state，如果是管理员还可以管理ADMIN_DB配置add_option.config生成run目录支持信息", "content": "启动图形配置界面选择工艺、项目以及Flow填写并生成user.config管理state，如果是管理员还可以管理ADMIN_DB配置add_option.config生成run目录支持信息" }, { "title": "IBM LSF RTM backups", "url": "/posts/ibm-lsf-rtm-backups/", "categories": "icenv", "tags": "lsf, rtm", "date": "2025-04-12 16:00:00 +0000", "snippet": "详细的备份步骤和方案：1. 日常备份RTM 会在每天的 00:00 自动进行默认的设置和配置备份，备份文件存储在 RTM_TOP/cacti/backup/cacti_db_backup_xx.tgz 中。需要注意，这是设置与配置的数据库备份，不是RTM完整备份。2. 备份数据分区通过启用分区功能，可以最小化灾难恢复时的数据丢失。分区备份文件存储在 RTM_TOP/backup/partit...", "content": "详细的备份步骤和方案：1. 日常备份RTM 会在每天的 00:00 自动进行默认的设置和配置备份，备份文件存储在 RTM_TOP/cacti/backup/cacti_db_backup_xx.tgz 中。需要注意，这是设置与配置的数据库备份，不是RTM完整备份。2. 备份数据分区通过启用分区功能，可以最小化灾难恢复时的数据丢失。分区备份文件存储在 RTM_TOP/backup/partition_backups/*.tgz，需定期备份。分区设定在 Console &gt; Configuration &gt; RTM Settings &gt; Maint &gt; Large System Settings。3. 重要目录的备份以下是关键目录及其备份建议： RTM_TOP/advocate - 每日备份 RTM_TOP/cacti - 每日备份 RTM_TOP/flexlm - 每日备份 RTM_TOP/ioncube - 每日备份 RTM_TOP/rlm（如果使用 Reprise License Manager） - 每日备份 RTM_TOP/rtm - 每日备份 RTMP_TOP/spine - 每日备份 RTM_TOP/cacti/rra - 每小时使用 rsync 或同类工具备份4. Cacti 数据库备份使用 mysqldump 命令定期备份 MariaDB 数据库内容（推荐每日备份）：mysqldump --lock-tables=FALSE cacti &gt; /somewhere/somefilename.sql如果使用table分区，mysqldump时请排除这些table，并额外单独备份table分区文件。5. 自定义文件的备份如果有自定义文件，以下目录需要每日备份： RTM_TOP/cacti/plugins RTM_TOP/cacti/scripts RTM_TOP/cacti/resource6. 其他配置文件备份建议每日备份以下文件和路径（具体路径依据操作系统版本而定）： /etc/php.ini /etc/php.d/* /etc/my.cnf /etc/my.cnf.d/* /etc/cron.d/cacti /etc/rsyslog.conf /etc/rsyslog.d/*以上是基于 IBM LSF RTM 官方的备份方案，可以确保系统和数据的高可用性与灾难恢复能力。" }, { "title": "Enable Marmaid support", "url": "/posts/enable-marmaid-support/", "categories": "icenv", "tags": "", "date": "2025-04-12 16:00:00 +0000", "snippet": "打开流程图的支持，更方便展示流程关系。以下是流程图样例：graph TD; A--&gt;B; A--&gt;C; B--&gt;D; C--&gt;D;", "content": "打开流程图的支持，更方便展示流程关系。以下是流程图样例：graph TD; A--&gt;B; A--&gt;C; B--&gt;D; C--&gt;D;" }, { "title": "Discuz 容器化部署", "url": "/posts/disuz-deployment/", "categories": "icenv", "tags": "forum", "date": "2025-04-12 16:00:00 +0000", "snippet": "🛠 环境准备确保系统已安装 Docker 和 Docker Compose。以RockyLinux 8.10为例，# 安装 Podman &amp; Podman-Composednf install -y podman podman-compose📁 目录结构本例子以 ~/discuz 作为工作目录。在工作目录下创建 html 和 mysql 两个子目录：mkdir -p ~/discuz...", "content": "🛠 环境准备确保系统已安装 Docker 和 Docker Compose。以RockyLinux 8.10为例，# 安装 Podman &amp; Podman-Composednf install -y podman podman-compose📁 目录结构本例子以 ~/discuz 作为工作目录。在工作目录下创建 html 和 mysql 两个子目录：mkdir -p ~/discuz/html ~/discuz/mysql从 https://www.discuz.vip/download 下载的 Discuz_X3.5_SC_UTF8_20250205.zip ，解压后复制 upload 目录中的所有文件到 html 目录：unzip Discuz_X3.5_SC_UTF8_20250205.zipcp -r upload/* ~/discuz/html/🐳 Dockerfile 配置在 html 目录下创建 Dockerfile，内容如下：# 使用官方 PHP 镜像作为基础镜像FROM php:8.2-apache# 安装 PHP 扩展和依赖RUN apt-get update &amp;&amp; apt-get install -y \\ libpng-dev \\ libjpeg-dev \\ libfreetype6-dev \\ &amp;&amp; docker-php-ext-configure gd --with-freetype --with-jpeg \\ &amp;&amp; docker-php-ext-install gd mysqli \\ &amp;&amp; a2enmod rewrite# 设置文档根目录COPY . /var/www/html# 设置工作目录WORKDIR /var/www/html📦 Docker Compose 配置在工作目录下创建 docker-compose.yml，内容如下：version: '3'services: web: build: ./html container_name: discuz_web ports: - \"8080:80\" volumes: - ./html:/var/www/html depends_on: - mysql mysql: image: mysql:8.0 container_name: discuz_mysql environment: - MYSQL_ROOT_PASSWORD=root - MYSQL_DATABASE=ultrax - MYSQL_USER=discuz - MYSQL_PASSWORD=discuz volumes: - ./mysql:/var/lib/mysql healthcheck: test: [\"CMD\", \"mysqladmin\", \"ping\", \"-h\", \"localhost\", \"-u\", \"discuz\", \"-pdiscuz\"] interval: 5s timeout: 5s retries: 5🚀 启动服务在工作目录下执行以下命令启动服务：cd ~/discuzdocker-compose up -d此命令会启动 Discuz! 的 Web 服务和 MySQL 数据库服务。🌐 访问安装界面在浏览器中访问 http://:8080/install，即可进入 Discuz! 的安装界面。📝 安装步骤 阅读并同意授权协议：点击“我同意”继续。 环境检测：系统会自动检查环境配置，确保满足安装要求。 选择安装类型：选择“全新安装 Discuz! X3.5（含 UCenter Server）”。 配置数据库信息： 数据库服务器地址：mysql 数据库名：ultrax 数据库用户名：root 数据库密码：root 设置管理员账号：填写管理员用户名和密码。 开始安装：点击“安装”按钮，系统会自动完成安装过程。 完成安装：安装完成后，系统会提示安装成功。 部分截图如下：✅ 安装完成安装完成后，您可以通过 http://:8080 访问您的 Discuz! 论坛。🔐 安全建议 删除安装目录：安装完成后，为了安全起见，建议删除 install 目录。 设置文件权限：确保论坛目录的权限设置正确，避免出现权限问题。 定期备份：定期备份数据库和论坛文件，以防数据丢失。如有疑问，欢迎留言。" }, { "title": "RTM调优", "url": "/posts/administering-rtm-advanced-configuration-and-performance-tuning/", "categories": "icenv", "tags": "rtm", "date": "2025-04-12 16:00:00 +0000", "snippet": "管理 RTM - 高级配置和性能调优本文详细介绍了 IBM Spectrum LSF RTM (RTM) 的高级配置选项和性能调优技术，旨在帮助管理员更好地监控集群并优化 RTM 性能。控制 LSF 集群RTM 提供了控制 LSF 集群、主机、队列和作业的功能，前提是您已启用 RTM 对 LSF 集群的控制权限。RTM 通过在 LSF 管理主机上启动 LSF 命令来实现对集群的控制。可控制的...", "content": "管理 RTM - 高级配置和性能调优本文详细介绍了 IBM Spectrum LSF RTM (RTM) 的高级配置选项和性能调优技术，旨在帮助管理员更好地监控集群并优化 RTM 性能。控制 LSF 集群RTM 提供了控制 LSF 集群、主机、队列和作业的功能，前提是您已启用 RTM 对 LSF 集群的控制权限。RTM 通过在 LSF 管理主机上启动 LSF 命令来实现对集群的控制。可控制的组件和操作： 集群级组件： mbatchd (管理批处理守护进程): 启动、重启或关闭。 LIM (负载信息管理器): 启动、重启或关闭。 RES (资源执行服务器): 启动、重启或关闭。 运行 badmin reconfig: 动态重新配置 LSF。 运行 lsadmin reconfig: 重启集群中所有主机上的 LIM。 主机： 打开或关闭 LSF 集群中的主机。 队列： 打开队列 关闭队列 激活队列 取消激活队列 将所有作业从一个队列切换到另一个队列 作业： btop: 将挂起作业相对于队列中的第一个作业移动。 bbot: 将挂起作业相对于队列中的最后一个作业移动。 bswitch: 将未完成的作业从一个队列切换到另一个队列。 bresume: 恢复挂起的作业。 brun: 强制作业立即运行。 bstop: 挂起未完成的作业。 bkill: 发送信号以终止未完成的作业。 强制终止 (Force kill): 使用 bkill -r 命令强制终止作业。 信号终止 (Signal kill): 使用 bkill -s 命令发送特定信号以终止作业。 在 LSF 集群上运行 Grid 控制命令可以通过 RTM 控制台在 LSF 集群上运行 LSF 命令。前提条件： 必须已在 LSF 集群上启用了 Grid 控制。步骤： 在 RTM 控制台中，点击 Console 标签页。 在 Grid Management 部分，点击 Clusters。 点击您想要配置的集群的 Cluster Name 链接。 配置集群设置。如果 Grid 控制需要更多信息，请在显示的字段中指定详细信息。 点击 Save。结果： 可以在“查看 LSF 集群和作业信息”部分查看集群的状态。强制执行集群操作控制注释RTM 可以为以下操作强制要求输入注释： 按主机 (By Host) 按队列 (By Queue) 集群 (Cluster)您必须设置 Mandatory Cluster Action Control Comments 选项，以允许您的 Grid 管理员在提交主机、队列或集群的控制操作（如启动/重启/关闭、打开/关闭）之前输入注释。设置强制集群操作控制注释步骤： 点击 Console 标签页。 在 Configuration 部分，点击 Grid Settings。 点击 General 标签页。 在 Cluster Control Settings 下，选中 Mandatory Cluster Action Control Comments 复选框。 点击 Save。对主机、队列或集群的集群操作控制添加注释步骤： 点击 Grid 标签页。 在 Job Info 部分，点击 By Host, By Queue, 或 By Cluster。 选中您想要执行操作的一个或多个主机名对应的复选框。 从列表中选择一个操作。 点击 Go。将显示一个确认对话框。 在文本框中输入您的注释。如果设置了强制集群操作注释，您必须输入注释才能继续提交。 点击 Yes。为集群配置空闲作业检测关于此任务： 空闲作业是按集群在 Cluster Edit 页面上配置的，并非全局配置。 可以排除特定队列（例如，提交到交互式队列的作业）不参与空闲作业计算。 注意： 全新安装 RTM 10.2 后，任何先前的空闲作业设置都将失效，您必须重新配置它们。步骤： 点击 Console 标签页。 在 Grid Management 部分，点击 Clusters。 点击您想要设置空闲作业检测的集群的 Cluster Name。 如果您想在集群中搜索空闲作业，请选中 Enable Idle Job Detection 复选框。 您可以选择为以下字段设置值： Email Notification Type (邮件通知类型) Minimum Runtime (最小运行时间) Floating Window (浮动窗口) CPU Time Threshold (CPU 时间阈值) Include Job Types (包含的作业类型) Job Commands (作业命令) Idle Jobs Exclude Queues (空闲作业排除队列) 点击 Save。配置空闲作业检测 (Grid 设置)步骤： 点击 Console 标签页。 在 Configuration 部分，点击 Grid Settings，然后转到 Idle jobs 标签页。 设置 Idle Job Detection 字段的值： Filter Name (过滤器名称): 提供过滤器名称以显示图例和作业异常。 Email Subject (邮件主题): 使用替换标签 &lt;JOBID&gt;, &lt;INDEXID&gt;, &lt;SUBMITTIME&gt;, &lt;CLUSTERNAME&gt;, &lt;USER&gt;, 和 &lt;CPUSECS&gt; 定义空闲作业邮件主题。 Email Message (邮件内容): 使用替换标签 &lt;JOBID&gt;, &lt;SUBMITTIME&gt;, &lt;CLUSTERNAME&gt;, &lt;USER&gt;, 和 &lt;CPUSECS&gt; 定义邮件内容。 Legend Background Color (图例背景颜色): 定义图例。如果颜色设置为 None，则禁用此功能。 点击 Save。配置内存违规检测关于此任务： 您可以配置作业的内存设置，以帮助您监控内存使用情况并灵活控制作业。步骤： 转到 Console &gt; Configuration &gt; RTM Settings。 转到 Memory Exceptions 标签页。 设置 Memory RUSAGE Violations 字段的值： Enable Memory RUSAGE Job Detection: 搜索内存违规作业。 Email Summary Reports: 接收邮件摘要报告通知的帐户。 Email Schedule: 接收邮件的通知频率。邮件在数据库维护期间每周日发送。 Memory Overusage Filter Name: 在作业详情图例中显示的内存过度使用过滤器名称。 Memory Overusage Allocation: 在标记作业之前，可接受的高于 RUSAGE 级别的内存使用百分比。 Memory Overusage Background Color: 图例颜色。如果颜色设置为 None，则禁用此功能。 Memory Underusage Filter Name: 在图例和作业异常过滤器显示中显示的内存使用不足过滤器名称。 Memory Underusage Allocation: 在标记作业之前，可接受的低于 RUSAGE 级别的内存使用百分比。 Memory Underusage Background Color: 图例和行显示的颜色。如果颜色设置为 None，则禁用此功能。 Minimum Run Window: 最小运行时间。 Minimum Memory Limit: 作业的最小内存限制。 Email Subject: 使用替换标签 &lt;OVERFILTER&gt;/&lt;UNDERFILTER&gt; 和 &lt;CLUSTERNAME&gt; 定义。 Email Message: 使用替换标签 &lt;CLUSTERNAME&gt;, &lt;OVERFILTER&gt;, &lt;OVERSHOOT&gt;, &lt;UNDERFILTER&gt;, &lt;UNDERSHOOT&gt;, 和 &lt;REPORTTABLE&gt; 定义。 点击 Save。添加或编辑 RTM 监控的 LSF 集群要添加或编辑 RTM 监控的 LSF 集群，需要按顺序执行以下操作： 添加或编辑集群。 将 RTM 主机作为 LSF 客户端添加到 LSF 集群。添加或编辑集群可以通过以下任一方法添加或编辑您希望 RTM 监控的任何 LSF 集群： 使用 RTM 控制台添加或编辑集群 使用脚本将集群添加到 RTM使用 RTM 控制台添加或编辑集群步骤： 点击 Console 标签页。 在 Grid Management 部分，点击 Clusters。 选择添加或编辑集群： 要添加 LSF 集群，点击 Add。 要编辑现有 LSF 集群，点击您想要编辑的集群的名称。 指定（或更新）描述您的 LSF 集群所需的字段。至少需要指定以下字段来添加 LSF 集群：Cluster Name, LSF Master LIM Hostname, LSF Master LIM Port, Grid Poller, 和 Primary LSF Administrator Username。 安装位置注意事项： 监控多个独立集群： 为获得最佳性能，请将 RTM 安装在 LSF 客户端主机上。但是，如果您打算监控多个独立集群并且您的 RTM 主机充当 LSF 服务器，请确保集群使用不同的 LIM 端口。 监控 LSF 多集群成员： 当监控 LSF 多集群环境中的两个或多个成员时，必须将 RTM 安装在多集群内任何成员的 LSF 客户端主机上。 对于 Grid Poller 字段，选择适合您的 LSF 集群版本的轮询器。此版本允许选择 Poller for LSF 8。 点击 Create (或 Save) 来保存您的 LSF 集群设置。后续操作： 如果您编辑了已在 RTM 控制台中的 LSF 集群，则无需执行其他操作。 如果您向 RTM 控制台添加了 LSF 集群，则必须按照“将 RTM 主机作为 LSF 客户端添加到 LSF 集群”中的说明将 RTM 主机添加到 LSF 集群。使用脚本将集群添加到 RTM关于此任务： 使用 grid_add_cluster.php 脚本将 LSF 集群添加到 RTM。步骤： 从命令行转到 Cacti 安装目录的 plugins/grid 子目录。 使用 php 运行 grid_add_cluster.php 脚本： php -q grid_add_cluster.php --type=0 --pollerid=lsf_type --cluster_name=cluster_name_text --cluster_env=lsf_envdir_path 其中： lsf_type: 代表集群中运行的 LSF 版本的整数 Poller ID。注意： Poller ID 不一定按顺序排列。最好使用 RTM 控制台 (Console &gt; Clusters &gt; Pollers) 来识别您要使用的 Poller ID。 cluster_name_text: 集群的名称。 lsf_envdir_path: LSF 集群的 lsf.conf 文件路径。 示例： 添加一个名为 maincluster 的 LSF 10.1 集群，其 lsf.conf 在 /share/lsf/conf，Poller ID 为 9： php -q grid_add_cluster.php --type=0 --pollerid=9 --cluster_name=maincluster --cluster_env=/share/lsf/conf 后续操作： 将 RTM 主机作为 LSF 客户端添加到 LSF 集群。 通过 RTM 控制台 (Clusters) 验证新集群已添加并处于“up”状态。将 RTM 主机作为 LSF 客户端添加到 LSF 集群关于此任务： 对于 RTM 监控的任何 LSF 集群，您必须将 RTM 主机作为 LSF 客户端添加到该集群，以便 RTM 访问 LSF 集群数据。步骤： 登录到 LSF 管理主机。 如果 LSF 管理主机无法将 RTM 主机名解析为 IP 地址，请编辑 /etc/hosts 文件并添加 RTM 主机的 IP 地址和主机名。（如果能成功 ping 通 RTM 主机名，则跳过此步）。 编辑 lsf.cluster.&lt;cluster_name&gt; 文件，并将 RTM 主机添加到 Host 部分。（如果配置了浮动客户端，则无需添加 RTM 主机）。 重新配置 LIM 并重启 mbatchd 以应用更改： lsadmin reconfigbadmin mbdrestart 测试 RTM 主机是否成功添加到 LSF 集群：a. 登录到 RTM 主机。b. 从 RTM 主机使用 telnet 登录到 LSF 管理主机的 LSF LIM 端口（LSF 8 及以上版本默认为 7869）。 bash telnet &lt;LSF_management_host_IP&gt; 7869 如果能连接到 LSF 管理主机的 IP 地址，则表示添加成功。结果： RTM 现在可以监控该 LSF 集群了。后续操作： 如果您希望 RTM 能够监控 LSF 集群中的所有单个主机，请将 LSF 集群中的所有主机添加到 RTM。Grid Heuristics (JobIQ)JobIQ 为 LSF 用户提供了一个可定制的视图，用于将其工作负载与 LSF 内部其他用户的工作负载进行比较。它还提供了 RTM 中包含的用户和集群范围数据的多个横截面视图。 功能： 显示您所有作业的信息，并将其与所有其他用户的作业进行比较。 提供关于您的作业运行时间是否比通常更长的洞察。 提供最近两天的作业历史记录视图。 允许直接控制您的作业（重新排队、终止、挂起等）。 按队列和项目确定所有作业的状态（运行、挂起、暂停）。 显示异常退出作业的退出原因。 筛选作业视图： 自定义视图，包括要显示的窗格和要查看的用户。 可以保存设置供下次使用。 RTM 管理员可以将 JobIQ 页面设置为用户的默认登录页面。 按常见问题筛选作业视图。 选择用户、集群和队列。 选择要在 JobIQ 仪表板中看到的视图和图表。 限制每个表中显示的信息行数（全部、5、10 或 20 条记录）。 选择视图刷新频率（1-5 分钟或从不）。 查看工作负载历史记录： 查看过去两天的工作负载历史记录。 Summary 视图创建 Current Status by Cluster (all Queues) 表，显示所有队列中的挂起、运行和暂停作业，以及每小时完成和退出的作业数、小时吞吐量和 5 分钟吞吐量。 查看跨多个集群的整体工作负载： Daily Throughput by Cluster 表显示当天和前一天完成和退出作业的总数。 Average TT Today 显示当天运行的所有作业的平均周转时间（从提交到完成的总分钟数）。 Current Status by Queue/Project 表显示： 每个队列的挂起作业数 / 排在您之前的挂起作业数（基于 LSF fairshare 动态优先级）。例如，670 / 230 表示您有 670 个挂起作业，而其他用户在同一队列中有 230 个作业排在您前面。 运行和暂停的作业数 / 其他用户在同一队列中的运行和暂停作业数。 小时吞吐量 (TPut(1Hr)) 和 5 分钟吞吐量 (TPut(5Min)) / 其他用户在同一队列中的吞吐量。 Estimate：根据运行时启发式（项目中作业运行时长的第 70 百分位）和吞吐量，估计您的作业何时预期完成。 “Stoplight graph” (红绿灯图) 显示多种警告类型（空闲作业、慢速作业、有依赖关系的作业、内存异常）的状态。 如果任何警告类别的红绿灯图显示非绿色状态，将鼠标悬停在图标上可查看完整状态。 点击状态图标可查看该作业的详细信息。 Idle Jobs (红色): 运行中的作业未使用任何 CPU 时间。 Long Jobs (红色): 作业超出了队列和项目中具有相同资源需求的作业的第 90 百分位。 Pend Dpnd (黄色): 作业有依赖关系；(红色): 有无效的作业依赖关系。 Mem Use (黄色): 作业使用的内存少于您保留的内存；(红色): 作业使用的内存远多于您保留的内存。 在 Current Status by Queue/Project 表中，点击队列或项目名称可在 Graphs 窗格中查看图表，总结选定时间段内的挂起、运行和完成作业。 General 窗格提供多个按队列的高级图表，总结选定时间段内的内存使用和作业吞吐量。 查看工作负载消耗的资源： 查看您的工作负载与其他用户相比所消耗的资源。 在 Current Status by Queue/Project 表中，点击挂起、运行或暂停的作业数量，可显示该状态下的作业列表。 在 Grid Heuristics &gt; View Job Listing 页面，按集群、队列、项目或作业状态筛选作业列表，并将表格导出为 .csv 文件进行进一步分析。 列表中显示每个作业的警告状态：空闲作业、慢速作业、有依赖关系的作业和内存异常。 点击作业列表中的作业 ID 可查看该作业的详细信息。 在作业详细信息视图中，使用 Job Graphs 查看作业资源使用情况的图表（内存消耗、CPU 时间、运行中的进程 ID (PID) 及其随时间的变化）。 Hosts Graphs 显示作业的各种基于主机的统计信息。 查看许可证使用情况： Feature Checkouts for User 表允许按用户检查许可证使用情况。 Grid Heuristics &gt; View Job Listing 页面也包含一列显示已签出的许可证。 按队列查看挂起原因： View Pending Reasons by Queue for User 表显示每个用户的挂起作业数量及其原因，以及挂起所花费的时间。 查看哪些作业有异常： 选择 Exit Analysis 以获取有关潜在问题作业的洞察。 Exit Analysis by Queue/Project 表显示过去一天内具有运行时、空闲或内存异常的作业。 可以深入查看以控制这些作业。 退出分析页面显示退出作业的数量和 LSF 退出原因。 控制您的作业： 在 Grid Heuristics &gt; View Job Listing 页面，使用 Choose an action 菜单控制列表中的任何作业。 在队列中向上或向下移动作业、将作业切换到另一个队列、强制作业立即运行（需相应权限）、挂起、恢复、终止、重新排队或发送信号给作业。 挂起原因 (Pending Reasons)您可以选择挂起原因级别来理解您的作业为何挂起。这是通过将挂起原因分类，然后仅显示顶级类别中的首要原因来实现的。 未分类挂起原因 (-p0): 获取集群中每个挂起作业的作业 ID、用户和挂起原因。 关键挂起原因 (-p1): 检索作业的关键挂起原因。如果关键挂起原因是基于主机的，则显示关键挂起原因和相应的主机数量。否则，仅显示关键挂起原因。（注意：如果没有除主要原因之外的主机原因，则主要原因将作为作业的关键挂起原因显示）。 候选主机挂起原因 (-p2): 更好地理解作业未运行的原因以及您可以采取的措施。bjobs -p2 选项显示集群中的总主机数和考虑的总数。对于考虑的主机，显示每个主机上的实际原因。对于每个挂起原因，显示给出该原因的主机数量。实际原因消息按从最常见到最不常见的顺序列出。基于主机的挂起原因分为候选主机原因和非候选主机原因，但使用此选项，您只会看到候选主机的原因。候选主机的原因可用于使作业运行。例如，对于原因“作业对保留资源 (mem) 的资源需求未满足”，用户可以选择减少作业的内存需求。查看 LSF 集群和作业信息点击 Grid 标签页，并参考左侧的 Grid 菜单栏来查看 LSF 集群和作业信息。 查看集群和主机健康摘要： 转到 Grid 菜单栏的 Dashboards 部分。 控制集群： 转到 Grid 菜单栏的 Management 部分（仅对具有 Cluster Control Management 领域权限的用户可用）。 查看 LSF 作业信息： 转到 Grid 菜单栏的 Job Info 部分。提供按主机、主机组、队列、作业数组、应用程序或组级别的 LSF 作业信息，以及特定作业的详细信息和挂起原因历史。 查看 LSF 用户和用户组信息： 转到 Grid 菜单栏的 User/Group Info 部分。 查看主机和主机组的负载信息： 转到 Grid 菜单栏的 Load Info 部分。 查看 LSF 主机和主机组信息： 转到 Grid 菜单栏的 Host Info 部分。 查看每日统计、FLEXlm 许可证使用和作业参数： 转到 Grid 菜单栏的 Reports 部分。可以筛选特定信息的统计和批处理系统参数。 配置 Grid 标签页设置： 点击 Grid 标签页，然后点击右侧的 Settings 标签页来配置 Grid 标签页中的项目。(有关 Dashboards, Job Info, User/Group Info, Load Info, Host Info, Reports 各部分的详细信息，请参考 PDF 原文第 76-85 页)查看集群和主机的时间序列图时间序列图呈现依赖于时间的集群状态和详细信息，时间是这些折线图的 X 轴。 查看方式： 树视图 (Tree view): 点击 Graphs 标签页，然后点击右侧的 Tree view 标签页。按设备和集群组织访问所有图表。点击根级别名称查看摘要信息，点击树部分查看主机特定信息。使用放大镜查看更详细的信息，使用扳手图标显示 RRD 工具收集的调试信息。 列表视图 (List view): 点击 Graphs 标签页，然后点击右侧的 List view 标签页。选择一个或多个集群名称，然后点击 View。 预览视图 (Preview): 点击 Graphs 标签页，然后点击右侧的 Preview 标签页。可以按主机筛选以限制显示的图表数量。 操作图标： 在查看数据行时，点击 View host job detail 或 View graphs 操作图标可查看特定行（如特定集群、主机或队列）的时间序列图。 配置图表显示设置： 点击 Graphs 标签页，然后点击右侧的 Settings 标签页。可以配置图表外观、默认页面设置、缩略图大小、树/预览/列表视图模式的默认设置以及字体。查看集群和主机的非时间序列图表非时间序列图表呈现不依赖于时间的集群和主机统计信息。由于统计信息不具有时间敏感性，RTM 可以使用图形丰富的格式（如饼图和条形图）来呈现这些数据。步骤： 点击 Cluster (或 Grid) 标签页。 在 Dashboards 部分，点击 Statistical。 在 Cluster Statistics 选择过滤器中，选择您希望以图表形式查看的数据类型。 如果图表旁边有 Selectable Reports 对话框，可以通过点击报告名称来选择不同的报告类型以查看不同的数据。为监控 LSF 集群或许可证服务创建图表RTM 提供了丰富的时序图，为集群和应用程序管理员及团队负责人提供对其环境运行情况的深入了解。RTM 中提供了许多开箱即用的图表，可用于深入了解作业处理方式和资源使用情况。步骤： 点击 Console 标签页。 在 Create 下，点击 New Graphs。 在 Host 字段中选择您的 LSF 或许可证服务器。 在 Graph Types 字段中选择图表类别以筛选可用图表类型。 在 Graph Templates 列底部的 Create 字段中，选择要为 LSF 或许可证服务创建的图表类型。后续操作： 可以通过点击 Console &gt; Management &gt; Graph Management，然后点击主机或图表的名称来编辑图表。 更多关于图表和图表模板的信息，请参考“图表和图表模板”文档。调整 RTM (Tuning RTM)高级用户可以修改 RTM 以满足其需求。 更新 grid_add_cluster.php: 如果您向主机模板添加了图表模板、为数据查询创建了新的图表模板或创建了新的数据查询，则必须更新 grid_add_cluster.php。 更改 Advocate 端口号: 如果默认的 8089 端口被其他应用程序硬编码使用，可以更改 Advocate 端口号。 在以下文件中搜索 8089 并更改端口号：/etc/init.d/advocate, /opt/advocate/advocate.init, /opt/advocate/command_advocate.py。 更新 Cacti 数据库：为 advocate_port 设置新端口号的值。 重启 Advocate 服务。 大型集群的性能调优将 RRD 文件存储在单独的磁盘上关于此任务： 为提高性能，将 RRD 文件存储在与数据库不同的单独磁盘上，并创建指向新位置的符号链接。步骤： 在单独的磁盘上创建目录，例如：mkdir /newDirectory。 将文件复制到新目录，例如：cp –p /opt/cacti/rra/* /newDirectory。 备份现有文件并创建符号链接，例如： mv /opt/cacti/rra /opt/cacti/rra.bakln –s /newDirectory /opt/cacti/rra 增加数据库内存关于此任务： 如果您看到数据库内存不足的错误（通常是数据库错误 1114），请增加分配给数据库的最大内存。步骤： 编辑 /etc/my.cnf 文件并增加 max_heap_table_size 的值。 重启 mysqld 服务：service mysqld restart。为磁盘 I/O 繁重的系统启用按需 RRD 文件更新关于此任务： 如果您遇到高磁盘 I/O 等待时间的问题，请启用按需 RRD 文件更新。启用后如果问题仍然存在，可以考虑使用 Spine（Cacti 的附加功能）。步骤： 转到 Console &gt; Configuration &gt; RTM Settings。 选择 Performance 标签页。 在 On Demand RRD Update Settings 部分，选中 Enable On Demand RRD Updating。 （可选）通过修改 How Often Should Boost Update All RRDs 和 Maximum Records 字段的值来更改 RRD 文件的更新频率。 点击 Save。配置并发轮询器进程步骤： 转到 Console &gt; Configuration &gt; RTM Settings。 点击 Poller 标签页。 在 General 部分，更改 Maximum Concurrent Poller Processes 的值。 点击 Save。启用数据库记录分区关于此任务： 数据库记录分区将较大的 LSF 作业数据表拆分为多个表，并在数据库维护操作期间加快处理速度。如果您每天有大量作业或希望延长保留作业摘要数据的时间，则需要分区。 调整分区大小，使其最多包含约 200 万条记录。调整分区大小时，请考虑主机为数据库提供的内存量（每个作业记录在数据库中占用 4 KB）。 您还可以指定每个分区使用的时间段。增加时间段意味着数据库包含更多用于整体分析的数据，但也会增加删除作业记录对系统的影响。步骤： 转到 Console &gt; Configuration &gt; RTM Settings。 选择 Maint 标签页。 在 Large System Settings 部分，选中 Enable Record Partitioning 复选框。 在 Partition Size 字段中指定时间段。 在 Maximum Partitions 字段中指定要在数据库中保留的最大分区数。当分区表数量达到此数目时，RTM 会在创建新分区表之前删除最旧的分区表。增加分区数量意味着数据库包含更多用于整体分析的数据，但也会增加数据库的大小。 点击 Save。配置数据收集频率关于此任务： 对于大型集群，更改数据收集频率。数据收集频率是为每个 LSF 集群配置的。 如果您在 cacti.log 文件中持续看到类似以下的错误，请降低数据收集频率： ERROR: Run-On/Abended Process Detected for ClusterName:'Large Cluster', ClusterID:'1', Process:'GRIDJOBS', PID:'19749', Attempting to Kill PID步骤： 转到 Console &gt; Clusters &gt; Clusters。 选择您要修改的 LSF 集群的名称。 点击 Poller 标签页。 您可以修改以下字段的值： 在 Queue/Host/Load Collection Settings 部分： Collection Frequency and Max Allowed Runtime 在 Job Collection Settings 部分： Minor Collection Frequency, Major Collection Frequency, and Max Allowed Runtime 点击 Save。增加 LSF API 超时值关于此任务： 如果您在 cacti.log 文件中看到指示 LSF API 超时的错误，请增加超时值。步骤： 转到 Console &gt; Clusters &gt; Clusters。 选择您要修改的 LSF 集群的名称。 点击 Advanced 标签页。 在 Cluster Connection Timeout Settings 部分，修改以下字段的值： Base Timeout Batch Timeout Batch Job Info Timeout Batch Job Info Retries 点击 Save。增强数据库性能关于此任务： 将 my.cnf 中的 innodb_flush_log_at_trx_commit 设置更改为 2，以每秒而不是每次查询提交时将数据库日志刷新到磁盘。此更改减少了随机磁盘 I/O 量，从而提高了 RTM 的可伸缩性。步骤： 编辑 /etc/my.cnf 文件并将 innodb_flush_log_at_trx_commit 的值更改为 2。 重启 mysqld 服务：service mysqld restart。维护数据库以下是您可以采取的维护或优化数据库的操作： 在数据库中设置记录分区 备份和恢复 RTM 系统设置在数据库中设置记录分区关于此任务： 在大型数据库中，删除旧的作业记录和其他数据库维护任务可能会对数据库性能产生显著影响。通过启用记录分区可以提高数据库性能。分区将数据库内的表划分为多个较小的表。从较小的表中删除作业记录对活动表的系统性能影响小于从较大的表中删除作业记录。 您可以为 RTM 监控的以下数据库表设置分区（所有以下表都会受到影响）： GRID_ARRAYS GRID_JOB_DAILY_STATS GRID_JOBS_FINISHED GRID_JOBS_MEMPERF GRID_JOBS_RUSAGE 步骤： 点击 Console 标签页。 在 Configuration 部分，点击 RTM Settings。 点击 Maint 标签页。 在 System Maintenance Settings 部分，您可以在 Database Maintenance Time 字段中指定时间，以指示何时必须从数据库中删除旧的数据库记录。所有分区数据始终根据您在该页面部分指定的保留期进行保留。 向下滚动到页面的 Large System Settings 部分，并确保设置了以下选项： Enable Record Partitioning: 选中此框以在数据库中启用记录分区。如果您每天有大量作业或希望延长保留作业摘要数据的时间，则需要分区。 Partition Size: 指定不同分区之间的时间。增加时间段意味着数据库包含更多用于整体分析的数据，但也会增加删除作业记录对系统的影响。 点击 Save 保存数据库记录分区设置。结果： 分区表具有数字后缀（_v000, _v001, … _vnnn）。最新的表具有最大的编号。备份和恢复 RTM 系统设置RTM 将系统和图表设置保存在 Cacti 数据库中。您可以使用 RTM 控制台备份 Cacti 数据库的操作，以便稍后恢复 RTM 系统。 用途： 如果您更改了 RTM 主机中的配置并希望恢复（例如，错误导入 Cacti 模板导致图表不再更新，或意外从 RTM 控制台删除了集群），可以恢复 RTM 系统和图表设置，并恢复到原始的备份设置。 恢复命令示例： mysql cacti &lt; backup/*.sql 限制： RTM 控制台无法恢复 RTM 监控的集群的所有作业性能数据。RTM 中任何此类数据都可能已过时。 如果要完全备份整个数据库，必须使用 mysqldump 命令。 如果经常使用 mysqldump 命令，则不能使用 MyISAM 表结构。 备份内容： lsfpollerd.conf: 包含凭据的数据库文件。 lsf.conf: 与每个集群关联的 lsf.conf 文件。 ego.conf (仅适用于 LSF 8.0 集群): 与每个集群关联的 ego.conf 文件。 server.key 和 server.crt: 用作 Advocate 的 httpd 认证文件。 除了以下大型表外，其它Cacti 数据库中的所有表都备份： GRID_ARRAYS, GRID_ARRAYS_FINISHED GRID_JOB_DAILY_STATS, GRID_JOB_INTERVAL_STATS GRID_JOBS, GRID_JOBS_FINISHED GRID_JOBS_JOBHOSTS, GRID_JOBS_JOBHOSTS_FINISHED GRID_JOBS_MEMPERF GRID_JOBS_PENDREASONS, GRID_JOBS_PENDREASONS_FINISHED GRID_JOBS_REQHOSTS, GRID_JOBS_REQHOSTS_FINISHED GRID_JOBS_RUSAGE LIC_DAILY_STATS, LIC_FLEXLM_LOG, LIC_INTERVAL_STATS, LIC_LUM_EVENTS POLLER_OUTPUT, POLLER_OUTPUT_BOOST SYSLOG, SYSLOG_REMOVED 操作： 使用 RTM 控制台备份 RTM 系统 启用自动数据归档 使用 RTM 控制台备份 RTM 系统关于此任务： 在升级到较新版本的 RTM 之前，必须首先备份现有的 Cacti 数据库。在计划的服务器维护期间备份 Cacti 数据库非常重要，您可以恢复到以前的 RTM 系统和图表设置。步骤： 转到 Console &gt; Configuration &gt; RTM Settings。 点击 Maint 标签页。 向下滚动到页面的 Database Backups 部分，并确保设置了以下选项： Backup Cacti Database: 选中此框以确保在运行维护脚本时备份 Cacti 数据库。 Backup Schedule: 指定备份计划为 Daily 或 Weekly。 Weekly Backup Day: 如果选择 Weekly 备份，请指定要进行备份的日期。 Backup Generations: 指定要维护的备份文件副本数。 Database Backup Location: 如果备份目录尚不存在，请提供位置。（如果目录存在，则在目录字段下方显示消息“[OK: DIR FOUND]”）。 Post Backup Command: 提供在 Cacti 数据库和计划备份完成后运行的备份后脚本。确保文件对 RTM 服务帐户既可执行又可读。 在 Utilities 部分，点击 RTM Utilities。 在 RTM Utilities 页面的 Database Administration 部分，点击 Force Cacti Backup。页面底部的 Backup Files 表将更新，显示新创建的备份文件、修改日期和文件大小。 点击备份文件名将其下载到指定位置。 下载完成后，验证 .tgz 文件包含必要的 SQL 文件、配置文件 (rtm.lic, lsfpollerd.conf, server.crt, server.key) 以及每个集群的 lsf.conf 和 ego.conf（如果适用）。启用自动数据归档关于此任务： 启用数据归档可在计划的服务器维护期间将现有的作业和作业相关数据保存到归档数据库。步骤： 点击 Console 标签页。 在 Configuration 部分，点击 RTM Settings。 点击 Archiving 标签页。 要启用现有作业和作业相关数据的归档，请选中 Enable Data Archiving 复选框并指定数据归档设置。 点击 Save 保存数据归档设置。手动备份或恢复 RTM 数据库 (旧版本)对于较旧版本的 RTM，您可能需要手动备份数据库。步骤包括：备份网站、备份数据库、备份 RTM 轮询器，然后升级 Cacti 网站和 Grid 插件、升级数据库、升级 RTM 轮询器。 备份网站： 备份 Cacti 目录，通常排除日志和 rra 目录。需要备份 include/global.php（包含数据库连接和插件列表）。如果修改了默认 RTM 轮询器脚本或数据查询，则分别备份 scripts 和 resource 目录。 备份数据库： RTM 提供 database_backup.php 工具备份数据库模式和重要的 Cacti/RTM 配置表，但不包括大型作业历史表。在 Console &gt; Configuration &gt; RTM Settings &gt; Maint 指定备份位置后，运行 php -q database_backup.php。 备份 RTM 轮询器： 备份 RTM 轮询器目录（例如 /opt/rtm 或 /usr/local/grid 下的 bin, lic, lsf* 目录）。 升级 Cacti 网站和 Grid 插件： 注意文件所有权（通常是 cacti:cacti）。将升级包中的 cacti 目录复制到目标位置，并确保 config.php 文件不变。 升级数据库： 运行 php -q database_upgrade.php 来更新数据库模式以适应新功能。 升级 RTM 轮询器： 验证文件权限。将升级包中的 poller 目录复制到轮询器安装位置并设置正确的所有权。设置远程数据库主机前提条件： 数据库服务器端口（默认为 3306）在防火墙上已打开。 目标数据库主机满足以下要求： 运行受支持的操作系统。 至少 4 GB RAM 和 40 GB 硬盘空间。 已安装数据库。 数据库主机名和 RTM 主机名可以相互解析。 关于此任务： 默认情况下，RTM 主机充当数据库主机。您可以选择将数据库设置在另一台主机上，以分散 RTM 活动或使用更优化的数据库主机。 重要提示： 请在 RTM 安装的初始设置期间执行这些步骤。如果在 RTM 运行一段时间后执行这些步骤，数据库传输到另一台主机可能需要相当长的时间，在此期间数据库将停机。步骤： 手动备份现有 RTM 数据库： 使用 RTM 控制台备份 (Console &gt; Configuration &gt; RTM Settings &gt; Maint 和 Console &gt; Utilities &gt; RTM Utilities &gt; Force Cacti Backup)。 准备 RTM 主机进行数据库转换： a. 登录 RTM 主机。 b. 停止所有基本服务：lsfpollerd, licpollerd, crond，并禁用 mysqld 服务。 c. 创建 SQL 数据库内存转储： ```sqlmysqldump cacti &gt; cactidump.sqlmysqldump mysql time_zone_name &gt; timezone.sql``` ​ 记录当前目录，以便将 SQL 转储文件复制到新的数据库主机。 d. 修改 RTM 配置文件以引用新的数据库主机。在以下文件中，将 localhost 更改为新的数据库主机名，或将 127.0.0.1 更改为新的数据库 IP 地址： /RTM_TOP/cacti/include/config.php/RTM_TOP/rtm/lsf&lt;version_number&gt;/bin/grid.conf/RTM_TOP/rtm/etc/lsfpollerd.conf/etc/rsyslog.conf/RTM_TOP/cacti/plugins/syslog/config.php/RTM_TOP/rtm/etc/lic.conf e. 更新 RTM 管理主机上的 ODBC 配置文件 (/etc/odbc.ini)，指定新的远程数据库服务器信息（Server, Database, UID, PASSWORD, Port 等）。使用 odbcinst -j 查找文件位置。 设置新的数据库主机 a. 登录新的数据库主机。 b. 安装并启动数据库服务（例如 MySQL/MariaDB）。 c. 创建新的 RTM 数据库：mysqladmin -u root create cacti。 d. 分配适当的数据库权限，允许 RTM 主机连接： ```sqlGRANT ALL ON cacti.* TO cacti@&lt;rtm_host_ip&gt; IDENTIFIED BY 'admin';GRANT SELECT ON mysql.time_zone_name TO cacti@&lt;rtm_host_ip&gt; IDENTIFIED BY 'admin';``` e. 备份原始 my.cnf，并将 RTM 主机 &lt;RTM_TOP&gt;/rtm/share 中的 my.cnf.*.innodb 文件复制到新数据库主机的 /etc 目录下。 f. 将 SQL 数据库转储文件从 RTM 主机复制到新的数据库主机。 g. 将 SQL 数据库转储文件导入新数据库： ```bashmysql cacti &lt; /tmp/cactidump.sqlmysql mysql &lt; /tmp/timezone.sql``` h. 重启数据库服务。 重启服务并验证： a. 登录 RTM 主机。 b. 重启基本服务：crond, rsyslog, lsfpollerd, licpollerd。 c. 验证数据库设置是否正确，检查 lsfpollerd 和 licpollerd 的状态。如果它们正在运行，则数据库设置正确。 " }, { "title": "网页总是显示旧内容，无法加载到新内容", "url": "/posts/purge-web-cache/", "categories": "icenv", "tags": "web", "date": "2025-04-11 16:00:00 +0000", "snippet": "问题Chrome浏览器，用“正常模式” vs. “隐私模式”打开同一个url网页，可以看到“正常模式”缺少了最新发布的内容。怀疑是缓存问题导致，于是将网络断开并刷新。发现“正常模式”打开的依然有内容，因此可以判断是缓存导致。分析Disable Cache在开发者模式下，勾选Disable cache并刷新，依然有内容提供。Unregister Service Worker在开发者模式下，点开...", "content": "问题Chrome浏览器，用“正常模式” vs. “隐私模式”打开同一个url网页，可以看到“正常模式”缺少了最新发布的内容。怀疑是缓存问题导致，于是将网络断开并刷新。发现“正常模式”打开的依然有内容，因此可以判断是缓存导致。分析Disable Cache在开发者模式下，勾选Disable cache并刷新，依然有内容提供。Unregister Service Worker在开发者模式下，点开Application，勾选 Update on reload Bypass for network然后点击Unregister，显示成功删除，再刷新网页即可查看到最新内容。总结Service Worker 是一种运行在浏览器背后的、与网页分离的 独立线程，它赋予 Web 应用一些原本只有原生应用才能做到的功能，比如：一、主要用途1. 离线访问能力（离线缓存） Service Worker 可以拦截并缓存网页请求，使用户即使断网，也能访问之前缓存的内容。 常用于 PWA（Progressive Web App）中，实现“断网可用”。2. 网络请求拦截与控制（代理作用） 可拦截页面发出的 HTTP 请求（fetch 请求），决定是否从缓存、网络或自定义方式返回响应。 允许你做“按需更新”、“缓存优先”、“网络优先”等策略。3. 后台推送（Push Notification） 支持 Web Push Notification，即便页面未打开，仍可接收服务器推送的消息（前提是用户授权）。4. 后台同步（Background Sync） 当用户在离线状态进行操作（如发送消息、填写表单），可在重新联网后自动同步数据。5. 性能优化 减少对服务器的依赖（如图片、本地 JS/CSS 静态资源可缓存），提升访问速度。二、工作机制概览+--------------------+ +---------------------------+| 页面（UI） | &lt;----&gt; | Service Worker（线程） |+--------------------+ +---------------------------+ | |（网络请求） v +-----------------+ | 网络或缓存响应 | +-----------------+ 生命周期管理： Service Worker 需显式注册和激活； 作用域隔离： 一个 Service Worker 只能控制注册它的路径范围内的页面； 异步编程模型： 使用 Promise 和事件监听机制（如 fetch、install、activate）。三、典型应用示意以离线网页为例：// 简化版本self.addEventListener('install', (event) =&gt; { event.waitUntil( caches.open('v1').then(cache =&gt; cache.addAll(['/index.html', '/styles.css', '/logo.png']) ) );});self.addEventListener('fetch', (event) =&gt; { event.respondWith( caches.match(event.request).then(response =&gt; response || fetch(event.request) ) );});这段代码做了什么？ 第一次加载时缓存核心资源； 后续访问时，若找不到网络，就从缓存返回资源，实现“断网可用”。四、Service Worker 与浏览器缓存的区别 特性 浏览器 HTTP 缓存 Service Worker 控制粒度 HTTP 响应头控制 JS 脚本可控，策略灵活 离线访问支持 受限（取决于缓存规则） 完整支持 是否可拦截请求 否 是（fetch 拦截） 生命周期控制 无，自动过期 有，需安装、激活、更新 是否支持推送通知 否 是（结合 Push API） 五、为什么要谨慎使用或管理 Service Worker？ 缓存更新不及时可能导致“内容旧、打不开、卡页面”； 开发调试时容易被缓存干扰； 安全性要求高（只能在 HTTPS 下运行）； 对调试者来说，如果不熟悉其行为，会导致“断网还能访问网页”的错觉。如果在部署自己的网站时启用了 PWA 或类似离线缓存功能，也建议设计好缓存更新策略（如 stale-while-revalidate 或 version-based cache busting），避免用户加载旧内容。" }, { "title": "ChatGPT improve memory", "url": "/posts/chatgpr-improve-memory/", "categories": "icenv", "tags": "gpt", "date": "2025-04-10 16:00:00 +0000", "snippet": "", "content": "" }, { "title": "SVN Directory rename failed", "url": "/posts/svn-directory-rename-failed/", "categories": "icenv", "tags": "svn", "date": "2025-04-07 16:00:00 +0000", "snippet": "如上图所示，在Repo-browser里修改好，然后在本地update就可以了。", "content": "如上图所示，在Repo-browser里修改好，然后在本地update就可以了。" }, { "title": "VSCode Agent Mode is Rolling Out to All VS Code Users", "url": "/posts/vscode-agent-mode/", "categories": "icenv", "tags": "ai", "date": "2025-04-06 16:00:00 +0000", "snippet": "作为一名开发者，我最近在 Visual Studio Code（VSCode）中体验了 GitHub Copilot 的 Agent 模式，收获颇丰。启用 Agent 模式首先，我确保使用的是 VSCode Insiders 版本，并安装了 GitHub Copilot Chat 的预发布扩展。在设置中，我启用了 Copilot 的 Agent 模式。使用体验在实际使用中，Agent 模式表...", "content": "作为一名开发者，我最近在 Visual Studio Code（VSCode）中体验了 GitHub Copilot 的 Agent 模式，收获颇丰。启用 Agent 模式首先，我确保使用的是 VSCode Insiders 版本，并安装了 GitHub Copilot Chat 的预发布扩展。在设置中，我启用了 Copilot 的 Agent 模式。使用体验在实际使用中，Agent 模式表现出色。它能够根据我的指令执行多步骤的编码任务，例如分析代码库、阅读相关文件、提出修改建议、执行终端命令和运行测试。这一过程中，Agent 模式会响应编译和 lint 错误，监控终端和测试输出，并在循环中自动修正，直到任务完成。我尝试了让 Agent 模式在多个文件之间进行重构，并生成单元测试。它能够自主确定与任务相关的上下文和需要编辑的文件，提出代码修改和终端命令，并监控输出的正确性，循环迭代直到任务完成。这种自主性大大提高了我的编码效率。注意事项在使用过程中，我发现对于大型代码库，Agent 模式可能需要更多时间来处理复杂任务。因此，建议将大型任务拆分为较小的子任务，逐一处理，以获得更好的效果。总的来说，GitHub Copilot 的 Agent 模式为我的开发过程带来了显著的提升。它不仅能够自动化处理复杂的编码任务，还能根据上下文提供智能建议，极大地节省了我的时间和精力。我期待未来它能在更多场景中发挥作用。" }, { "title": "Using GitHub Public Repo to Store Images", "url": "/posts/using-github-public-repo-to-store-images/", "categories": "icenv", "tags": "analog", "date": "2025-04-06 16:00:00 +0000", "snippet": "使用GitHub公共仓库存储图片在这篇文章，我们将介绍如何使用GitHub公共仓库来存储图片，配合Typora等编辑器使用，方便在写作时直接插入图片。1. 创建GitHub仓库首先，我们需要创建一个GitHub公共仓库，您可以按照以下步骤操作： 登录GitHub账号。 点击右上角的 + 按钮，选择 New repository 创建一个新的仓库。 仓库名称可以随意设置，确保选中 Pub...", "content": "使用GitHub公共仓库存储图片在这篇文章，我们将介绍如何使用GitHub公共仓库来存储图片，配合Typora等编辑器使用，方便在写作时直接插入图片。1. 创建GitHub仓库首先，我们需要创建一个GitHub公共仓库，您可以按照以下步骤操作： 登录GitHub账号。 点击右上角的 + 按钮，选择 New repository 创建一个新的仓库。 仓库名称可以随意设置，确保选中 Public 选项。 创建完成后，您将看到该仓库的主页。2. 创建GitHub Token为了安全地与GitHub进行交互，我们需要创建一个GitHub Token。请按照以下步骤进行操作： 点击右上角的头像，选择 Settings。 在左侧菜单中，点击 Developer settings。 选择 Personal access tokens，然后点击 Fine-grained tokens。 点击 Generate new token 按钮，按照提示填写。 选择 repo 权限，启用 Contents 的读写权限。 配置完成后，点击 Generate token。 复制生成的 token，因为这是唯一一次展示 token 内容，后续无法再查看。3. 配置Typora接下来，我们需要在Typora中进行配置，以便将图片上传到GitHub仓库。以 Windows 平台为例，如上所示， 打开Typora，点击右上角的 Preferences，进入设置页面。 选择 图片上传 相关设置，设置如下：{ \"picBed\": { \"github\": { \"repo\": \"icinfra/icinfra-artifacts\", // 替换为您的GitHub仓库名 \"token\": \"your_token_here\", // 将这里的your_token_here替换为您刚刚生成的token \"path\": \"img/\", // 图片上传至仓库中的路径 \"customUrl\": \"\", // 可选：设置自定义URL，通常留空 \"branch\": \"master\" // 选择主分支（master）或其他分支 }, \"current\": \"github\", \"uploader\": \"github\" }, \"picgoPlugins\": {}} 粘贴生成的token到 \"token\": \"\" 的位置。如果是Mac用户，则可以npm install -g picgovi ~/.picgo/config.json完成这些步骤后，您的Typora就会配置好，可以直接将图片上传到GitHub。4. 使用方法配置完成后，您可以开始在Typora中编辑文章了。当您需要插入图片时，只需按照以下步骤： 在Typora编辑器中插入图片。 在弹出的提示框中，点击 上传图片 按钮。这时，图片将会被自动上传到GitHub仓库，上传成功后，Typora会自动将图片链接插入到您的文章中。小结通过以上步骤，您就可以轻松地将图片存储在GitHub公共仓库中，并在Typora等编辑器中直接引用。这样的做法不仅能保持文档的整洁，还能方便地进行版本控制和管理图片资源。如果您有任何问题或需要进一步的帮助，请随时与我联系。" }, { "title": "Using Hspice Model with Spectre", "url": "/posts/using-hspice-model-with-spectre/", "categories": "icenv", "tags": "analog", "date": "2025-04-02 16:00:00 +0000", "snippet": "[经验分享] 如何在 Cadence Spectre 中使用 HSPICE 模型（含 spp 工具转换方法）大家好，今天分享一下在 Cadence Spectre 中使用 HSPICE 模型的一些方法，供有需要的朋友参考。✅ 方法一：Spectre v7 及以上版本 – 直接仿真从 Spectre v7 起，Cadence 已经支持直接仿真 HSPICE 网表。使用方式非常简单：spectr...", "content": "[经验分享] 如何在 Cadence Spectre 中使用 HSPICE 模型（含 spp 工具转换方法）大家好，今天分享一下在 Cadence Spectre 中使用 HSPICE 模型的一些方法，供有需要的朋友参考。✅ 方法一：Spectre v7 及以上版本 – 直接仿真从 Spectre v7 起，Cadence 已经支持直接仿真 HSPICE 网表。使用方式非常简单：spectre your_netlist.sp无需修改 .sp 网表内容，Spectre 会自动识别并执行，非常方便。✅ 方法二：Spectre v5 用户 – 使用 spp 工具转换模型对于使用较早版本（如 v5）的 Spectre 用户，仍可以通过 Cadence 提供的 spp 工具将 HSPICE 模型转换为 Spectre 可识别的格式。🔧 转换步骤如下： 屏幕显示转换结果： spp -convert &lt; bjt.lib 将结果保存为 Spectre 格式文件： spp -convert &lt; bjt.lib &gt; bjt.scs 转换后生成的 bjt.scs 文件就是可供 Spectre 使用的模型库文件。⚠️ 注意事项： spp 转换后生成的 .scs 文件中，模型引用的文件名可能需要根据实际路径手动调整。 并非所有 HSPICE 模型都能完美转换，遇到错误需根据 log 做相应修改。如有其他经验或疑问，欢迎留言讨论！参考文档https://bbs.eetop.cn/thread-297147-1-1.html" }, { "title": "OnePackage 介绍", "url": "/posts/onepackage-unified-linux-package-manager/", "categories": "icenv", "tags": "os", "date": "2025-04-02 00:00:00 +0000", "snippet": "在近期的开源社区中，OnePackage 作为一种全新的软件包管理系统引起了广泛关注。该系统旨在融合现有包管理工具的优势，提供统一且高效的解决方案。OnePackage 的核心目标： 融合优势： OnePackage 旨在结合 Flatpak 的安全性、Snap 的集中管理以及 AppImage 的可移植性，避免了社区中关于这些工具的争议。 解决系统膨胀问题： 通...", "content": "在近期的开源社区中，OnePackage 作为一种全新的软件包管理系统引起了广泛关注。该系统旨在融合现有包管理工具的优势，提供统一且高效的解决方案。OnePackage 的核心目标： 融合优势： OnePackage 旨在结合 Flatpak 的安全性、Snap 的集中管理以及 AppImage 的可移植性，避免了社区中关于这些工具的争议。 解决系统膨胀问题： 通过实施名为“真正删除不再需要的东西”的技术，OnePackage 计划有效清理系统中不再使用的包和依赖，解决长期困扰用户的系统膨胀问题。 包管理系统的现状与挑战：当前，Linux 发行版采用多种包管理系统，例如： Ubuntu： 使用 DEB 格式，由 dpkg 和 APT 管理。 RHEL 系列： 采用 RPM 格式，由 RPM 包管理器管理。 其他格式： 如 Snap、Flatpak、AppImage 等，共计约 17 种不同的包格式。 这些多样化的包管理系统虽然各有特色，但也给用户和开发者带来了管理上的复杂性。OnePackage 的出现，旨在统一这些格式，简化软件的分发和管理流程。OnePackage 的潜在影响：如果 OnePackage 能成功实现其目标，将对 Linux 生态系统产生深远影响： 简化管理： 用户和开发者无需在多种包管理系统之间切换，降低学习成本。 优化资源占用： 通过清理不再使用的包和依赖，释放系统资源，提升性能。 促进生态融合： 统一的包管理系统有助于不同发行版和工具之间的协同，推动开源社区的共同发展。 总体而言，OnePackage 的推出为解决现有包管理系统的碎片化问题提供了新的思路。随着开发者社区的持续努力和反馈，OnePackage 有望在未来的 Linux 发行版中发挥重要作用。" }, { "title": "Install IBM Spectrum LSF RTM on CentOS 7.9", "url": "/posts/rtm-installation/", "categories": "icenv", "tags": "rtm", "date": "2025-03-28 13:00:00 +0000", "snippet": "引言IBM Spectrum LSF 实时监控（RTM）是一个监控工具，它为计算环境中的工作负载报告和管理提供了一个仪表板。本指南概述了在 CentOS 7.9 系统上安装 IBM Spectrum LSF RTM 的步骤。前提条件 确保系统满足 RTM 版本所需的系统规格。 获得安装的系统上管理员权限。安装步骤准备系统验证您的系统满足软件依赖性和系统要求。本文以CentOS 7.9作为...", "content": "引言IBM Spectrum LSF 实时监控（RTM）是一个监控工具，它为计算环境中的工作负载报告和管理提供了一个仪表板。本指南概述了在 CentOS 7.9 系统上安装 IBM Spectrum LSF RTM 的步骤。前提条件 确保系统满足 RTM 版本所需的系统规格。 获得安装的系统上管理员权限。安装步骤准备系统验证您的系统满足软件依赖性和系统要求。本文以CentOS 7.9作为实验环境。安装所有必需的软件包，包括 PHP、Cacti 和如 MariaDB 数据库系统的特定版本。yum install bash chkconfig chrony coreutils gd httpd initscripts libnsl mariadb mariadb-connector-odbc mariadb-server mod_ssl perl php php-common php-gd php-json php-ldap php-mbstring php-mysqlnd php-process php-xml python3-pexpect python3-pyOpenSSL rrdtool rsyslog rsyslog-mysql shadow-utils unixODBC下载安装包从 IBM Passport Advantage 网站下载 IBM Spectrum LSF RTM 安装包。[root@icinfra-cn-172-16-0-118-lsf-rtm rtm]# ls -1 rtm*tar.gzrtm-server-10.2.0-rhel7-x64.tar.gzrtm-poller-10.2.0-rhel7-x64.tar.gz确保您下载的版本与操作系统的架构相匹配。rpm -e --allmatches --nodeps unixODBC mysql-connector-odbcyum install unixODBC.x86_64 mysql-connector-odbc解压安装包使用 tar 或类似工具将安装包解压到指定目录。systemctl stop mariadbrm -f /var/lib/mysql/ib_logfile* mkdir -p /mnt/rtmcd /mnt/rtmtar zxf rtm-server-10.2.0-rhel(ver)-x64.tar.gz运行安装脚本导航到文件解压的目录。cd /mnt/rtmcat &gt; install.config &lt;&lt; EOFRTM_TOP=/opt/IBMRTM_PACKAGEDIR=./NON_GPGCHECK='Y'DAEMON_USER='apache'DAEMON_GROUP='apache'LSF_CLUSTERS=1010:7869:N:icinfra-cn-cluster-01@icinfra-cn-172-16-0-116-lsf-master-01EOFsh rtm_install.sh -f install.config其中，LSF_CLUSTERS 请按照实际情况填写，如集群名字与master名字。验证安装通过网页浏览器访问 http:// ，默认账号密码均为 admin/admin。首先会提示修改admin密码。这里，可能查看到Diminished状态，如图所示可能的原因有多个，如， https://www.ibm.com/support/pages/cluster-collect-status-down-or-diminished or, https://www.ibm.com/support/pages/collect-status-diminished-lsf-cluster-ibm-platform-rtm or, https://www.ibm.com/support/pages/lsf-cluster-status-shows-diminished-rtm-after-running-fine-while or,RTM host未以client身份加入到被监控集群。则应将RTM host以client身份加入被监控集群，并reconfigure集群。验证 RTM 是否与您的 LSF 集群有效通信并显示实时数据。管理密码重置To reset your Platform RTM password, you can:Find your Platform RTM user name using the commandmysql -u root cacti -e \"SELECT * FROM user_auth\"Update the password for the Platform RTM user using the commandmysql -u root cacti -e \"UPDATE user_auth SET password=md5('&lt;password you choose&gt;') WHERE id='&lt;id got in step 1&gt;'\"Commit the change to the Platform RTM database using the commandmysql -u root cacti -e \"COMMIT\"" }, { "title": "ETX 自动化安装", "url": "/posts/etx-automation/", "categories": "icenv", "tags": "etx", "date": "2025-03-09 04:00:00 +0000", "snippet": "1. 系统环境配置首先，我们需要准备好对应的主机，并在 inventory.ini 文件中定义各主机的详细信息。inventory 配置[centos_hosts]centos110 ansible_host=172.31.0.110centos112 ansible_host=172.31.0.112[rocky_hosts]rocky120 ansible_host=172.31.0.1...", "content": "1. 系统环境配置首先，我们需要准备好对应的主机，并在 inventory.ini 文件中定义各主机的详细信息。inventory 配置[centos_hosts]centos110 ansible_host=172.31.0.110centos112 ansible_host=172.31.0.112[rocky_hosts]rocky120 ansible_host=172.31.0.120rocky121 ansible_host=172.31.0.121rocky122 ansible_host=172.31.0.122rocky130 ansible_host=172.31.0.130rocky132 ansible_host=172.31.0.132[etx_servers]rocky130rocky120rocky121centos110[etx_nodes]centos112rocky122rocky1322. 项目目录结构以下是本项目的目录结构，包含了必要的配置文件和脚本文件。[root@rockylinux-9-5-mgmt ansible-std]# tree -L 2.├── ansible.cfg├── galaxy.yml├── group_vars│ ├── etx_nodes.yml│ └── etx_servers.yml├── inventory.ini├── playbooks│ ├── deploy_etxcn.yml│ ├── deploy_etxsvr.yml├── roles│ ├── etxcn_deployment│ ├── etxcn_purge_error_nodes│ ├── etxsvr_api_key│ ├── etxsvr_deployment│ ├── join_ad│ ├── linux_prep│ └── mount_iso└── vault.yml3. ETX 服务器安装3.1 执行安装通过 Ansible 自动化工具，执行 deploy_etxsvr.yml 脚本进行 ETX 服务器安装。确保在运行时提供正确的密码。ansible-playbook -i inventory.ini playbooks/deploy_etxsvr.yml --ask-pass安装过程中，系统会提示输入 SSH 密码。SSH password: 3.2 接受 EULA安装完成后，访问 ETX 服务器的管理后台，使用浏览器访问各 ETX 服务器的 URL，点击同意 EULA（例如，对于第一台服务器，访问 https://172.31.0.130:8443/etx/admin）。3.3 配置安装过程中，以下配置项需要手动完成： License：根据环境需求进行配置。 Authentication：配置适当的认证方式。 Profile：创建和配置用户 Profile。4. ETXCN 安装4.1 执行安装同样使用 Ansible 脚本来部署 ETXCN，执行以下命令：ansible-playbook -i inventory.ini playbooks/deploy_etxcn.yml --ask-pass --ask-vault-pass此时，会要求输入 SSH 密码以及 Vault 密码：SSH password: Vault password: 4.2 配置客户端安装完成ETXCN后，用户可以使用加入的域账户通过 Profile 接入到 ETX 系统中。5. 其他配置与调整根据安装环境的不同，可能需要对各主机进行一些额外的调整，例如： 设置系统的防火墙规则 配置网络策略 更新系统软件包 调整性能优化参数6. 总结通过本教程，您已经完成了 ETX 服务器和客户端的安装与配置，后续可以根据具体需求进行系统的进一步优化与调整。" }, { "title": "脚本计时", "url": "/posts/script-elapsed-time/", "categories": "icenv", "tags": "script", "date": "2025-01-22 16:00:00 +0000", "snippet": "脚本实现#!/bin/csh # 信息：wanlin.wang, 2025/01/23# 用法：在需要计时的业务脚本末尾加一行，source 本脚本。运行完毕业务脚本后，会打印该脚本运行的elapsed time。 set pid = $$ set system_boot_time = `awk '/^btime / {print $2}' /proc/stat`set proc_start...", "content": "脚本实现#!/bin/csh # 信息：wanlin.wang, 2025/01/23# 用法：在需要计时的业务脚本末尾加一行，source 本脚本。运行完毕业务脚本后，会打印该脚本运行的elapsed time。 set pid = $$ set system_boot_time = `awk '/^btime / {print $2}' /proc/stat`set proc_start_time_ticks = `awk '{print $22}' /proc/$pid/stat`set clock_ticks_per_sec = `getconf CLK_TCK` @ proc_start_time_secs = $proc_start_time_ticks / $clock_ticks_per_sec@ start_time = $system_boot_time + $proc_start_time_secs set start_time_human = `date -d @$start_time`set end_time_human = `date`set end_time = `date +%s` @ elapsed_time = $end_time - $start_time@ days = $elapsed_time / 86400@ hours = ($elapsed_time % 86400) / 3600@ minutes = ($elapsed_time % 3600) / 60@ seconds = $elapsed_time % 60 echo \"\"echo \"Summary for PID ${pid}:\"echo \"Start time: $start_time_human\"echo \"End time: $end_time_human\"echo \"Elapsed time: ${days} days, ${hours} hours, ${minutes} minutes, ${seconds} seconds\"关键分析proc_start_time_ticks是从 Linux 系统启动（boot）那一刻起，到特定进程启动时所经过的“滴答数”（ticks）。这个值可以在 /proc/[pid]/stat 文件中找到，通常是第 22 个字段。技术原理：内核时钟中断 (Timer Interrupts): Linux 内核通过一个硬件定时器周期性地产生中断，这被称为“时钟中断”或“定时器中断”。这些中断是内核进行时间管理、任务调度等操作的基础。Jiffies: 在 Linux 内核内部，有一个全局变量叫做 jiffies（或者在 64 位系统上是 jiffies_64）。这个变量在系统启动时被初始化为 0，并且每发生一次时钟中断，jiffies 的值就会加 1。因此，jiffies 实际上是系统自启动以来所经历的时钟滴答的总数。它被称为内核的“心跳”。进程的 starttime: 当一个新进程在 Linux 上启动时，内核会记录下它启动时的 jiffies 值。这个值被存储在进程的 task_struct 结构体中（通常是 real_start_time 或类似字段）。当用户空间程序读取 /proc/[pid]/stat 文件时，内核会从这个 task_struct 结构体中提取相应的值并格式化输出。单位转换: 历史上，starttime 字段直接以 jiffies 为单位。然而，自 Linux 2.6 版本以来，为了提供更统一和可移植的时间单位，starttime 字段的值通常以 clock ticks 为单位，这里的 clock ticks 与 sysconf(_SC_CLK_TCK) (即 CLK_TCK) 返回的值相关联，而不是直接的内核 HZ。这意味着，为了将其转换为秒，需要除以 CLK_TCK，而不是直接除以内核的 HZ 值。这使得用户空间程序更容易进行时间转换。总结： proc_start_time_ticks 实际上是内核记录的特定进程在系统启动后，经过了多少个“时钟滴答”才开始运行。它是一个相对值，需要结合系统启动的 epoch 时间和滴答频率来计算出进程的绝对启动时间（epoch time）。clock_ticks_per_sec通过 getconf CLK_TCK 命令获取，它返回的是一个系统配置值，表示每秒钟有多少个“时钟滴答”。在 POSIX 标准中，这被称为 _SC_CLK_TCK。技术原理：用户空间和内核空间时间单位的桥梁: 虽然 Linux 内核有其内部的 HZ（定时器中断频率）来驱动 jiffies，但为了提供给用户空间一个标准化的、与硬件无关的时间单位，POSIX 标准定义了 CLK_TCK。sysconf() 函数: CLK_TCK 的值通常是系统在启动时确定的，并通过 sysconf() 系统调用（在 C 语言中）或 getconf 命令行工具暴露给用户空间。历史背景与目的:在早期的 Unix 系统中，各种系统资源使用时间（如 CPU 时间、进程启动时间等）都以“时钟滴答”为单位报告。然而，不同系统或不同架构的“时钟滴答”频率可能不同。为了使这些时间度量具有可移植性，POSIX 标准引入了 CLK_TCK，它定义了每秒的时钟滴答数。这样，应用程序就可以通过将报告的滴答数除以 CLK_TCK 来得到以秒为单位的时间，而无需关心底层内核的实际 HZ 值。CLK_TCK 的常见值是 100（即每秒 100 个滴答，每个滴答 10 毫秒）或 1000（每秒 1000 个滴答，每个滴答 1 毫秒）。现代 Linux 系统上，为了更高的精度，CLK_TCK 常常是 1000。总结： clock_ticks_per_sec (CLK_TCK) 是一个系统配置参数，它定义了用户空间应用程序进行时间计算时应使用的每秒时钟滴答数。它作为将内核报告的以滴答为单位的时间（例如 proc_start_time_ticks、utime、stime 等）转换为标准秒数的关键转换因子。" }, { "title": "红帽与SUSE对RHEL/CentOS 7系列延长生命周期支持策略：保障企业Linux系统的持续安全与稳定", "url": "/posts/centos7-eol/", "categories": "icenv", "tags": "os", "date": "2024-08-31 00:25:00 +0000", "snippet": "一、前言昨天有幸参加了一个活动，其一主办方是SUSE，感谢SUSE的工程师提供相关信息。在本篇文章中，我们将深入探讨两个关键的Linux操作系统支持方案：“红帽企业版 Linux 7（RHEL 7）延长生命周期支持”和“SUSE Liberty Linux Lite”，分析它们的特点、优势，并对比其他可用的解决方案。此外，我们还将简要介绍Open Enterprise Linux Assoc...", "content": "一、前言昨天有幸参加了一个活动，其一主办方是SUSE，感谢SUSE的工程师提供相关信息。在本篇文章中，我们将深入探讨两个关键的Linux操作系统支持方案：“红帽企业版 Linux 7（RHEL 7）延长生命周期支持”和“SUSE Liberty Linux Lite”，分析它们的特点、优势，并对比其他可用的解决方案。此外，我们还将简要介绍Open Enterprise Linux Association (OpenELA)的重要性和其在Linux社区的作用。二、红帽企业版 Linux 7（RHEL 7）延长生命周期支持2024年5月29日，红帽公司更新了其RHEL 7的延长生命周期支持（Extended Lifecycle Support, ELS）政策，使其与RHEL 8和RHEL 9的延长更新支持（Extended Update Support, EUS）政策趋于一致。这一变更主要是为了扩大对安全漏洞（CVE）的覆盖范围，满足客户不断增长的安全需求，并取消了先前ELS版本中的“包含列表”维护政策。主要特点：安全性优先：扩展了对RHEL 7的支持，包括对RHEL for SAP Solutions、RHEL High Availability附加组件和Resilient Storage附加组件的支持。维护的架构：支持x86（64位）和IBM S/390x架构。软件包支持：专注于RHEL 7.9版本，提供关键软件包的安全修复和紧急BUG修复。长期支持：Extended Lifecycle Support (ELS)从2024年07月01日开始，为其4年，即至2028年06月30日。OpenJDK 11和OpenJDK 8的支持将分别于2024年10月和2026年11月结束。三、SUSE Liberty Linux Lite面对CentOS 7即将在2024年6月30日结束支持的现状，SUSE推出了Liberty Linux Lite，为CentOS 7用户提供了一个简单的过渡方案，以便继续接收安全更新和支持。主要特点：零中断过渡：用户仅需将其CentOS 7的更新仓库切换至SUSE提供的仓库，无需进行操作系统迁移。成本效益：定价每台服务器/实例每年25美元，最低投资额为2500美元。长期支持：承诺提供至2028年6月30日的更新支持，与红帽保持一致。四、Open Enterprise Linux Association (OpenELA)OpenELA是由SUSE、CIQ和Oracle联合成立的组织，旨在应对Red Hat对RHEL源代码可用性的调整。OpenELA提供了一个开放和自由的企业Linux源代码库，使任何人都可以构建与RHEL及CentOS兼容的发行版。重要性：保证开源的持续性：确保企业Linux源代码对公众开放和免费。提供选择性：通过开放的源代码库，增强了用户在选择Linux发行版时的自由度和灵活性。时效性：会略比RHEL源码仓库晚几小时至1天。五、总结红帽的RHEL 7 ELS和SUSE的Liberty Linux Lite都提供了针对旧系统的支持策略，以应对不断变化的技术需求和安全挑战。RHEL 7 ELS的更新主要聚焦于扩大安全覆盖和取消“包含列表”维护政策，而SUSE Liberty Linux Lite则提供了一种无缝过渡方案，特别适合那些不希望迁移操作系统但需要持续支持的CentOS 7用户。通过OpenELA，SUSE等公司还提供了一个保证企业级Linux开源持续性的重要平台，这对于整个Linux社区的健康发展具有长远的意义。六、资料来源https://www.redhat.com/en/blog/announcing-4-years-extended-life-cycle-support-els-red-hat-enterprise-linux-7https://events.rainfocus.com/widget/suse/susecon2024/ondemandsessioncatalog/session/1715173217396001dVKj" }, { "title": "解决桌面初始化问题", "url": "/posts/fixing-desktop-init-issue/", "categories": "icenv", "tags": "desktop", "date": "2024-07-19 23:25:00 +0000", "snippet": "问题启动vnc桌面，提示问题。定位从[t]csh手册可以看到初始化流程。经定位，是.cshrc的这段代码存在，导致桌面初始化异常。[wanlin.wang@icinfra-cn-172-16-0-115 ~]$ cat .cshrc...部分省略...# Environment for anaconda3/4.4.0setenv PATH /tools/oss/spack/opt/spack...", "content": "问题启动vnc桌面，提示问题。定位从[t]csh手册可以看到初始化流程。经定位，是.cshrc的这段代码存在，导致桌面初始化异常。[wanlin.wang@icinfra-cn-172-16-0-115 ~]$ cat .cshrc...部分省略...# Environment for anaconda3/4.4.0setenv PATH /tools/oss/spack/opt/spack/linux-almalinux8-x86_64_v4/gcc-8.5.0/anaconda3-4.4.0-zpdh67mbu2fubypa6uqtgkrl5syel2hz/bin:$PATHif ($?LD_LIBRARY_PATH) then setenv LD_LIBRARY_PATH /tools/oss/spack/opt/spack/linux-almalinux8-x86_64_v4/gcc-8.5.0/anaconda3-4.4.0-zpdh67mbu2fubypa6uqtgkrl5syel2hz/lib:$LD_LIBRARY_PATHelse setenv LD_LIBRARY_PATH /tools/oss/spack/opt/spack/linux-almalinux8-x86_64_v4/gcc-8.5.0/anaconda3-4.4.0-zpdh67mbu2fubypa6uqtgkrl5syel2hz/libendif思路用户需要在.cshrc文件里加载各种各样的工具与库路径，以期望一开桌面/terminal，所需工具立即可用。但在桌面初始化时却导致了失败。因此，管理员需要从.cshrc入手，检测到桌面启动时，就立即终止往下source。也可以将这部分公共代码抽出来，放到公共cshrc里，供用户在.cshrc第一行进行source。解决.cshrc样例# For init desktop. Here we assume \"icinfra-cn-\" is the desktop hostname's prefix.if ($?SHLVL &amp;&amp; $SHLVL == 1 &amp;&amp; ! $?SSH_TTY &amp;&amp; (\"$HOSTNAME\" =~ icinfra-cn-*)) then exitendif# For init environment modules.source /tools/oss/spack/opt/spack/linux-almalinux8-x86_64_v4/gcc-8.5.0/environment-modules-5.4.0-uiudomq3q3xmgulxntqouamwlt6krxpa/init/cshsetenv MODULEPATH /tools/oss/spack/share/spack/modules/linux-almalinux8-x86_64_v4# For anaconda3/4.4.0setenv PATH /tools/oss/spack/opt/spack/linux-almalinux8-x86_64_v4/gcc-8.5.0/anaconda3-4.4.0-zpdh67mbu2fubypa6uqtgkrl5syel2hz/bin:$PATHif ($?LD_LIBRARY_PATH) then setenv LD_LIBRARY_PATH /tools/oss/spack/opt/spack/linux-almalinux8-x86_64_v4/gcc-8.5.0/anaconda3-4.4.0-zpdh67mbu2fubypa6uqtgkrl5syel2hz/lib:$LD_LIBRARY_PATHelse setenv LD_LIBRARY_PATH /tools/oss/spack/opt/spack/linux-almalinux8-x86_64_v4/gcc-8.5.0/anaconda3-4.4.0-zpdh67mbu2fubypa6uqtgkrl5syel2hz/libendif" }, { "title": "ontap模拟器", "url": "/posts/ontap-simulator/", "categories": "icenv", "tags": "storage", "date": "2024-07-14 06:40:00 +0000", "snippet": "一、下载模拟器参考《Simulate_ONTAP_9-14-1_Installation_and_Setup_Guide.pdf》P4的指导，登录网站进行下载。二、传入pve，并解压转换# 解压tar -xvf vsim-netapp-DOT9.14.1-cm_nodar.ova# 解压后的文件列表，其中ovf文件里定义了虚拟机的物理规格。vsim-NetAppDOT-simulate-di...", "content": "一、下载模拟器参考《Simulate_ONTAP_9-14-1_Installation_and_Setup_Guide.pdf》P4的指导，登录网站进行下载。二、传入pve，并解压转换# 解压tar -xvf vsim-netapp-DOT9.14.1-cm_nodar.ova# 解压后的文件列表，其中ovf文件里定义了虚拟机的物理规格。vsim-NetAppDOT-simulate-disk1.vmdkvsim-NetAppDOT-simulate-disk2.vmdkvsim-NetAppDOT-simulate-disk3.vmdkvsim-NetAppDOT-simulate-disk4.vmdkvsim-NetAppDOT-simulate.mfvsim-NetAppDOT-simulate.ovf# 转换vmdk为qcow2，能被导入到kvm平台。qemu-img convert -f vmdk -O qcow2 vsim-NetAppDOT-simulate-disk1.vmdk disk1.qcow2qemu-img convert -f vmdk -O qcow2 vsim-NetAppDOT-simulate-disk2.vmdk disk2.qcow2qemu-img convert -f vmdk -O qcow2 vsim-NetAppDOT-simulate-disk3.vmdk disk3.qcow2qemu-img convert -f vmdk -O qcow2 vsim-NetAppDOT-simulate-disk4.vmdk disk4.qcow2三、查看虚拟机需求，并创建虚拟机查看vsim-NetAppDOT-simulate.ovf文件，可以看虚拟机规格，特别的是 创建4个网卡，网卡类型为e1000 IDE 控制器点完成，然后创建4个e1000的网卡四、在proxmox命令行，导入磁盘到虚拟机。随后attach并设置启动项qm importdisk 120701001 disk1.qcow2 local-xfsqm importdisk 120701001 disk2.qcow2 local-xfsqm importdisk 120701001 disk3.qcow2 local-xfsqm importdisk 120701001 disk4.qcow2 local-xfsattach时选择ide控制器设置启动项五、启动输入admin，然后执行halt命令，然后将虚拟机stop掉，重启进入到配置模式：六、配置后面就可以通过web来配置了。配置完毕后，自动跳到集群管理IP的web页面至此，ontap模拟器搭建完毕。七、配置NetApp配置许可证贴入许可证准备存储配置协议配置存储八、挂载使用九、给svm配置LDAP备注：图片丢失，重新操作时补充一份。" }, { "title": "lxc缓存到期", "url": "/posts/lxc-cache-expired/", "categories": "icenv", "tags": "lxc", "date": "2024-04-09 04:30:00 +0000", "snippet": "[root@lxc-host ~]# DOWNLOAD_KEYSERVER=\"hkp://keyserver.ubuntu.com\" lxc-create -n slurm-master-node -t download -- -d almalinux -r 8 -a amd64 #提示过期了The cached copy has expired, re-downloading...Sett...", "content": "[root@lxc-host ~]# DOWNLOAD_KEYSERVER=\"hkp://keyserver.ubuntu.com\" lxc-create -n slurm-master-node -t download -- -d almalinux -r 8 -a amd64 #提示过期了The cached copy has expired, re-downloading...Setting up the GPG keyringERROR: Unable to fetch GPG key from keyserverlxc-create: slurm-master-node: lxccontainer.c: create_run_template: 1625 Failed to create container from templatelxc-create: slurm-master-node: tools/lxc_create.c: main: 331 Failed to create container slurm-master-node[root@lxc-host ~]# date -d \"@`cat /var/cache/lxc/download/almalinux/8/amd64/default/expiry`\" #查看过期日期Fri Mar 29 07:15:19 CST 2024[root@lxc-host ~]# date -d \"30 days\" +%s &gt; /var/cache/lxc/download/almalinux/8/amd64/default/expiry #更新过期日期至未来30天[root@lxc-host ~]# DOWNLOAD_KEYSERVER=\"hkp://keyserver.ubuntu.com\" lxc-create -n slurm-master-node -t download -- -d almalinux -r 8 -a amd64 #再次执行，即可使用cache了。Using image from local cacheUnpacking the rootfs---You just created a Almalinux 8 x86_64 (20240227_23:08) container." }, { "title": "给spack加编译器", "url": "/posts/how-to-add-compiler-for-spack/", "categories": "icenv", "tags": "spack", "date": "2024-04-09 01:12:00 +0000", "snippet": "参考资料https://spack.readthedocs.io/en/latest/getting_started.html#spack-compiler-add", "content": "参考资料https://spack.readthedocs.io/en/latest/getting_started.html#spack-compiler-add" }, { "title": "NFS AUTH_SYS 16 groups limitation", "url": "/posts/nfs-auth-sys-16-groups-limitation/", "categories": "icenv", "tags": "nfs", "date": "2024-03-30 11:12:00 +0000", "snippet": "背景NFS使用AUTH_SYS时有16群组限制，使用AUTH_GSS时有32群组限制。很多IC设计公司，使用AUTH_SYS方式，都有遇到超过16个群组无法使用的问题。分析问题现象[wanlinwang@VM-AlmaLinux8-tmpl-wanlinwang ~]$ id #从返回结果可知，q是第16群组，r是第17群组。uid=1001(wanlinwang) gid=1001(p) ...", "content": "背景NFS使用AUTH_SYS时有16群组限制，使用AUTH_GSS时有32群组限制。很多IC设计公司，使用AUTH_SYS方式，都有遇到超过16个群组无法使用的问题。分析问题现象[wanlinwang@VM-AlmaLinux8-tmpl-wanlinwang ~]$ id #从返回结果可知，q是第16群组，r是第17群组。uid=1001(wanlinwang) gid=1001(p) groups=1001(p),1002(system),1003(b),1004(c),1005(d),1006(e),1007(f),1008(h),1009(i),1010(j),1011(k),1012(l),1013(m),1014(n),1015(o),1016(q),1017(r),1018(s),1019(a),1020(z)[wanlinwang@VM-AlmaLinux8-tmpl-wanlinwang ~]$ ls -ld /tools/{testq,a}drwxrwx--- 2 root r 2 Mar 31 11:16 /tools/adrwxrwx--- 2 root q 2 Mar 31 11:16 /tools/testq[wanlinwang@VM-AlmaLinux8-tmpl-wanlinwang ~]$ cd /tools/a-bash: cd: /tools/a: Permission denied[wanlinwang@VM-AlmaLinux8-tmpl-wanlinwang ~]$ cd /tools/testq[wanlinwang@VM-AlmaLinux8-tmpl-wanlinwang testq]$ RPC包分析认证方式是AUTH_UNIX（AUTH_SYS），只传递了16个群组。源码分析从RFC5531 authsys_parms数据结构可看出，gids数组大小为16， struct authsys_parms { unsigned int stamp; string machinename&lt;255&gt;; unsigned int uid; unsigned int gid; unsigned int gids&lt;16&gt;; };解决方案自建NFSrpc.mountd daemon是NFS(v2,v3) MOUNT协议的服务侧实现。从管理员命令mountd的手册可以看到，-g, --manage-gids选项可以从name service查询确定group ids，而不使用NFS client提供的用户的group ids。因此，在导出文件系统时，调整mountd的选项，并配置好适当的name service以供查询。而NFS v4的nfsd没有提到该选项，尚不清楚选项与行为如何。NetApp1）必须为NFS Vserver配置LDAP或NIS并使其正常运行。也可以本地SVM UID与群组成员文件。2）LDAP或NIS服务器必须 为所有用户配置关联的组。3）配置ns-switch包含 LDAP 或 NIS 进来，vs1::&gt; set -privilege advancedWarning: These advanced commands are potentially dangerous; use them only when directed to do so by NetApp personnel.Do you want to continue? {y|n}: yvs1::*&gt; vserver services name-service ns-switch modify -vserver &lt;svm_name&gt; -database passwd -sources files,nisvs1::*&gt; vserver services name-service ns-switch modify -vserver &lt;svm_name&gt; -database group -sources files,nisvs1::*&gt; vserver services name-service ns-switch show4）通过这两个选项，来打开超过16群组的支持。vs1::&gt; set -privilege advancedWarning: These advanced commands are potentially dangerous; use them only when directed to do so by NetApp personnel.Do you want to continue? {y|n}: yvs1::*&gt; vserver nfs modify -vserver vs1 -auth-sys-extended-groups enabled -extended-groups-limit 512vs1::*&gt; vserver nfs show -vserver vs1 -fields auth-sys-extended-groups,extended-groups-limitvserver auth-sys-extended-groups extended-groups-limit------- ------------------------ ---------------------vs1 enabled 5125）调整缓存失效期限（可选）某用户打开了NetApp对超过16群组的支持，超过16群组的用户，假设群组是先前已经加好的，则work；假设群组是刚加入的，则不work。经过分析，是Name Service缓存、凭据缓存失效期限过长。而用户验证时，在新加群组几分钟内去验证的，此时缓存还是旧的，因此不work。可根据业务容忍度，适当地调整缓存失效时间。与群组相关的，我们有三种缓存时间可以调整，分别是name-service cache，vserver cached-cred-negative-ttl，vserver cached-cred-positive-ttl。查询命令：vs1::*&gt; vserver services name-service cache group-membership settings show -vserver &lt;svm_name&gt; #初始值为2小时。vs1::*&gt; vserver nfs show -vserver &lt;svm_name&gt; -fields cache-cred-negative-ttl #初始值为2小时。vs1::*&gt; vserver nfs show -vserver &lt;svm_name&gt; -fields cache-cred-positive-ttl #初始值为24小时。修改命令vs1::*&gt; vserver services name-service cache group-membership settings modify -grplist-ttl 15m #修改为15min。vs1::*&gt; vserver nfs modify -vserver &lt;svm_name&gt; -cached-cred-negative-ttl 900000 #单位：毫秒，等于15min。vs1::*&gt; vserver nfs modify -vserver &lt;svm_name&gt; -cached-cred-positive-ttl 900000 #单位：毫秒，等于15min。修改完再使用查询命令，查看是否已更改。验证命令vs1::*&gt; vserver services name-service cache group-membership show -vserver &lt;svm_name&gt; -user &lt;username&gt;vs1::*&gt; vserver services name-service getxxbyy getgrlist -node &lt;node_name&gt; -vserver &lt;svm_name&gt; -use-cache true -username &lt;username&gt;vs1::*&gt; vserver services name-service getxxbyy getgrlist -node &lt;node_name&gt; -vserver &lt;svm_name&gt; -use-cache false -username &lt;username&gt;vs1::*&gt; vserver nfs credentials show -node &lt;node_name&gt; -vserver &lt;svm_name&gt; -unix-user-name &lt;username&gt;总结不改NFS RPC传输的数据结构，而是服务端去Name Service查一下。这同时也解决了用户新群组在旧VNC Session不生效的问题：即使用户在terminal里执行groups没显示到新群组，但用户能访问新群组才有权限访问的目录，因为检查群组的这个步骤在服务端完成。参考资料:https://thinksystem.lenovofiles.com/storage/help/index.jsp?topic=%2Fnfs_file_access_reference_guide%2F1D3D018C-DF37-4C87-A789-58526A46B1A9_.htmlhttps://www.netapp.com/pdf.html?item=/media/10720-tr-4067.pdfhttps://kb.netapp.com/onprem/ontap/da/NAS/How_does_AUTH_SYS_Extended_Groups_change_NFS_authenticationhttps://datatracker.ietf.org/doc/html/rfc5531 P25 defines authsys_parms data structure, which limit the number of secondary groups up to 16.https://access.redhat.com/articles/625273https://docs.netapp.com/us-en/ontap/nfs-config/configure-name-service-switch-table-task.htmlhttps://kb.netapp.com/onprem/ontap/da/NAS/NFS_access_is_getting_denied_after_enabling_auth-sys-extended-groups致谢感谢EDACAD社区同学的对于该问题激烈讨论与分享。" }, { "title": "如何让软件使用不同版本的glibc而不导致系统崩溃", "url": "/posts/how-to-use-a-different-version-of-glibc/", "categories": "icenv", "tags": "glibc", "date": "2024-03-26 23:45:00 +0000", "snippet": "背景IC设计环境需要使用大量的开源工具。快速迭代的开源工具往往在开发时依赖于高版本的库，如glibc库。但IC设计环境主流还在使用CentOS 7.9，系统自带的glibc不满足运行条件。通常，为了满足运行条件，IT向业务提供一台自带高版本 glibc 的操作系统使用。如果仅仅为了运行小部分不常用的软件，这种方式成本较高。而另一种粗暴的做法：下载高版本glibc源码并直接执行./config...", "content": "背景IC设计环境需要使用大量的开源工具。快速迭代的开源工具往往在开发时依赖于高版本的库，如glibc库。但IC设计环境主流还在使用CentOS 7.9，系统自带的glibc不满足运行条件。通常，为了满足运行条件，IT向业务提供一台自带高版本 glibc 的操作系统使用。如果仅仅为了运行小部分不常用的软件，这种方式成本较高。而另一种粗暴的做法：下载高版本glibc源码并直接执行./configure &amp;$ make &amp;&amp; make install进行升级，将导致运维人“从勇士变为烈士”。需求在已有的操作系统上，让软件运行依赖于高版本的glibc，但同时不能影响系统与已有软件的正常运行。解决自行编译一个高版本glibc，并让软件使用它提供的链接器，以及让软件去找它提供的libc库。编译这里使用自动化包管理器spack解决诸多复杂的依赖。$ spack install glibc让软件使用它源码重新编译g++ main.o -o myapp ... \\ -Wl,--rpath=/path/to/newglibc_lib_dir \\ -Wl,--dynamic-linker=/path/to/newglibc_lib_dir/ld-linux.so.2修改已编译软件用patchelf修改，选项如下patchelf --set-interpreter /path/to/newglibc_lib_dir/ld-linux.so.2 --set-rpath /path/to/newglibc_lib_dir/ myapp参考资料https://lwn.net/Articles/631631/ ELF二进制可执行文件的介绍，包括解析器的介绍https://stackoverflow.com/a/44710599https://stackoverflow.com/a/851229" }, { "title": "svn ignore设置", "url": "/posts/svn-ignore/", "categories": "icenv", "tags": "svn", "date": "2024-03-21 02:25:00 +0000", "snippet": "svn(subversion)关于ignore的设置，在文末的参考资料中搜global-ignores，可以看到用户没有做任何设置的情况下，默认忽略了一些后缀文件。如果需要不忽略： 可以通过显示地加上 –no-ignore 选项。或者， 修改 ~/.subversion/config 全局文件。或者， svn propset svn:ignore来设置一个目录下直接文件，svn pro...", "content": "svn(subversion)关于ignore的设置，在文末的参考资料中搜global-ignores，可以看到用户没有做任何设置的情况下，默认忽略了一些后缀文件。如果需要不忽略： 可以通过显示地加上 –no-ignore 选项。或者， 修改 ~/.subversion/config 全局文件。或者， svn propset svn:ignore来设置一个目录下直接文件，svn propset svn:global-ignores 来设置一个目录树下的所有文件。参考资料https://svnbook.red-bean.com/nightly/en/svn.advanced.confarea.html#svn.advanced.confarea.opts.config" }, { "title": "集群运行nfsiostat收集信息并分析", "url": "/posts/cluster-nfsiostat/", "categories": "icenv", "tags": "storage", "date": "2024-03-17 12:25:00 +0000", "snippet": "工作中偶遇到NFS Server中IO hang，这里提供一个在集群中批量运行nfsiostat命令，并收集信息保存至excel文件，按nfs server分sheet，锁定第一行，并对每一列汇总。也可以进一步定制，定期将数据推送至ElasticSearch，记录时序数据以做进一步分析。# wanlinwang# 2024-03-17import reimport paramikoimpor...", "content": "工作中偶遇到NFS Server中IO hang，这里提供一个在集群中批量运行nfsiostat命令，并收集信息保存至excel文件，按nfs server分sheet，锁定第一行，并对每一列汇总。也可以进一步定制，定期将数据推送至ElasticSearch，记录时序数据以做进一步分析。# wanlinwang# 2024-03-17import reimport paramikoimport pandas as pdfrom io import StringIOfrom concurrent.futures import ThreadPoolExecutor# fs to mountpointfs2mp = {\"192.168.10.1:/nfs001\": \"home\",\"192.168.10.1:/nfs002\": \"tools\",\"192.168.10.2:/nfs003\": \"proj\",# Server information listservers = [\"192.168.10.1\",\"192.168.10.2\",]ops_pattern = r'\\b[\\d.]+(?: \\([\\d.]+\\))?|\\d+ \\(.*?\\)'# Execute nfsiostat and get the resultsdef get_nfsiostat(host, username=\"root\"): client = paramiko.SSHClient() client.set_missing_host_key_policy(paramiko.AutoAddPolicy()) client.connect(hostname=host, username=username, port=36000) stdin, stdout, stderr = client.exec_command('nfsiostat 2 2') # 等待第一次报告的输出并忽略 while not stdout.channel.recv_ready(): time.sleep(1) # 轮询等待输出 first_output = stdout.channel.recv(1000000) # 读取并丢弃第一次输出 print(f\"{host} 接收到第一次数据。\") #print(first_output.decode()) # 等待并读取第二次结果 time.sleep(2) # 接收第二次 output = b\"\" while not stdout.channel.eof_received: try: chunk = stdout.channel.recv(4096) if not chunk: break output += chunk except Eception as e: print(f\"接收第二次时发生错误{e}\") break print(f\"{host} 第二次结果\") output = output.decode() #print(f\"output {output}\") client.close() return output# Parse nfsiostat outputdef parse_nfsiostat_output(server, output): data = [] output_io = StringIO(output) lines = output_io.readlines() lines = [line for line in lines if line.strip() != \"\"] for i in range(0, len(lines), 7): if i + 5 &lt; len(lines): #mount_point = \"/\".join(lines[i].strip().split(\"/\")[0:2]) mount_point = \"/\".join(re.split('/| ', lines[i].strip())[0:2]) ops_rpc = lines[i+2].strip().split() matches = re.findall(ops_pattern, lines[i+4]) read_ops = [float(num) if '.' in num else int(num) for num in matches] matches = re.findall(ops_pattern, lines[i+6]) write_ops = [float(num) if '.' in num else int(num) for num in matches] data.append({ \"server\": server, \"mount_point\": mount_point, \"op/s\": ops_rpc[0], \"rpc bklog\": ops_rpc[1], \"read_ops/s\": read_ops[0], \"read_kB/s\": read_ops[1], \"read_kB/op\": read_ops[2], \"read_retrans\": read_ops[3], \"read_retrans%\": str(read_ops[4]) + \"%\", \"read_avg RTT(ms)\": read_ops[5], \"read_avg exe(ms)\": read_ops[6], \"write_ops/s\": write_ops[0], \"write_kB/s\": write_ops[1], \"write_kB/op\": write_ops[2], \"write_retrans\": write_ops[3], \"write_retrans%\": str(write_ops[4]) + \"%\", \"write_avg RTT(ms)\": write_ops[5], \"write_avg exe(ms)\": write_ops[6] }) return data# Function to fetch and parse nfsiostat output for a single serverdef fetch_and_parse_nfsiostat(server): output = get_nfsiostat(server) return parse_nfsiostat_output(server, output)# Main program using ThreadPoolExecutor for concurrencydef main(): all_data = [] with ThreadPoolExecutor(max_workers=len(servers)) as executor: futures = [executor.submit(fetch_and_parse_nfsiostat, server) for server in servers] for future in futures: all_data.extend(future.result()) # Convert data to DataFrame for easier processing df = pd.DataFrame(all_data) # Removing duplicates, keeping only unique records df_unique = df.drop_duplicates() # Output to Excel file with different mount_points on different sheets # Generating the Excel file name with a timestamp current_time = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\") excel_filename = f\"nfsiostat_data_{current_time}.xlsx\" with pd.ExcelWriter(excel_filename, engine='xlsxwriter') as writer: workbook = writer.book for mount_point in df_unique['mount_point'].unique(): df_mp = df_unique[df_unique['mount_point'] == mount_point] # 对每个server保留op/s最高的记录 df_mp = df_mp.sort_values(by='op/s', ascending=False).drop_duplicates(subset=['server'], keep='first') # 对指定列进行降序排序 if 'write_kB/s' in df_mp.columns and 'read_kB/s' in df_mp.columns: df_mp = df_mp.sort_values(by=['write_kB/s', 'read_kB/s'], ascending=[False, False]) # 创建工作表并写入数据 if mount_point in fs2mp: sheet_name = fs2mp[mount_point] else: sheet_name = mount_point.replace(\":/\", \"_\")[0:31] df_mp.to_excel(writer, sheet_name=sheet_name, index=False) # 获取工作表对象 worksheet = writer.sheets[sheet_name] # 锁定第一行 worksheet.freeze_panes(1, 0) # 自动调整列宽 for column in df_mp: column_length = max(df_mp[column].astype(str).map(len).max(), len(column)) col_idx = df_mp.columns.get_loc(column) worksheet.set_column(col_idx, col_idx, column_length) # Identify numeric columns and exclude specific ones from sum calculation numeric_cols = df_mp.select_dtypes(include=['number']).columns numeric_cols = numeric_cols.drop(['read_avg RTT(ms)', 'read_avg exe(ms)', 'write_avg RTT(ms)', 'write_avg exe(ms)'], errors='ignore') # Exclude specific columns sum_row = df_mp[numeric_cols].sum().to_dict() sum_row = {col: sum_row.get(col, '') for col in df_mp.columns} # Include empty values for non-numeric columns df_sum = pd.DataFrame([sum_row]) startrow = len(df_mp) + 1 df_sum.to_excel(writer, sheet_name=sheet_name, startrow=startrow, index=False, header=False) # Format the sum row sum_format = workbook.add_format({'bold': True}) for col_num, value in enumerate(df_sum.columns): worksheet.write(startrow, col_num, sum_row[value], sum_format) print(f\"Data has been outputted to Excel file at {excel_filename}\")if __name__ == \"__main__\": main()" }, { "title": "time to read/write in spin disk", "url": "/posts/time-to-read-or-write-in-spin-disk/", "categories": "icenv", "tags": "disk", "date": "2024-03-13 15:30:00 +0000", "snippet": "寻道以及旋转所需时间，相加：seek time：4～15ms平均等half a revolution：～4ms读写臂切换磁道时：time to 读写臂切换track，time to servo seek，time to settle onto the middle of the desired track。1）以前的设计是下一磁道的第一个 block 紧接着上一磁道最后一个 block，而读...", "content": "寻道以及旋转所需时间，相加：seek time：4～15ms平均等half a revolution：～4ms读写臂切换磁道时：time to 读写臂切换track，time to servo seek，time to settle onto the middle of the desired track。1）以前的设计是下一磁道的第一个 block 紧接着上一磁道最后一个 block，而读写臂切换track需要时间，切到下一磁道时，第一个block已经错过了。因此需要等它完全转一圈才能开始读取/写入；2）现在的设计，下一磁道的第一个 block 大约在上一次到最后一个 block 的 1/5 圈后。这样读写臂切换过去，大概到第一个 block的位置了。" }, { "title": "What is IOPs", "url": "/posts/iops/", "categories": "icenv", "tags": "storage", "date": "2024-03-13 04:30:00 +0000", "snippet": "我们经常会听到文件系统的IOPs，它是input/output Operations Per Second的缩写，它通常用于衡量文件系统的性能。对于读写操作，它通常是以n字节为单位的： 有时候它被称为operation or block size 一个1MB的文件以256个4KB块的读取，也可以以16个64KB块的读取：如果是4KB的块则产生256 IOPs，如果是64KB的块则产生16...", "content": "我们经常会听到文件系统的IOPs，它是input/output Operations Per Second的缩写，它通常用于衡量文件系统的性能。对于读写操作，它通常是以n字节为单位的： 有时候它被称为operation or block size 一个1MB的文件以256个4KB块的读取，也可以以16个64KB块的读取：如果是4KB的块则产生256 IOPs，如果是64KB的块则产生16 IOPs。其它非读写操作，如metadata的操作，也共享了IOPs。disk IOPs与front-end IOPs是不相同的。参考链接：What are IOPs? Why does the sum of all volume IOPS in an aggregate not match the aggregate IOPS? What available IOPS is" }, { "title": "LXC", "url": "/posts/lxc-snippets/", "categories": "icenv", "tags": "lxc", "date": "2024-03-10 00:30:00 +0000", "snippet": "lxc installationdnf install epel-releasednf install lxc lxc-doc lxc-templateslxc commandslxc-ls # list all instancesDOWNLOAD_KEYSERVER=\"hkp://keyserver.ubuntu.com\" lxc-create -n almalinux8 -B lvm -...", "content": "lxc installationdnf install epel-releasednf install lxc lxc-doc lxc-templateslxc commandslxc-ls # list all instancesDOWNLOAD_KEYSERVER=\"hkp://keyserver.ubuntu.com\" lxc-create -n almalinux8 -B lvm --vgname vg01 --thinpool almalinux8 --fssize=20G -t download -- -d almalinux -r 8 -a amd64lxc-start -n almalinux8 # start the instancelxc-info -n almalinux8 # get the instance infolxc-attach -n almalinux8 # attach to the instancelxc-stop -n almalinux8 # stop the instance注意：需创建lv给容器的根目录来运行FlexNet lic。除创建lv的方法，还可以参考文末”其它相关资料”。用以解决启动时报错： Cannot open daemon lock fileEXITING DUE TO SIGNAL 41 Exit reason 9***lmd exited with status 41 (Exited because another server was running)MULTIPLE “***lmd” license server systems running.Please kill, and run lmreread This error probbly results from either: Another copy of the license server manager (lmgrd) is running. A prior license server manager (lmgrd) was killed with “kill -9” customizing config for containervi /var/lib/lxc/almalinux8/config# Template used to create this container: /usr/share/lxc/templates/lxc-download# Parameters passed to the template: --dist almalinux --release 8 --arch amd64# For additional config options, please look at lxc.container.conf(5)# Uncomment the following line to support nesting containers:#lxc.include = /usr/share/lxc/config/nesting.conf# (Be aware this has security implications)# Distribution configurationlxc.include = /usr/share/lxc/config/common.conflxc.arch = x86_64# Container specific configurationlxc.rootfs.path = lvm:/dev/vg01/almalinux8lxc.uts.name = almalinux8# Network configurationlxc.net.0.type = vethlxc.net.0.link = virbr0lxc.net.0.flags = uplxc.net.0.hwaddr = 12:34:56:78:90:ablxc.net.0.ipv4.address = 192.168.122.2/24lxc.net.0.ipv4.gateway = 192.168.122.1# Mount entieslxc.mount.entry = /software software none bind,create=dir 0 0lxc.mount.entry = /tools tools none bind,create=dir 0 0lxc.mount.entry = /licenses licenses none bind,create=dir 0 0Creating a bridge NIC named virbr0# NetworkManagernmcli con add type bridge ifname virbr0 con-name virbr0nmcli con mod virbr0 ipv4.addresses 192.168.122.1/24 ipv4.method manualnmcli con up virbr0Firewall(DNAT and FORWARD)enable ipv4 forwarding which needed by NAT[root@lxc-host ~]# cat /proc/sys/net/ipv4/ip_forward0[root@lxc-host ~]# echo \"net.ipv4.ip_forward = 1\" &gt;&gt; /etc/sysctl.conf [root@lxc-host ~]# sysctl -pkernel.sysrq = 1sysctl: cannot stat /proc/sys/net/ipv6/conf/all/disable_ipv6: No such file or directorysysctl: cannot stat /proc/sys/net/ipv6/conf/default/disable_ipv6: No such file or directorysysctl: cannot stat /proc/sys/net/ipv6/conf/lo/disable_ipv6: No such file or directorykernel.numa_balancing = 0kernel.shmmax = 68719476736kernel.printk = 5net.ipv4.ip_forward = 1[root@lxc-host ~]# cat /proc/sys/net/ipv4/ip_forward1iptables# Generated by iptables-save*raw:PREROUTING ACCEPT [0:0]:OUTPUT ACCEPT [0:0]COMMIT*mangle:PREROUTING ACCEPT [0:0]:INPUT ACCEPT [0:0]:FORWARD ACCEPT [0:0]:OUTPUT ACCEPT [0:0]:POSTROUTING ACCEPT [0:0]COMMIT*nat:PREROUTING ACCEPT [0:0]:INPUT ACCEPT [0:0]:OUTPUT ACCEPT [0:0]:POSTROUTING ACCEPT [0:0]-A PREROUTING -p tcp -m tcp --dport 5280 -j DNAT --to-destination 192.168.122.2:5280 #DNAT-A PREROUTING -p tcp -m tcp --dport 3000 -j DNAT --to-destination 192.168.122.2:3000 #DNAT-A POSTROUTING -o virbr0 -j MASQUERADE #DNAT# SNAT-A POSTROUTING -s 192.168.122.3/32 -o eth0 -j MASQUERADECOMMIT*filter:INPUT ACCEPT [0:0]:FORWARD ACCEPT [0:0]:OUTPUT ACCEPT [0:0]-A INPUT -m state --state RELATED,ESTABLISHED -j ACCEPT-A INPUT -p icmp -j ACCEPT-A INPUT -i lo -j ACCEPT-A INPUT -j REJECT --reject-with icmp-host-prohibited# SNAT-A FORWARD -s 192.168.122.3/32 -j ACCEPT# DNAT-A FORWARD -d 192.168.122.2/32 -p tcp -m tcp --dport 5280 -j ACCEPT-A FORWARD -d 192.168.122.2/32 -p tcp -m tcp --dport 3000 -j ACCEPT-A FORWARD -m state --state RELATED,ESTABLISHED -j ACCEPT-A FORWARD -j REJECT --reject-with icmp-host-prohibited-A OUTPUT -o lo -j ACCEPTCOMMITfirewalldsysctl net.ipv4.ip_forward=1firewall-cmd --zone=public --add-forward-port=port=5280:proto=tcp:toaddr=192.168.122.2:toport=5280 --permanentfirewall-cmd --zone=public --add-forward-port=port=3000:proto=tcp:toaddr=192.168.122.2:toport=3000 --permanentfirewall-cmd --zone=public --add-port=5280/tcp --permanentfirewall-cmd --zone=public --add-port=3000/tcp --permanentfirewall-cmd --zone=public --add-masquerade --permanentfirewall-cmd --reloadfirewall-cmd --list-all其它相关资料来源 https://serverfault.com/q/922532 https://serverfault.com/a/1024360#define _GNU_SOURCE#include &lt;stdio.h&gt;#include &lt;stdlib.h&gt;#include &lt;dirent.h&gt;#include &lt;dlfcn.h&gt;#include &lt;string.h&gt;static int is_root = 0;static int d_ino = -1;static DIR *(*orig_opendir)(const char *name);static int (*orig_closedir)(DIR *dirp);static struct dirent *(*orig_readdir)(DIR *dirp);DIR *opendir(const char *name) { if (strcmp(name, \"/\") == 0) { is_root = 1; } return orig_opendir(name);}int closedir(DIR *dirp) { is_root = 0; return orig_closedir(dirp);}struct dirent *readdir(DIR *dirp) { struct dirent *r = orig_readdir(dirp); if (is_root &amp;&amp; r) { if (strcmp(r-&gt;d_name, \".\") == 0) { r-&gt;d_ino = d_ino; } else if (strcmp(r-&gt;d_name, \"..\") == 0) { r-&gt;d_ino = d_ino; } } return r;}static __attribute__((constructor)) void init_methods() { orig_opendir = dlsym(RTLD_NEXT, \"opendir\"); orig_closedir = dlsym(RTLD_NEXT, \"closedir\"); orig_readdir = dlsym(RTLD_NEXT, \"readdir\"); DIR *d = orig_opendir(\"/\"); struct dirent *e = orig_readdir(d); while (e) { if (strcmp(e-&gt;d_name, \".\") == 0) { d_ino = e-&gt;d_ino; break; } e = orig_readdir(d); } orig_closedir(d); if (d_ino == -1) { puts(\"Failed to determine root directory inode number\"); exit(EXIT_FAILURE); }}gcc -ldl -shared -fPIC snpslmd-ld-preload.c -o snpslmd-ld-preload.sovi snpslmd#!/bin/shexport LD_PRELOAD=snpslmd-ld-preload.soexec /path/to/original_snpslmd \"$@\"" }, { "title": "lmgrd not found but exists", "url": "/posts/lmgrd-not-found-but-exists/", "categories": "icenv", "tags": "lic", "date": "2024-03-10 00:30:00 +0000", "snippet": "$ strace -s 512 /software/Cadence/XCELIUM/23.09/tools.lnx86/bin/64bit/lmgrd -c cadence.txtexecve(\"/software/Cadence/XCELIUM/23.09/tools.lnx86/bin/64bit/lmgrd\", [\"/software/Cadence/XCELIUM/23.09/too...", "content": "$ strace -s 512 /software/Cadence/XCELIUM/23.09/tools.lnx86/bin/64bit/lmgrd -c cadence.txtexecve(\"/software/Cadence/XCELIUM/23.09/tools.lnx86/bin/64bit/lmgrd\", [\"/software/Cadence/XCELIUM/23.09/tools.lnx86/bin/64bit/lmgrd\", \"-c\", \"cadence.txt\"], 0x7fff138508d0 /* 33 vars */) = -1 ENOENT (No such file or directory)strace: exec: No such file or directory+++ exited with 1 +++sulotion$ dnf install lsb" }, { "title": "IC行业上云", "url": "/posts/tips-for-cloud/", "categories": "icenv", "tags": "cloud", "date": "2024-03-09 13:27:00 +0000", "snippet": "AMD关注的领域之一是前端验证。 首选的流程包括将他们的构建保留在本地，将模型本身与测试刺激捆绑在一起，然后将其发送出去以在云计算上执行实际的模拟活动。参考资料https://semiengineering.com/navigating-eda-vendor-cloud-options/", "content": "AMD关注的领域之一是前端验证。 首选的流程包括将他们的构建保留在本地，将模型本身与测试刺激捆绑在一起，然后将其发送出去以在云计算上执行实际的模拟活动。参考资料https://semiengineering.com/navigating-eda-vendor-cloud-options/" }, { "title": "环境变量的高优先级值", "url": "/posts/top-priority-environment-variables-in-environment-modules/", "categories": "icenv", "tags": "modules", "date": "2024-02-22 04:00:00 +0000", "snippet": "将路径保持在最前面，有两种方式： 官网的方式：https://modules.readthedocs.io/en/latest/cookbook/top-priority-values.html 我设计的方式：在有命令冲突的modulefile里，如xcelium里，加上这段使得indago工具的PATH变量在前面，优先级更高。这样，运行的indago命令是来自于in...", "content": "将路径保持在最前面，有两种方式： 官网的方式：https://modules.readthedocs.io/en/latest/cookbook/top-priority-values.html 我设计的方式：在有命令冲突的modulefile里，如xcelium里，加上这段使得indago工具的PATH变量在前面，优先级更高。这样，运行的indago命令是来自于indago工具目录的indago。 if { [ info exists env(LOADEDMODULES) ] } { set loaded_module_list [ split $env(LOADEDMODULES) \":\"] foreach modulefile $loaded_module_list { if {[regexp {^(indago|VDEBUG)} $modulefile]} { module swap --not-req $modulefile #--not-req以便允许用户切换版本。如果不加，其依赖关系将阻止用户切换版本。 break } }} " }, { "title": "verilator性能优化", "url": "/posts/verilator-accelerated/", "categories": "icenv", "tags": "verilator", "date": "2024-02-20 02:45:00 +0000", "snippet": "参考资料： https://veripool.org/papers/Verilator_Accelerated_OSDA2020.pdf https://verilator.org/guide/latest/environment.html#cmdoption-arg-OBJCACHE verilator可以使用分布式编译器 distcc（https://github.com/distc...", "content": "参考资料： https://veripool.org/papers/Verilator_Accelerated_OSDA2020.pdf https://verilator.org/guide/latest/environment.html#cmdoption-arg-OBJCACHE verilator可以使用分布式编译器 distcc（https://github.com/distcc/distcc?tab=readme-ov-file） 来利用多机编译。 https://veripool.org/papers/Verilator_Fast_Free_Me_DVClub10_pres.pdf P23提到使用distcc + ccache在多机进行编译。" }, { "title": "tcp/udp连通性测试", "url": "/posts/tcp-and-udp-connectivity-checking/", "categories": "icenv", "tags": "network", "date": "2024-02-18 01:45:00 +0000", "snippet": "背景说起开通防火墙端口（比如FlexNet license server的端口），通常用的是TCP协议，大家通常也默认是为需要开通的端口，开通TCP协议的访问。由于大部分服务使用了TCP协议，这样开通没问题。但是有些使用了UDP协议，导致服务无法起来，如这篇文章提到的lsf服务起不来的问题。环境准备如果服务已经启动，则可以直接进行连通性测试；如果服务还没启动，但需要先测试连通性，则可以使用下...", "content": "背景说起开通防火墙端口（比如FlexNet license server的端口），通常用的是TCP协议，大家通常也默认是为需要开通的端口，开通TCP协议的访问。由于大部分服务使用了TCP协议，这样开通没问题。但是有些使用了UDP协议，导致服务无法起来，如这篇文章提到的lsf服务起不来的问题。环境准备如果服务已经启动，则可以直接进行连通性测试；如果服务还没启动，但需要先测试连通性，则可以使用下述命令，在服务端以相应的协议监听对应的端口：监听TCP：nc -l &lt;port&gt;监听UDP：nc -ul &lt;port&gt;连通性测试说起测试端口连通性，大家也第一时间想到telnet工具。但telnet是基于TCP协议的，因此只能测试tcp的连通性，无法测试udp的连通性。先明确服务使用了哪些端口什么协议，然后使用对应的工具，逐个测试其连通性。如何测试TCP连通性？telnet工具用法：telnet &lt;hostname&gt; [&lt;port&gt;]nc工具用法：nc -zv &lt;hostname&gt; &lt;port&gt;如何测试UDP连通性？nc工具用法：nc -zvu &lt;hostname&gt; &lt;port&gt;参考资料https://en.wikipedia.org/wiki/Telnet telnet是基于TCP协议的，因此只能测试tcp的连通性。" }, { "title": "strace命令追踪子进程以及多线程", "url": "/posts/strace-subprocess-and-threads/", "categories": "icenv", "tags": "strace", "date": "2024-01-29 02:15:00 +0000", "snippet": "多线程strace命令，可以使用-f来追踪-p &lt;PID&gt;指定进程的所有线程。子进程对于子进程呢，strace是如何追踪的？strace命令，可以使用-f来追踪被追踪时新创建的子进程，而不会追踪原来已经创建了的子进程。因此，如果需要追踪一个已经启动的进程的所有子进程，需要分别将子进程ID用-p &lt;PID&gt;传进来追踪。", "content": "多线程strace命令，可以使用-f来追踪-p &lt;PID&gt;指定进程的所有线程。子进程对于子进程呢，strace是如何追踪的？strace命令，可以使用-f来追踪被追踪时新创建的子进程，而不会追踪原来已经创建了的子进程。因此，如果需要追踪一个已经启动的进程的所有子进程，需要分别将子进程ID用-p &lt;PID&gt;传进来追踪。" }, { "title": "Pyhon2 to Python3", "url": "/posts/2to3/", "categories": "icenv", "tags": "python", "date": "2024-01-26 08:15:00 +0000", "snippet": "背景Imagination提供的flow脚本是基于Python2的，里面导入一个PIL模块。但是使用pip2 install PIL或pip2 install pillow却无法装上。解决现在Python2已经不维护了，争取将代码迁移到Python3上来。安装2to3:在Python 2.7下，pip2 install 2to3转换2to3 -w /path/to/python2.py就可以...", "content": "背景Imagination提供的flow脚本是基于Python2的，里面导入一个PIL模块。但是使用pip2 install PIL或pip2 install pillow却无法装上。解决现在Python2已经不维护了，争取将代码迁移到Python3上来。安装2to3:在Python 2.7下，pip2 install 2to3转换2to3 -w /path/to/python2.py就可以原地将/path/to/python2.py里面的内容，转换成Python3的语法了。但是第一行的解析器没有修改，你可能还需要手动将解析器修改至正确的Python3的位置。参考资料https://pypi.org/project/2to3/" }, { "title": "Windows下使用psping工具测到指定ip:port的延时", "url": "/posts/psping/", "categories": "icenv", "tags": "psping", "date": "2024-01-26 07:15:00 +0000", "snippet": "问题如何获得从Windows到一个IP:PORT的网络延时？工具PsPing是微软提供的，实现了ping、tcp ping、延时与带宽测量的工具。PS C:\\Users\\wanlinwang&gt; C:\\Users\\wanlinwang\\Downloads\\PSTools\\psping 192.168.1.2:3389PsPing v2.12 - PsPing - ping, latenc...", "content": "问题如何获得从Windows到一个IP:PORT的网络延时？工具PsPing是微软提供的，实现了ping、tcp ping、延时与带宽测量的工具。PS C:\\Users\\wanlinwang&gt; C:\\Users\\wanlinwang\\Downloads\\PSTools\\psping 192.168.1.2:3389PsPing v2.12 - PsPing - ping, latency, bandwidth measurement utilityCopyright (C) 2012-2023 Mark RussinovichSysinternals - www.sysinternals.comTCP connect to 192.168.1.2:3389:5 iterations (warmup 1) ping test:Connecting to 192.168.1.2:3389 (warmup): from 192.168.11.10:57712: 0.33msConnecting to 192.168.1.2:3389: from 192.168.11.10:57714: 0.31msConnecting to 192.168.1.2:3389: from 192.168.11.10:57716: 0.33msConnecting to 192.168.1.2:3389: from 192.168.11.10:57718: 0.34ms Sent = 3, Received = 3, Lost = 0 (0% loss), Minimum = 0.31ms, Maximum = 0.34ms, Average = 0.33msControl-C参考资料https://learn.microsoft.com/en-us/sysinternals/downloads/psping" }, { "title": "spack bootstrap in air-gapped system", "url": "/posts/spack-bootstrap-in-air-gapped-system/", "categories": "icenv", "tags": "spack", "date": "2024-01-21 03:15:00 +0000", "snippet": "背景首次使用spack时，虽然将gmake-4.4.1.tar.gz包下载至mirror目录，但还是提示如下：spack install gcc@13.2.0 +binutils==&gt; Installing gmake-4.4.1-bun3eynjvtrgzylwfldooydmcbtgsavx [1/2]==&gt; No binary for gmake-4.4.1-bun3eyn...", "content": "背景首次使用spack时，虽然将gmake-4.4.1.tar.gz包下载至mirror目录，但还是提示如下：spack install gcc@13.2.0 +binutils==&gt; Installing gmake-4.4.1-bun3eynjvtrgzylwfldooydmcbtgsavx [1/2]==&gt; No binary for gmake-4.4.1-bun3eynjvtrgzylwfldooydmcbtgsavx found: installing from source==&gt; Error: FetchError: All fetchers failed for spack-stage-gmake-4.4.1-bun3eynjvtrgzylwfldooydmcbtgsavx分析需先在离线系统下spack bootstrap。在air-gapped system（离线系统）需要手动将bootstrap相关包准备好，否则spack会尝试去互联网取并失败。步骤在在线系统下，执行$ spack bootstrap mirror --binary-packages /opt/bootstrap==&gt; Adding \"clingo-bootstrap@spack+python %apple-clang target=x86_64\" and dependencies to the mirror at /opt/bootstrap/local-mirror==&gt; Adding \"gnupg@2.3: %apple-clang target=x86_64\" and dependencies to the mirror at /opt/bootstrap/local-mirror==&gt; Adding \"patchelf@0.13.1:0.13.99 %apple-clang target=x86_64\" and dependencies to the mirror at /opt/bootstrap/local-mirror==&gt; Adding binary packages from \"https://github.com/alalazo/spack-bootstrap-mirrors/releases/download/v0.1-rc.2/bootstrap-buildcache.tar.gz\" to the mirror at /opt/bootstrap/local-mirror将/opt/bootstrap目录拷贝到离线系统下，并添加，$ spack bootstrap add --trust local-sources /opt/bootstrap/metadata/sources$ spack bootstrap add --trust local-binaries /opt/bootstrap/metadata/binaries效果$ spack install gcc@13.2.0 +binutils==&gt; Fetching file:///tools/opensrc/spack/spack-mirror/bootstrap_cache/build_cache/linux-centos7-x86_64-gcc-10.2.1-patchelf-0.16.1-p72zyan5wrzuabtmzq7isa5mzyh6ahdp.spec.json==&gt; Fetching file:///tools/opensrc/spack/spack-mirror/bootstrap_cache/build_cache/linux-centos7-x86_64/gcc-10.2.1/patchelf-0.16.1/linux-centos7-x86_64-gcc-10.2.1-patchelf-0.16.1-p72zyan5wrzuabtmzq7isa5mzyh6ahdp.spack==&gt; Installing \"patchelf@=0.16.1%gcc@=10.2.1 ldflags=\"-static-libstdc++ -static-libgcc\" build_system=autotools arch=linux-centos7-x86_64\" from a buildcache==&gt; Fetching file:///tools/opensrc/spack/spack-mirror/bootstrap_cache/build_cache/linux-centos7-x86_64-gcc-10.2.1-clingo-bootstrap-spack-prqkzynv2nwko5mktitebgkeumuxkveu.spec.json==&gt; Fetching file:///tools/opensrc/spack/spack-mirror/bootstrap_cache/build_cache/linux-centos7-x86_64/gcc-10.2.1/clingo-bootstrap-spack/linux-centos7-x86_64-gcc-10.2.1-clingo-bootstrap-spack-prqkzynv2nwko5mktitebgkeumuxkveu.spack==&gt; Installing \"clingo-bootstrap@=spack%gcc@=10.2.1~docs~ipo+python+static_libstdcpp build_type=Release arch=linux-centos7-x86_64\" from a buildcache==&gt; Installing gmake-4.4.1-7xujubssqx5cedh3lnbz7nhzgn2kjpyh [1/30]==&gt; No binary for gmake-4.4.1-7xujubssqx5cedh3lnbz7nhzgn2kjpyh found: installing from source参考资料https://spack.readthedocs.io/en/latest/bootstrapping.html#creating-a-mirror-for-air-gapped-systems" }, { "title": "new group and change directory", "url": "/posts/new-group-n-chdir/", "categories": "icenv", "tags": "newgrp", "date": "2024-01-19 02:19:00 +0000", "snippet": "介绍newgrp启动一个新shell。用户一般会拥有多个群组。切换primary群组时会带来很多麻烦。实践如果group名字与目录名字不一样，就放这个进去到~/.cshrc文件，通过不同分支来判断。alias new_group 'setenv NEW_MANNUALY_GROUP \\!:1; exec newgrp $NEW_MANNUALY_GROUP'if ($?NEW_MANNUAL...", "content": "介绍newgrp启动一个新shell。用户一般会拥有多个群组。切换primary群组时会带来很多麻烦。实践如果group名字与目录名字不一样，就放这个进去到~/.cshrc文件，通过不同分支来判断。alias new_group 'setenv NEW_MANNUALY_GROUP \\!:1; exec newgrp $NEW_MANNUALY_GROUP'if ($?NEW_MANNUALY_GROUP) then switch ($NEW_MANNUALY_GROUP) case 'group001': cd /project/group001/${USER} &amp;&amp; unsetenv NEW_MANNUALY_GROUP breaksw case 'group002': cd /project/group002/${USER} &amp;&amp; unsetenv NEW_MANNUALY_GROUP breaksw endswendif如果group名字与目录名字一样，就放这段进去到~/.cshrc文件，简单：alias new_group 'setenv NEW_MANNUALY_GROUP \\!:1; exec newgrp $NEW_MANNUALY_GROUP'if ($?NEW_MANNUALY_GROUP) then cd /project/${NEW_MANNUALY_GROUP}/${USER} &amp;&amp; unsetenv NEW_MANNUALY_GROUPendif然后就可以执行 new_grp xxxx 来切换至xxxx群组了，并且还可以保持当前环境变量。" }, { "title": "Pull-Through Cache Docker Registry实践", "url": "/posts/registry-as-a-pull-through-cache/", "categories": "icenv", "tags": "registry", "date": "2024-01-17 08:30:00 +0000", "snippet": "背景容器在risc-v社区比较流行。这里介绍容器在研发环境的实践，能够单向拉取镜像运行，不能推送。+------------------------------------+ +------------------------------+ +-----------+| Upstream Docker | | Pu...", "content": "背景容器在risc-v社区比较流行。这里介绍容器在研发环境的实践，能够单向拉取镜像运行，不能推送。+------------------------------------+ +------------------------------+ +-----------+| Upstream Docker | | Pull-Through Cache | | Client || Registry | | Docker Registry | | (host001) || (https://registry-1.docker.io) | -----&gt; | (registry.icinfra.cn:5000) | ----&gt; | |+------------------------------------+ +------------------------------+ +-----------+配置Pull-through cache docker registry根据 https://docs.docker.com/docker-hub/mirror/#run-a-registry-as-a-pull-through-cache 介绍，配置/etc/docker/registry/config.yml文件里的proxy.remoteurl为外部registry。registry容器可以通过传入REGISTRY_PROXY_REMOTEURL环境变量来完成配置，命令如下：podman run -d -p 5000:5000 --name registry-cache -e REGISTRY_PROXY_REMOTEURL=https://registry-1.docker.io registry:2Client在客户端侧配置registry地址，让podman或docker命令使用。cat &gt; ~/.config/containers/registries.conf &lt;&lt;EOF[registries.insecure] registries = ['registry.icinfra.cn:5000']EOF完毕。附录 https://distribution.github.io/distribution/about/configuration/ 与 https://distribution.github.io/distribution/recipes/mirror/ 提到，podman push到pull-through cache是不支持的。满足“禁止用户push”的需求。 https://www.icinfra.cn/blog/2024/rootless-podman-and-nfs/ 容器镜像层不能放在NFS，用户数据可以通过-v映射NFS目录进去使用。 https://www.redhat.com/sysadmin/rootless-podman-user-namespace-modes 运行 rootless容器 需要打开subordinate ID。" }, { "title": "mill工具的proxy设置", "url": "/posts/mill-proxy-setting/", "categories": "icenv", "tags": "mill", "date": "2024-01-15 08:30:00 +0000", "snippet": "背景新Scala构建工具mill正在流行。很多Scala开发环境是内网环境，访问互联网需要通过proxy。问题用户设置了http_proxy与https_proxy变量，执行mill构建Scala工程时卡住。解决假设http proxy的主机与端口为 your-proxy-server.com:8080，则按照以下步骤来让mill使用proxy： 在构建环境，设置环境变量JAVA_OPTS...", "content": "背景新Scala构建工具mill正在流行。很多Scala开发环境是内网环境，访问互联网需要通过proxy。问题用户设置了http_proxy与https_proxy变量，执行mill构建Scala工程时卡住。解决假设http proxy的主机与端口为 your-proxy-server.com:8080，则按照以下步骤来让mill使用proxy： 在构建环境，设置环境变量JAVA_OPTS=”-Dhttp.proxyHost=your-proxy-server.com -Dhttp.proxyPort=8080 -Dhttps.proxyHost=your-proxy-server.com -Dhttps.proxyPort=8080” 在调用mill时，加上-i选项。" }, { "title": "rootless容器与NFS", "url": "/posts/rootless-podman-and-nfs/", "categories": "icenv", "tags": "container", "date": "2024-01-12 15:10:00 +0000", "snippet": "很多人都对rootless Podman感兴趣。此工具允许您构建、安装和使用容器，而无需用户以 root 身份运行，也不需要用户在其系统上拥有大型 root 运行守护程序。相反，Podman（默认情况下）将容器映像存储在用户的主目录中。Podman 利用用户命名空间来执行此操作，因为大多数容器映像在映像中都有多个 UID。但是，一个不起作用的问题是将这些映像存储在基于 NFS 的主目录中。为...", "content": "很多人都对rootless Podman感兴趣。此工具允许您构建、安装和使用容器，而无需用户以 root 身份运行，也不需要用户在其系统上拥有大型 root 运行守护程序。相反，Podman（默认情况下）将容器映像存储在用户的主目录中。Podman 利用用户命名空间来执行此操作，因为大多数容器映像在映像中都有多个 UID。但是，一个不起作用的问题是将这些映像存储在基于 NFS 的主目录中。为什么 Podman 不支持 NFS 上的存储？首先，对于大多数场景，rootless Podman 可以很好地与 NFS 卷配合使用。效果不佳的场景是将容器映像存储驻留在 NFS 挂载点上。当用户尝试拉取映像或安装 RPM 包时，这个问题最容易理解。让我们来看看当用户尝试使用rootless Podman 在文件系统上安装 tarball 或 RPM 包时会发生什么。在我们的示例中，我将使用 UID 为 1000 的用户，其中的 UID 映射设置如下所示：/etc/subuidwanlinwang:100000:65536结果如下所示：$ podman unshare cat /proc/self/uid_map 0 1000 1 1 100000 65536现在，在容器内部，我想安装该软件包。该软件包将以 root 用户和 UID 为 60 的用户身份安装文件。这意味着，在主目录上安装包的容器的根进程会尝试运行如下内容：$ chown 60:60 /var/www/html/index.html当这种情况发生在本地文件系统上时，内核会检查两件事。首先，它检查 UID 60 和 GID 60 是否映射在用户命名空间内。其次，它决定了执行 chowning 的过程是否具有DAC_OVERRIDE能力。由于该进程未以 UID 60 的形式运行，因此它必须能够覆盖正常的 UID/GID 权限。容器内部的进程以 root 身份运行时以 UID 1000 运行，当容器内以 UID 60 运行时，它实际上是主机上的 uid 100059。请注意，我只谈论用户命名空间DAC_OVERRIDE，这意味着容器内部的进程可以覆盖映射到用户命名空间（例如容器）的 UID/GID。此设置适用于所有本地文件系统，因为本地内核可以做出决策。在处理 NFS 时，您必须满足本地内核和远程内核的要求。从远程 NFS 服务器内核的角度来看待这个问题。远程内核看到一个进程以 UID 1000（容器中的根）身份运行，尝试将 1000 拥有的文件更改owner到 UID 100059（容器内的 UID 60）。远程内核拒绝此访问。NFS 协议没有用户命名空间的概念，也无法知道作为 UID 1000 运行的进程是否合二为一。NFS 服务器也无法知道客户端进程是否DAC_OVERRIDE用户命名空间，以及 UID 100059是否映射到同一用户命名空间。现在，如果您有一个在 NFS 共享上创建文件的正常进程，并且没有利用用户命名空间功能，则一切正常。当容器内的进程需要在 NFS 共享上执行需要特殊功能访问的操作时，问题就出现了。在这种情况下，远程内核将不知道该功能，并且很可能会拒绝访问。案例wanlinwang@h74ba78:/home/wanlinwang/ podman --versionpodman version 4.4.1wanlinwang@h74ba78:/home/wanlinwang/ podman unshare cat /proc/self/uid_map 0 1157 1 1 2147483648 65536wanlinwang@h74ba78:/home/wanlinwang/ podman run -ti -v /home/wanlinwang/podman-volume:/mnt mirrors.tencent.com/sysbox/busybox bashTrying to pull mirrors.tencent.com/sysbox/busybox:latest...Getting image source signaturesCopying blob b71f96345d44 done ERRO[0000] While applying layer: ApplyLayer stdout: stderr: setting up pivot dir: mkdir /home/wanlinwang/.local/share/containers/storage/vfs/dir/5b8c72934dfc08c7d2bd707e93197550f06c0751023dabb3a045b723c5e7b373/.pivot_root2193543684: permission denied exit status 1 Error: writing blob: adding layer with blob \"sha256:b71f96345d44b237decc0c2d6c2f9ad0d17fde83dad7579608f1f0764d9686f2\": ApplyLayer stdout: stderr: setting up pivot dir: mkdir /home/wanlinwang/.local/share/containers/storage/vfs/dir/5b8c72934dfc08c7d2bd707e93197550f06c0751023dabb3a045b723c5e7b373/.pivot_root2193543684: permission denied exit status 1wanlinwang@h74ba78:/home/wanlinwang/ mkdir -p /home/wanlinwang/.local/share/containers/storage/vfs/dir/5b8c72934dfc08c7d2bd707e93197550f06c0751023dabb3a045b723c5e7b373/.pivot_root2193543684wanlinwang@h74ba78:/home/wanlinwang/ podman run -ti -v /home/wanlinwang/podman-volume:/mnt mirrors.tencent.com/sysbox/busybox bashTrying to pull mirrors.tencent.com/sysbox/busybox:latest...Getting image source signaturesCopying blob b71f96345d44 done Copying blob b71f96345d44 done Error: writing blob: adding layer with blob \"sha256:b71f96345d44b237decc0c2d6c2f9ad0d17fde83dad7579608f1f0764d9686f2\": ApplyLayer stdout: stderr: lchown /home: operation not permitted exit status 1如何使 NFS 与无根 Podman 一起工作？有几种方法可以在 NFS 共享上设置用户的主目录以使用无根 Podman。方法一可以将文件中的graphroot标志配置为非 NFS 目录。例如，更改：~/.config/containers/storage.conf[storage] driver = \"overlay\" runroot = \"/run/user/1000\" graphroot = \"/home/wanlinwang/.local/share/containers/storage\"为[storage] driver = \"overlay\" runroot = \"/run/user/1000\" graphroot = \"/var/tmp/wanlinwang/containers/storage此更改将使得在容器中拉取和创建的映像在家目录之外的其他目录上进行处理。但该方法有一个缺点，就是无法在多台机器同时使用容器映像。如果需要在由多台服务器组成的集群中跑一个容器映像的多个实例，则需要在每台机器上都拉取该容器映像。方法二另一种选择是创建磁盘映像并将其挂载到目录中。您可以使用如下脚本：~/.local/share/containerstruncate -s 10g /home/wanlinwang/xfs.img mkfs.xfs -m reflink=1 /home/wanlinwang/xfs.img然后，您可以在具有家目录的计算机上，执行如下操作：$ mount /home/myuser/xfs.img /home/myuser/.local/share/containers结论rootless和root Podman 非常适合作为卷挂载的远程网络共享，包括 NFS 共享。但是，开箱即用的rootless Podman 在 NFS 主目录中可能无法正常工作，因为该协议无法理解用户命名空间。幸运的是，只需稍作配置更改，就可以在 NFS 主目录上使用rootless Podman。参考资料https://www.redhat.com/sysadmin/rootless-podman-nfshttps://opensource.com/article/18/12/podman-and-user-namespaceshttps://opensource.com/users/rhatdan 红帽工程师的主页，容器相关的https://opensource.com/article/19/5/shortcomings-rootless-containers rootless容器的缺点https://github.com/containers/podman/blob/main/rootless.md rootless容器的缺点https://man7.org/linux/man-pages/man7/capabilities.7.html CAP_DAC_OVERRIDE 资料https://www.redhat.com/sysadmin/controlling-access-rootless-podman-users 忽略chown与su的错误" }, { "title": "用Python猜谜", "url": "/posts/solve-puzzle-with-python/", "categories": "icenv", "tags": "python", "date": "2024-01-11 15:20:00 +0000", "snippet": "这里，记录一个比较有趣的谜题解决方法。谜题略。思路编程来解决这个问题。#!/usr/bin/env python3# 定义线索clues = [ (\"ABC\", (1, True)), # A B C - 一个数字正确且位置正确 (\"AEF\", (1, False)), # A E F - 一个数字正确但位置不正确 (\"CKA\", (2, False)), # C ...", "content": "这里，记录一个比较有趣的谜题解决方法。谜题略。思路编程来解决这个问题。#!/usr/bin/env python3# 定义线索clues = [ (\"ABC\", (1, True)), # A B C - 一个数字正确且位置正确 (\"AEF\", (1, False)), # A E F - 一个数字正确但位置不正确 (\"CKA\", (2, False)), # C K A - 两个数字正确但位置都不正确 (\"DEB\", (0, False)), # D E B - 所有数字都不正确 (\"BDK\", (1, False)) # B D K - 一个数字正确但位置不正确]# 定义可能的数字digits = \"ABCDEFGHK\" # 可能的数字，排除了未提到的# 生成所有可能的三字母组合from itertools import permutations# 初始化一个列表来保存可能的组合possible_combinations = [''.join(p) for p in permutations(digits, 3)]# 检查组合是否符合线索的函数def check_combination(combination, clue): digit_correct, position_correct = clue[1] # 计算有多少数字是正确且位置正确的 correct_digits_and_positions = sum(1 for i in range(3) if combination[i] == clue[0][i]) # 计算有多少数字是正确的，不考虑位置 correct_digits = sum(1 for c in clue[0] if c in combination) # 根据线索进行检查 if position_correct: return correct_digits_and_positions == digit_correct else: if digit_correct == 0: return correct_digits == 0 return correct_digits == digit_correct and correct_digits_and_positions == 0# 通过每条线索过滤可能的组合for clue in clues: possible_combinations = [comb for comb in possible_combinations if check_combination(comb, clue)]print(possible_combinations)" }, { "title": "打开ipa用户的subid(subordinate id)以运行rootless容器", "url": "/posts/subid-from-ipa/", "categories": "icenv", "tags": "ipa", "date": "2024-01-10 03:30:00 +0000", "snippet": "背景前面文章升级ipa介绍了如何将ipa从CentOS 7上的旧版本迁移至AlmaLinux 8上的新版本。这里我们来看看如何使用AlmaLinux 8上的FreeIPA新版本的subid功能。步骤FreeIPA服务端配置略。FreeIPA客户端配置与验证[root@almalinux-8-ipa-client ~]# su - wanlinwangLast login: Wed Jan 1...", "content": "背景前面文章升级ipa介绍了如何将ipa从CentOS 7上的旧版本迁移至AlmaLinux 8上的新版本。这里我们来看看如何使用AlmaLinux 8上的FreeIPA新版本的subid功能。步骤FreeIPA服务端配置略。FreeIPA客户端配置与验证[root@almalinux-8-ipa-client ~]# su - wanlinwangLast login: Wed Jan 10 02:36:13 EST 2024 on pts/0[wanlinwang@almalinux-8-ipa-client ~]$ podman pull bosybox✔ docker.io/library/bosybox:latestTrying to pull docker.io/library/bosybox:latest...Error: initializing source docker://bosybox:latest: reading manifest latest in docker.io/library/bosybox: requested access to the resource is denied[wanlinwang@almalinux-8-ipa-client ~]$ podman run busybox dateResolved \"busybox\" as an alias (/etc/containers/registries.conf.d/000-shortnames.conf)Trying to pull docker.io/library/busybox:latest...Getting image source signaturesCopying blob a307d6ecc620 done Error: copying system image from manifest list: writing blob: adding layer with blob \"sha256:a307d6ecc6205dfa11d2874af9adb7e3fc244a429e00e8e3df90534d4cf0f3f8\": processing tar file(potentially insufficient UIDs or GIDs available in user namespace (requested 65534:65534 for /home): Check /etc/subuid and /etc/subgid if configured locally and run \"podman system migrate\": lchown /home: invalid argument): exit status 1[wanlinwang@almalinux-8-ipa-client ~]$ podman system migrate[wanlinwang@almalinux-8-ipa-client ~]$ podman run busybox dateERRO[0000] cannot find UID/GID for user wanlinwang: no subuid ranges found for user \"wanlinwang\" in /etc/subuid - check rootless mode in man pages. WARN[0000] Using rootless single mapping into the namespace. This might break some images. Check /etc/subuid and /etc/subgid for adding sub*ids if not using a network user Resolved \"busybox\" as an alias (/etc/containers/registries.conf.d/000-shortnames.conf)Trying to pull docker.io/library/busybox:latest...Getting image source signaturesCopying blob a307d6ecc620 done Error: copying system image from manifest list: writing blob: adding layer with blob \"sha256:a307d6ecc6205dfa11d2874af9adb7e3fc244a429e00e8e3df90534d4cf0f3f8\": processing tar file(potentially insufficient UIDs or GIDs available in user namespace (requested 65534:65534 for /home): Check /etc/subuid and /etc/subgid if configured locally and run \"podman system migrate\": lchown /home: invalid argument): exit status 1[wanlinwang@almalinux-8-ipa-client ~]$ exitlogout[root@almalinux-8-ipa-client ~]# vi /etc/nsswitch.conf #在/etc/nsswitch.conf配置文件里增加了subid:sss[root@almalinux-8-ipa-client ~]# grep subid /etc/nsswitch.confsubid: sss[root@almalinux-8-ipa-client ~]# su - wanlinwangLast login: Wed Jan 10 02:39:28 EST 2024 on pts/0[wanlinwang@almalinux-8-ipa-client ~]$ podman run busybox dateResolved \"busybox\" as an alias (/etc/containers/registries.conf.d/000-shortnames.conf)Trying to pull docker.io/library/busybox:latest...Getting image source signaturesCopying blob a307d6ecc620 done Error: copying system image from manifest list: writing blob: adding layer with blob \"sha256:a307d6ecc6205dfa11d2874af9adb7e3fc244a429e00e8e3df90534d4cf0f3f8\": processing tar file(potentially insufficient UIDs or GIDs available in user namespace (requested 65534:65534 for /home): Check /etc/subuid and /etc/subgid if configured locally and run \"podman system migrate\": lchown /home: invalid argument): exit status 1[wanlinwang@almalinux-8-ipa-client ~]$ podman system migrate #在/etc/nsswitch.conf配置文件里增加了subid:sss后，需要执行podman system migrate后podman run才生效。[wanlinwang@almalinux-8-ipa-client ~]$ podman run busybox date #生效了。Resolved \"busybox\" as an alias (/etc/containers/registries.conf.d/000-shortnames.conf)Trying to pull docker.io/library/busybox:latest...Getting image source signaturesCopying blob a307d6ecc620 done Copying config 9211bbaa0d done Writing manifest to image destinationWed Jan 10 07:40:58 UTC 2024资料https://access.redhat.com/solutions/6784071 如何配置使用ipa subid来源https://access.redhat.com/solutions/6961540 只能允许一种subid来源" }, { "title": "为什么不要将ntp service运行在virtual machine上？", "url": "/posts/do-not-run-ntp-server-on-vm/", "categories": "icenv", "tags": "ntp", "date": "2024-01-09 03:50:00 +0000", "snippet": "背景NTP是Network Time Protocal，被计算机分布式服务依赖，用来同步。一旦时间服务器与客户端时间差异较大，分布式服务通信可能出问题。virtual machine（下文以“虚拟机”代替）以其轻量、标准化、预置快，在如今使用的越来越频繁。也有很多人使用它来提供ntp服务。分析虚拟机没有硬件时钟源，它仅由虚拟机监控程序提供服务，尽管提供了一个名为 kvm-clock 的半虚拟...", "content": "背景NTP是Network Time Protocal，被计算机分布式服务依赖，用来同步。一旦时间服务器与客户端时间差异较大，分布式服务通信可能出问题。virtual machine（下文以“虚拟机”代替）以其轻量、标准化、预置快，在如今使用的越来越频繁。也有很多人使用它来提供ntp服务。分析虚拟机没有硬件时钟源，它仅由虚拟机监控程序提供服务，尽管提供了一个名为 kvm-clock 的半虚拟化驱动程序作为更准确的时钟源。此外，虚拟机也可能被暂停，或从一台宿主机漂移到另一台宿主机，这时由不同的hypervisor提供服务，导致提供的NTP不可靠。在KVM虚拟机中，NTP 服务器提供的 NTP 时间的精度和准确性不足以在无更高层 NTP 服务器的情况下提供 NTP 服务。NTP 服务器不是为在虚拟机内部运行而设计的。它需要高分辨率的系统时钟，对时钟中断的响应时间具有很高的精度。参考资料https://access.redhat.com/solutions/361803https://access.redhat.com/site/documentation/en-US/Red_Hat_Enterprise_Linux/6/html/Virtualization_Host_Configuration_and_Guest_Installation_Guide/chap-Virtualization_Host_Configuration_and_Guest_Installation_Guide-KVM_guest_timing_management.html" }, { "title": "升级ipa并保持用户与群组等数据同步，降低用户上手成本", "url": "/posts/upgrading-ipa-server-without-changing-end-user-password/", "categories": "icenv", "tags": "ipa", "date": "2024-01-09 02:50:00 +0000", "snippet": "背景由于CentOS 7/8的EOL，IC设计环境的IT底座之一————操作系统，其升级被提上日程。其中涉及到在旧版本操作系统上的FreeIPA的升级。思考开始，计划在一台新操作系统上做fresh FreeIPA installation，给升级上去的操作系统使用即可。后来，考虑在过渡期间需要维护两套FreeIPA，需要从旧FreeIPA里同步用户/群组到新FreeIPA，并且两套系统内用户...", "content": "背景由于CentOS 7/8的EOL，IC设计环境的IT底座之一————操作系统，其升级被提上日程。其中涉及到在旧版本操作系统上的FreeIPA的升级。思考开始，计划在一台新操作系统上做fresh FreeIPA installation，给升级上去的操作系统使用即可。后来，考虑在过渡期间需要维护两套FreeIPA，需要从旧FreeIPA里同步用户/群组到新FreeIPA，并且两套系统内用户的密码不能够保持统一。查阅了红帽官网升级的相关资料，决定使用Replica的方式来使得新旧FreeIPA数据同步，也能够保持用户的密码一致，降低用户的上手成本。升级方案架构图升级的过渡期间，FreeIPA master-replica架构图，如下所示：+---------------------+ +----------------------------+| | | || CentOS 7 VM | | AlmaLinux 8 VM || | | || +-------------+ | | +--------------------+ || | | | | | | || | FreeIPA | | | | AlmaLinux 8 | || | Server | | | | Container | || | (Master) | | | | | || | version: | | Replication| | +----------------+ | || | 4.6.8 &lt;----------------------&gt; | | || +-------------+ | | | | FreeIPA | | || | | | | Server | | |+---------------------+ | | | (Replica) | | | | | | | version: | | | | | | | 4.9.12 | | | | | | +----------------+ | | | | | | | | | +--------------------+ | | | |+------------+ +----------------------------+| Client Host| || Group | || (for | || Master) | |+------------+ | +---------------+ | Client Host | | Group | | (for | | Replica) | +---------------+其中，CentOS 7 VM里的是直接安装启动的FreeIPA Server。在AlmaLinux 8 VM里运行的AlmaLinux 8 Container里运行FreeIPA Server Replica。这里使用容器来承载新FreeIPA Server，主要考虑到容器环境可以做到标准化，数据通过持久化到容器宿主机（AlmaLinux 8 VM）的目录下，再定期快照备份容器宿主机（AlmaLinux 8 VM）。相关命令# CentOS 7.9虚拟机上，安装FreeIPA Master。sudo su -yum install -y freeipa-server ipa-server-dns &gt;&amp; /dev/nullfirewall-cmd --add-service={freeipa-ldap,freeipa-ldaps,dns,mountd,rpc-bind} --permanent &amp;&amp; firewall-cmd --reload\"172.16.0.100 centos-7-ipa-server.icinfra.cn\" | tee -a /etc/hostscp -a /etc/hosts /etc/cloud/templates/hosts.redhat.tmpl ipa-server-install --setup-dns --domain=icinfra.cn --realm=ICINFRA.CN --hostname=centos-7-ipa-server.icinfra.cn --admin-password=12345678 --ds-password=12345678 --no-reverse --allow-zone-overlap --auto-forwarders -U# AlmaLinux 8虚拟机上，运行容器并初始化安装FreeIPA Replica。sudo su -dnf install -y podmanfirewall-cmd --add-service={freeipa-ldap,freeipa-ldaps,dns,mountd,rpc-bind} --permanent &amp;&amp; sudo firewall-cmd --reload# 初次运行mkdir /var/lib/ipa-datapodman run -ti --rm \\ -h almalinux-8-ipa-server.icinfra.cn \\ --net=host \\ --dns 172.16.0.100 \\ --dns-search icinfra.cn \\ -v /var/lib/ipa-data:/data:Z \\ --add-host=centos-7-ipa-server.icinfra.cn:172.16.0.100 \\ --add-host=almalinux-8-ipa-server.icinfra.cn:172.16.0.101 \\ -e TZ=Asia/Shanghai \\ freeipa/freeipa-server:almalinux-8 ipa-replica-install \\ --force-join \\ --setup-ca \\ --setup-dns \\ --server centos-7-ipa-server.icinfra.cn \\ --domain icinfra.cn \\ --ip-address 172.16.0.101 \\ --no-forwarders \\ --no-ntp \\ --principal admin \\ --admin-password 12345678# 这样安装的replica，比master少了ntpd server。看下如何将这个也安装上。补充原因：由于容器实际上使用的是宿主机的时间，因此可以忽略。# 如果因定位问题，需要在容器里执行strace，则在宿主机以及容器里，都要将selinux关掉。sudo setenforce 0# 初始化完成之后，即/var/lib/ipa-data目录已经populated数据，下一次可以以后台的方式运行。podman run -d --rm \\ -h almalinux-8-ipa-server.icinfra.cn \\ --net=host \\ --dns 172.16.0.100 \\ --dns-search icinfra.cn \\ -v /var/lib/ipa-data:/data:Z \\ --add-host=centos-7-ipa-server.icinfra.cn:172.16.0.100 \\ --add-host=almalinux-8-ipa-server.icinfra.cn:172.16.0.101 \\ -e TZ=Asia/Shanghai \\ freeipa/freeipa-server:almalinux-8 \\ ipa-replica-install \\ --force-join \\ --setup-ca \\ --setup-dns \\ --server centos-7-ipa-server.icinfra.cn \\ --domain icinfra.cn \\ --ip-address 172.16.0.101 \\ --no-forwarders \\ --no-ntp \\ --principal admin \\ --admin-password 12345678# 新客户端系统加入 almalinux-8-ipa-server.icinfra.cn 这个FreeIPAdnf install -y freeipa-client podmancat &gt; /etc/resolv.conf &lt;&lt; EOFsearch icinfra.cnnameserver 172.16.0.101EOFipa-client-install --force-join --hostname=almalinux-8-ipa-client.icinfra.cn --domain=icinfra.cn --server=almalinux-8-ipa-server.icinfra.cn --enable-dns-updates --principal=admin --password=12345678 -U测试项用户/群组同步包括用户/群组的ID/Subordinate ID以及相关信息的同步。需要注意的是，CentOS 7 VM里自带的FreeIPA Server是不支持Subordinate ID的，因此需要重点关注对它的测试————比如在AlmaLinux 8 Container上的FreeIPA Server创建的Subordinate ID能否被持久化保存，并被正常使用。测试通过，见打开ipa用户的subid(subordinate id)以运行rootless容器。域名解析DNS forwarder遇到些问题，需要进一步定位。时间同步TODO其它项参考资料IdM从非RHEL发行版迁移至RHEL8FreeIPA Replica SetupIdM Replica安装" }, { "title": "CentOS 7 & 8 EOL事宜，以及替代方案介绍", "url": "/posts/centos-7-and-8-eol/", "categories": "icenv", "tags": "os", "date": "2024-01-05 03:20:00 +0000", "snippet": "背景截止至2023年末，芯片设计公司，除了少量订阅RHEL用作发生故障时的救命稻草，普遍在使用CentOS操作系统（RHEL的一个衍生发行版），其中以CentOS 7居多，少部分技术债较低的团队“尝鲜”了CentOS 8操作系统。甚至因历史项目依赖的工具链版本较旧，还有不少CentOS 6.10的存量系统。根据CentOS Linux is reaching its end of life....", "content": "背景截止至2023年末，芯片设计公司，除了少量订阅RHEL用作发生故障时的救命稻草，普遍在使用CentOS操作系统（RHEL的一个衍生发行版），其中以CentOS 7居多，少部分技术债较低的团队“尝鲜”了CentOS 8操作系统。甚至因历史项目依赖的工具链版本较旧，还有不少CentOS 6.10的存量系统。根据CentOS Linux is reaching its end of life. Now what?官方公布消息来看，CentOS 8已在2021.12.31不再更新发布，CentOS Stream 8将于2024.05.31不再更新发布，CentOS 7将于2024.06.30不再更新发布。企业内正在使用的系统EOL后，企业的IT管理员应该如何应对？分析总结参考资料" }, { "title": "FreeIPA/IdM服务器（即将/已）过期的证书的处理方法", "url": "/posts/ipa-expired-certificates-renewal/", "categories": "icenv", "tags": "ipa", "date": "2024-01-03 07:20:00 +0000", "snippet": "背景FreeIPA/IdM服务器，默认Certificate Authority certificate的有效期为20年，host or service certificate有效期为2年。FreeIPA/IdM服务器在安装时，默认使用了Certmonger来auto renew证书。场景有些公司出于安全需求，禁止了auto renew的策略。假如没有打开auto renew， 如何手动更...", "content": "背景FreeIPA/IdM服务器，默认Certificate Authority certificate的有效期为20年，host or service certificate有效期为2年。FreeIPA/IdM服务器在安装时，默认使用了Certmonger来auto renew证书。场景有些公司出于安全需求，禁止了auto renew的策略。假如没有打开auto renew， 如何手动更新即将过期的certificate？ 如何手动修复已经过期的certificate？更新即将过期的certificate参考1，IPA &gt;= 4.1，在FreeIPA服务器执行ipa-cacert-manage renew。IPA &lt; 4.1的例子：略。修复已经过期的certificate测试环境这里构建一个测试环境，模拟证书过期的场景。 参考CentOS 7.9上部署高可用FreeIPA服务器一文，安装好FreeIPA服务器与客户端。 [centos@CentOS7-ipa-server ~]$ kinit adminPassword for admin@ICINFRA.CN: [centos@CentOS7-ipa-server ~]$ ipa user-find--------------1 user matched--------------User login: adminLast name: AdministratorHome directory: /home/adminLogin shell: /bin/bashPrincipal alias: admin@ICINFRA.CNUID: 450000000GID: 450000000Account disabled: False----------------------------Number of entries returned 1---------------------------- 在FreeIPA服务器与客户端，分别操作：将时间同步服务断开，并将时间设置到将来的2年后，模拟证书过期。命令如下： [centos@CentOS7-ipa-server ~]$ sudo date --set=\"`date -d '+2 years' '+%Y-%m-%d %H:%M:%S'`\"Sat Jan 3 20:36:47 EST 2026[centos@CentOS7-ipa-server ~]$ ipa user-findipa: ERROR: cannot connect to 'https://ipa-server-01.icinfra.cn/ipa/json': [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed (_ssl.c:618)[centos@CentOS7-ipa-server ~]$ sudo ipactl restart --ignore-service-failureRestarting Directory ServiceRestarting krb5kdc ServiceRestarting kadmin ServiceRestarting named ServiceRestarting httpd ServiceFailed to restart httpd ServiceForced restart, ignoring httpd Service, continuing normal operationRestarting ipa-custodia ServiceRestarting ntpd ServiceRestarting pki-tomcatd Service 更新证书在FreeIPA服务器上，执行sudo ipa-cert-fix修复过期的证书。[centos@CentOS7-ipa-server ~]$ sudo ipa-cert-fix WARNINGipa-cert-fix is intended for recovery when expired certificatesprevent the normal operation of IPA. It should ONLY be usedin such scenarios, and backup of the system, especially certificatesand keys, is STRONGLY RECOMMENDED.The following certificates will be renewed: Dogtag sslserver certificate: Subject: CN=ipa-server-01.icinfra.cn,O=ICINFRA.CN Serial: 3 Expires: 2025-12-24 01:32:38Dogtag subsystem certificate: Subject: CN=CA Subsystem,O=ICINFRA.CN Serial: 4 Expires: 2025-12-24 01:32:38Dogtag ca_ocsp_signing certificate: Subject: CN=OCSP Subsystem,O=ICINFRA.CN Serial: 2 Expires: 2025-12-24 01:32:38Dogtag ca_audit_signing certificate: Subject: CN=CA Audit,O=ICINFRA.CN Serial: 5 Expires: 2025-12-24 01:32:38IPA IPA RA certificate: Subject: CN=IPA RA,O=ICINFRA.CN Serial: 7 Expires: 2025-12-24 01:32:52IPA Apache HTTPS certificate: Subject: CN=ipa-server-01.icinfra.cn,O=ICINFRA.CN Serial: 9 Expires: 2026-01-04 01:33:26IPA LDAP certificate: Subject: CN=ipa-server-01.icinfra.cn,O=ICINFRA.CN Serial: 8 Expires: 2026-01-04 01:33:11IPA KDC certificate: Subject: CN=ipa-server-01.icinfra.cn,O=ICINFRA.CN Serial: 10 Expires: 2026-01-04 01:33:34Enter \"yes\" to proceed: yesProceeding.Renewed Dogtag sslserver certificate: Subject: CN=ipa-server-01.icinfra.cn,O=ICINFRA.CN Serial: 11 Expires: 2027-12-25 01:47:51Renewed Dogtag subsystem certificate: Subject: CN=CA Subsystem,O=ICINFRA.CN Serial: 12 Expires: 2027-12-25 01:47:51Renewed Dogtag ca_ocsp_signing certificate: Subject: CN=OCSP Subsystem,O=ICINFRA.CN Serial: 13 Expires: 2027-12-25 01:47:52Renewed Dogtag ca_audit_signing certificate: Subject: CN=CA Audit,O=ICINFRA.CN Serial: 14 Expires: 2027-12-25 01:47:52Renewed IPA IPA RA certificate: Subject: CN=IPA RA,O=ICINFRA.CN Serial: 15 Expires: 2027-12-25 01:47:52Renewed IPA Apache HTTPS certificate: Subject: CN=ipa-server-01.icinfra.cn,O=ICINFRA.CN Serial: 16 Expires: 2028-01-05 01:47:52Renewed IPA LDAP certificate: Subject: CN=ipa-server-01.icinfra.cn,O=ICINFRA.CN Serial: 17 Expires: 2028-01-05 01:47:53Renewed IPA KDC certificate: Subject: CN=ipa-server-01.icinfra.cn,O=ICINFRA.CN Serial: 18 Expires: 2028-01-05 01:47:53Becoming renewal master.The ipa-cert-fix command was successful[centos@CentOS7-ipa-server ~]$ sudo ipactl restartRestarting Directory ServiceRestarting krb5kdc ServiceRestarting kadmin ServiceRestarting named ServiceRestarting httpd ServiceRestarting ipa-custodia ServiceRestarting ntpd ServiceRestarting pki-tomcatd ServiceRestarting ipa-otpd ServiceRestarting ipa-dnskeysyncd Serviceipa: INFO: The ipactl command was successful[centos@CentOS7-ipa-server ~]$ sudo ipactl statusDirectory Service: RUNNINGkrb5kdc Service: RUNNINGkadmin Service: RUNNINGnamed Service: RUNNINGhttpd Service: RUNNINGipa-custodia Service: RUNNINGntpd Service: RUNNINGpki-tomcatd Service: RUNNINGipa-otpd Service: RUNNINGipa-dnskeysyncd Service: RUNNINGipa: INFO: The ipactl command was successful完成。使用getcert list命令查看，已经延期了。参考资料https://www.freeipa.org/page/Certificate_renewalhttps://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/identity_management_guide/certmonger-tracking-certshttps://frasertweedale.github.io/blog-redhat/posts/2019-12-12-certmonger-disable-auto-renew.html https://www.freeipa.org/page/Howto/CA_Certificate_Renewal &#8617;&#xfe0e; " }, { "title": "如何使用vim插件", "url": "/posts/vim-plugins-usage/", "categories": "icenv", "tags": "vim", "date": "2023-12-27 07:20:00 +0000", "snippet": "本文，以缩进插件 https://github.com/tabulapdf/tabula/releases 为例。下载1.0.0版本存放至 /tools/opensrc/vim-plugins/tabular/1.0.0 目录。在 ~/.vimrc 里增加一行set runtimepath+=/tools/opensrc/vim-plugins/tabular/1.0.0", "content": "本文，以缩进插件 https://github.com/tabulapdf/tabula/releases 为例。下载1.0.0版本存放至 /tools/opensrc/vim-plugins/tabular/1.0.0 目录。在 ~/.vimrc 里增加一行set runtimepath+=/tools/opensrc/vim-plugins/tabular/1.0.0" }, { "title": "prompt工程", "url": "/posts/prompt-engineering/", "categories": "ai", "tags": "gpt", "date": "2023-12-17 14:20:00 +0000", "snippet": "本指南分享了从 GPT-4 等大型语言模型（有时称为 GPT 模型）中获得更好结果的策略和策略。这里描述的方法有时可以组合使用，以获得更大的效果。我们鼓励您进行实验，以找到最适合您的方法。此处演示的一些示例目前仅适用于我们功能最强大的模型 gpt-4。通常，如果发现某个模型在某项任务中失败，并且有功能更强大的模型可用，则通常值得使用功能更强大的模型再次尝试。您还可以浏览示例提示，这些提示展示...", "content": "本指南分享了从 GPT-4 等大型语言模型（有时称为 GPT 模型）中获得更好结果的策略和策略。这里描述的方法有时可以组合使用，以获得更大的效果。我们鼓励您进行实验，以找到最适合您的方法。此处演示的一些示例目前仅适用于我们功能最强大的模型 gpt-4。通常，如果发现某个模型在某项任务中失败，并且有功能更强大的模型可用，则通常值得使用功能更强大的模型再次尝试。您还可以浏览示例提示，这些提示展示了我们的模型的功能：获得更好结果的6种策略写出清晰的指令这些模型无法读懂你的心思。如果输出太长，请要求简短回复。如果输出太简单，请要求专家级写作。如果您不喜欢该格式，请展示您希望看到的格式。模型越少猜测你想要什么，你就越有可能得到想要的结果。策略： 在查询中包含详细信息以获得更相关的答案 要求模型采用角色 使用分隔符清楚地指示输入的不同部分 指定完成任务所需的步骤 举例说明 指定所需的输出长度提供参考文本语言模型可以自信地发明虚假答案，尤其是在被问及深奥的主题或引文和 URL 时。就像一张笔记可以帮助学生在考试中做得更好一样，为这些模型提供参考文本可以帮助以更少的捏造来回答。策略： 指示模型使用参考文本回答 指示模型使用参考文本中的引文进行回答将复杂的任务拆分为更简单的子任务正如在软件工程中将复杂系统分解为一组模块化组件是很好的做法一样，提交给语言模型的任务也是如此。复杂任务往往比简单任务具有更高的错误率。此外，复杂任务通常可以重新定义为更简单任务的工作流，其中早期任务的输出用于构建后续任务的输入。策略： 使用意向分类来识别与用户查询最相关的说明 对于需要很长对话的对话应用程序，请总结或筛选上一个对话 分段总结长文档，递归构建完整摘要给模型时间“思考”如果被要求将 17 乘以 28，您可能不会立即知道，但仍然可以随着时间的推移而计算出来。同样，模型在试图立即回答时会犯更多的推理错误，而不是花时间找出答案。在回答之前询问“思维链”可以帮助模型更可靠地推理出正确答案。策略： 在匆忙得出结论之前，指示模型制定自己的解决方案 使用内心独白或一系列查询来隐藏模型的推理过程 询问模型在之前的传递中是否遗漏了任何内容使用外部工具通过向模型提供其他工具的输出来弥补模型的弱点。例如，文本检索系统（有时称为 RAG 或检索增强生成）可以告诉模型相关文档。像 OpenAI 的 Code Interpreter 这样的代码执行引擎可以帮助模型进行数学运算和运行代码。如果一项任务可以通过工具而不是语言模型更可靠或更高效地完成，请卸载它以充分利用两者。策略： 使用基于嵌入的搜索实现高效的知识检索 使用代码执行来执行更准确的计算或调用外部 API 授予模型对特定函数的访问权限系统地测试更改如果可以衡量性能，则更容易提高性能。在某些情况下，对提示的修改将在一些孤立的示例上获得更好的性能，但在一组更具代表性的示例上会导致整体性能变差。因此，为了确保更改对性能有净积极影响，可能需要定义一个全面的测试套件（也称为“评估”）。策略： 参考黄金标准答案评估模型输出策略上面列出的每个策略都可以用特定的策略进行实例化。这些策略旨在为尝试提供想法。但不是全部，您应该随意尝试此处未提及的其他创意。策略：写出清晰的指令策略：在查询中包含详细信息以获得更相关的答案为了获得高度相关的响应，请确保请求提供任何重要的详细信息或上下文。否则，你就要让模型来猜测你的意思了。 更糟 更好 如何在Excel中添加数字？ 如何在Excel中将一行美元金额相加？我想自动为整张行表执行此操作，所有总数都位于名为“Total”的列的右侧。 谁是总统？ 2021年谁是墨西哥总统，选举多久举行一次？ 编写代码来计算斐波那契数列。 编写一个 TypeScript 函数来有效地计算斐波那契数列。对代码进行宽松的注释，以解释每个部分的作用以及为什么这样编写。 总结会议记录。 用一个段落总结会议记录。然后写下演讲者的降价列表和他们的每个关键点。最后，列出演讲者建议的后续步骤或行动项目（如果有的话）。 策略：要求模型采用角色系统消息可用于指定模型在其回复中使用的角色。     系统 当我请求帮助写东西时，你会回复一份文档，每个段落中至少包含一个笑话或俏皮的评论。 用户 给我的钢螺栓供应商写一封感谢信，感谢他们在短时间内按时交货。这使我们能够交付一个重要的订单。 策略：使用分隔符清楚地指示输入的不同部分三引号、XML 标记、章节标题等分隔符可以帮助划分要区别对待的文本部分。     用户 用俳句总结用三引号分隔的文本。&lt;/br&gt;&lt;/br&gt;“”“在此处插入文本”“”     系统 您将获得两篇关于同一主题的文章（用 XML 标记分隔）。首先总结一下每篇文章的论点。然后指出他们中的哪一个提出了更好的论点并解释原因。 用户 &lt;article&gt;在此处插入第一篇文章 &lt;/article&gt;&lt;/br&gt;&lt;/br&gt;&lt;article&gt;在此处插入第二篇文章 &lt;/article&gt;     系统 您将获得论文摘要和建议的标题。论文标题应该让读者对论文的主题有一个很好的了解，但也应该引人注目。如果标题不符合这些标准，请建议 5 个替代方案。 用户 摘要：在此处插入摘要&lt;/br&gt;&lt;/br&gt;标题：在此处插入标题 对于此类简单任务，使用分隔符可能不会对输出质量产生影响。但是，任务越复杂，消除任务细节的歧义就越重要。不要让模型确切地理解你对他们的要求。策略：指定完成任务所需的步骤某些任务最好指定为一系列步骤。显式写出这些步骤可以使模型更容易遵循它们。     系统 使用以下分步说明来响应用户输入。&lt;/br&gt;第 1 步 - 用户将为您提供三引号中的文本。用一句话总结这段文字，前缀是“摘要：”。&lt;/br&gt;第 2 步 - 将第 1 步中的摘要翻译成西班牙语，前缀为“翻译：”。 用户 “”“在此处插入文本”“” 策略：举例说明提供适用于所有示例的一般说明通常比通过示例演示任务的所有排列更有效，但在某些情况下，提供示例可能更容易。例如，如果您打算让模型复制响应用户查询的特定样式，这很难显式描述。这被称为“小镜头”提示。     系统 以一致的风格回答。 用户 教我忍耐。 助理 雕刻最深谷的河流从一汪不起眼的泉水流出;最伟大的交响曲起源于一个音符;最复杂的挂毯始于一根孤独的线。 用户 教我关于海洋的知识。 策略：指定所需的输出长度您可以要求模型生成具有给定目标长度的输出。目标输出长度可以根据单词、句子、段落、项目符号等的数量来指定。但请注意，指示模型生成特定数量的单词并不能高精度地工作。该模型可以更可靠地生成具有特定数量的段落或项目符号的输出。     用户 用三引号分隔的文本总结在大约 50 个单词中。&lt;/br&gt;&lt;/br&gt;“”“在此处插入文本”“”     用户 总结 2 段中用三引号分隔的文本。&lt;/br&gt;&lt;/br&gt;“”“在此处插入文本”“”     用户 总结用三引号分隔的文本，分为 3 个要点。&lt;/br&gt;&lt;/br&gt;“”“在此处插入文本”“” 策略：提供参考文本策略：指示模型使用参考文本进行回答如果我们能够为模型提供与当前查询相关的可信信息，那么我们可以指示模型使用提供的信息来撰写其答案。     系统 使用提供的文章（用三引号分隔）来回答问题。如果在文章中找不到答案，请写“我找不到答案”。 用户 &lt;插入文章，每篇文章用三引号分隔&gt;&lt;/br&gt;&lt;/br&gt;问题： 鉴于所有模型的上下文窗口都有限，我们需要某种方法来动态查找与所问问题相关的信息。嵌入可用于实现高效的知识检索。有关如何实现此策略的更多详细信息，请参阅策略“使用基于嵌入的搜索实现高效的知识检索”。策略：指示模型使用参考文本中的引文来回答如果输入已补充相关知识，则直接要求模型通过引用所提供文档中的段落来为其答案添加引文。请注意，输出中的引文可以通过提供的文档中的字符串匹配以编程方式进行验证。     系统 您将获得一份由三引号分隔的文件和一个问题。您的任务是仅使用提供的文档回答问题，并引用用于回答问题的文档的段落。如果文档不包含回答此问题所需的信息，则只需写：“信息不足”。如果提供了问题的答案，则必须用引文进行注释。使用以下格式引用相关段落 （{“citation”： …}）。 用户 “”“”“”&lt;/br&gt;&lt;/br&gt;问题： 策略：将复杂的任务拆分为更简单的子任务策略：使用意向分类来识别与用户查询最相关的说明对于需要大量独立指令集来处理不同情况的任务，首先对查询类型进行分类，然后使用该分类来确定需要哪些指令，这可能是有益的。这可以通过定义与处理给定类别中的任务相关的固定类别和硬编码指令来实现。此过程也可以递归应用，以将任务分解为一系列阶段。这种方法的优点是，每个查询将仅包含执行任务下一阶段所需的那些指令，与使用单个查询执行整个任务相比，这可能会导致更低的错误率。这也可以降低成本，因为较大的提示的运行成本更高（请参阅[定价信息(https://openai.com/pricing)]）。例如，假设对于客户服务应用程序，查询可以按如下方式进行有用的分类：根据客户查询的分类，可以向模型提供一组更具体的指令，以便其处理后续步骤。例如，假设客户需要“故障排除”方面的帮助。请注意，已指示模型发出特殊字符串，以指示会话状态何时更改。这使我们能够将系统变成一个状态机，其中状态决定了注入哪些指令。通过跟踪状态、在该状态下哪些指令是相关的，以及可以选择允许从该状态进行哪些状态转换，我们可以围绕用户体验设置护栏，而这些保护措施很难用不太结构化的方法实现。策略：对于需要很长对话的对话应用程序，总结或筛选之前的对话由于模型具有固定的上下文长度，因此用户和助手之间的对话（其中整个对话包含在上下文窗口中）不能无限期地继续。此问题有多种解决方法，其中之一是总结对话中的前一轮。一旦输入的大小达到预定的阈值长度，这可能会触发一个查询，该查询汇总了部分会话，并且先前会话的摘要可以作为系统消息的一部分包含在内。或者，可以在整个对话中在后台异步总结先前的对话。另一种解决方案是动态选择与当前查询最相关的对话的先前部分。请参阅策略“使用基于嵌入的搜索实现高效的知识检索”。策略：分段总结长文档，递归构建完整摘要由于模型具有固定的上下文长度，因此它们不能用于汇总长度超过上下文长度减去单个查询中生成的摘要长度的文本。为了总结一个很长的文档，比如一本书，我们可以使用一系列查询来总结文档的每个部分。章节摘要可以连接和汇总，从而生成摘要的摘要。此过程可以递归方式进行，直到对整个文档进行汇总。如果有必要使用有关前面部分的信息来理解后面的部分，那么另一个有用的技巧是，在总结该点的内容时，包括书中任何给定点之前的文本的连续摘要。OpenAI 之前使用 GPT-3 变体的研究中已经研究了这种总结书籍程序的有效性。策略：给模型“思考”的时间策略：在匆忙得出结论之前，指示模型制定自己的解决方案有时，当我们明确指示模型在得出结论之前从第一性原理进行推理时，我们会得到更好的结果。例如，假设我们想要一个模型来评估学生对数学问题的解决方案。最明显的方法是简单地询问模型学生的解决方案是否正确。但学生的解法其实是不对的！我们可以通过提示模型首先生成自己的解决方案来让模型成功注意到这一点。策略：使用内心独白或一系列查询来隐藏模型的推理过程前面的策略表明，模型在回答特定问题之前详细推理问题有时很重要。对于某些应用程序，模型用于得出最终答案的推理过程不适合与用户共享。例如，在辅导应用中，我们可能希望鼓励学生自己找出答案，但模型对学生解决方案的推理过程可能会向学生揭示答案。内心独白是一种可以用来缓解这种情况的策略。内心独白的思想是指示模型将输出中对用户隐藏的部分转换为结构化格式，以便轻松解析它们。然后，在将输出呈现给用户之前，将解析输出，并且仅显示部分输出。或者，这可以通过一系列查询来实现，其中除最后一个查询外的所有查询都对最终用户隐藏其输出。首先，我们可以要求模型自行解决问题。由于此初始查询不需要学生的解决方案，因此可以省略它。这提供了额外的优势，即模型的解决方案不会因学生尝试的解决方案而产生偏差。     用户 接下来，我们可以让模型使用所有可用信息来评估学生解决方案的正确性。最后，我们可以让模型使用自己的分析来构建一个乐于助人的导师角色的回复。策略：询问模型在之前的传递中是否遗漏了任何内容假设我们正在使用一个模型来列出与特定问题相关的来源摘录。列出每个摘录后，模型需要确定是否应该开始编写另一个摘录，或者是否应该停止。如果源文档很大，模型通常会过早停止并且无法列出所有相关的摘录。在这种情况下，通常可以通过提示模型进行后续查询来查找它在以前的传递中遗漏的任何摘录，从而获得更好的性能。策略：使用外部工具策略：使用基于嵌入的搜索实现高效的知识检索如果模型作为其输入的一部分提供，则可以利用外部信息源。这可以帮助模型生成更明智和最新的响应。例如，如果用户询问有关特定电影的问题，则将有关电影的高质量信息（例如演员、导演等）添加到模型的输入中可能很有用。嵌入可用于实现高效的知识检索，从而可以在运行时将相关信息动态添加到模型输入中。文本嵌入是一种向量，可以测量文本字符串之间的相关性。相似或相关的字符串将比不相关的字符串更紧密地联系在一起。这一事实，加上快速向量搜索算法的存在，意味着嵌入可用于实现有效的知识检索。特别是，文本语料库可以拆分为多个块，每个块都可以嵌入和存储。然后，可以嵌入给定的查询，并执行向量搜索，以从语料库中查找与查询最相关的嵌入文本块（即在嵌入空间中最接近的文本块）。示例实现可以在 OpenAI Cookbook 中找到。有关如何使用知识检索来最大程度地降低模型编造错误事实的可能性的示例，请参阅策略“指示模型使用检索到的知识来回答查询”。策略：使用代码执行来执行更准确的计算或调用外部 API不能依赖语言模型自行准确地执行算术或长计算。如果需要，可以指示模型编写和运行代码，而不是进行自己的计算。特别是，可以指示模型将要运行的代码放入指定格式，例如三重反引号。生成输出后，可以提取并运行代码。最后，如有必要，可以将代码执行引擎（即 Python 解释器）的输出作为下一个查询的模型输入。     系统 您可以通过将 Python 代码括在三个反引号中来编写和执行 Python 代码，例如 ‘'’code goes here’’‘。使用它来执行计算。 用户 求出以下多项式的所有实值根：3x5 - 5*x4 - 3x*3 - 7x - 10。 代码执行的另一个很好的用例是调用外部 API。如果模型被指示正确使用 API，它可以编写使用它的代码。通过向模型提供演示如何使用 API 的文档和/或代码示例，可以指导模型如何使用 API。     系统 您可以通过将 Python 代码括在三重反引号中来编写和执行 Python 代码。另请注意，您可以访问以下模块来帮助用户向其朋友发送消息：&lt;/br&gt;&lt;/br&gt;’'’python&lt;/br&gt;import message&lt;/br&gt;message.write（to=“John”， message=“嘿，下班后想见面吗？’’’ ** 警告：执行模型生成的代码本身并不安全，任何试图执行此操作的应用程序都应采取预防措施。特别是，需要一个沙盒代码执行环境来限制不受信任的代码可能造成的危害。 **策略：授予模型对特定函数的访问权限聊天完成 API 允许在请求中传递函数描述列表。这使模型能够根据提供的架构生成函数参数。生成的函数参数由 API 以 JSON 格式返回，可用于执行函数调用。然后，可以在以下请求中将函数调用提供的输出反馈到模型中以关闭循环。这是使用 OpenAI 模型调用外部函数的推荐方式。要了解更多信息，请参阅我们介绍性文本生成指南中的函数调用部分，以及 OpenAI Cookbook 中的更多函数调用示例。策略：系统地测试更改有时很难判断更改（例如，新指令或新设计）是使您的系统变得更好还是更糟。看几个例子可能会暗示哪个更好，但是在样本量较小的情况下，很难区分真正的改进还是随机的运气。也许这种变化有助于某些输入的性能，但会损害其他输入的性能。评估程序（或“评估”）对于优化系统设计非常有用。好的评估是： 代表现实世界的用法（或至少是多样化的） 包含许多测试用例以获得更高的统计能力（请参阅下表以获取指南） 易于自动化或重复输出的评估可以由计算机、人类或混合完成。计算机可以使用客观标准（例如，具有单个正确答案的问题）以及一些主观或模糊标准自动执行评估，其中模型输出由其他模型查询评估。OpenAI Evals是一个开源软件框架，提供用于创建自动评估的工具。当存在一系列被认为质量同样高的可能输出时，基于模型的评估可能很有用（例如，对于答案很长的问题）。使用基于模型的评估可以实际评估的内容与需要人工评估的内容之间的界限是模糊的，并且随着模型功能的增强而不断变化。我们鼓励进行实验，以确定基于模型的评估对您的用例的效果如何。策略：参考黄金标准答案评估模型输出假设已知问题的正确答案应参考一组特定的已知事实。然后，我们可以使用模型查询来计算答案中包含多少必需的事实。例如，使用以下系统消息：下面是一个示例输入，其中两个点都得到满足：下面是一个示例输入，其中仅满足一个点：下面是一个示例输入，一个都不满足：这种类型的基于模型的评估有许多可能的变体。考虑以下变体，该变体跟踪候选答案和黄金标准答案之间的重叠类型，并跟踪候选答案是否与黄金标准答案的任何部分相矛盾。下面是一个带有不合格答案的示例输入，但与专家答案并不矛盾：下面是一个带有答案的示例输入，该答案与专家答案直接矛盾：下面是一个带有正确答案的示例输入，该输入还提供了比必要内容更多的详细信息：参考资料https://platform.openai.com/docs/guides/prompt-engineering" }, { "title": "FreeIPA用户生命周期", "url": "/posts/ipa-user-life-cycle/", "categories": "icenv", "tags": "ipa", "date": "2023-12-17 14:00:00 +0000", "snippet": "图片来源：User Life Cycle Operations在用户生命周期管理操作中，为了管理用户的配置，管理员可以将用户账户从一个状态移动到另一个状态。新的用户账户可以作为 active 或 stage 添加，但不能作为 preserved 添加。FreeIPA 支持以下用户生命周期管理操作： stage → active: 当处于 stage 状态的账户准备好被正式激活时，管理员将其...", "content": "图片来源：User Life Cycle Operations在用户生命周期管理操作中，为了管理用户的配置，管理员可以将用户账户从一个状态移动到另一个状态。新的用户账户可以作为 active 或 stage 添加，但不能作为 preserved 添加。FreeIPA 支持以下用户生命周期管理操作： stage → active: 当处于 stage 状态的账户准备好被正式激活时，管理员将其移动到 active 状态。 active → preserved: 员工离开公司后，管理员将其账户移动到 preserved 状态。 preserved → active: 前员工重新加入公司。管理员通过将其账户从 preserved 状态移回 active 状态来恢复员工账户。 preserved → stage: 前员工计划重新加入公司。管理员将其账户从 preserved 状态移动到 stage 状态，以准备账户的后续重新激活。还可以从 FreeIPA 中永久删除 active、stage 和 preserved 用户。请注意，不能将 stage 用户移动到 preserved 状态，只能永久删除它们。" }, { "title": "FreeIPA运行于容器", "url": "/posts/deploy-freeipa-with-docker/", "categories": "icenv", "tags": "ipa", "date": "2023-12-17 02:00:00 +0000", "snippet": "FreeIPA Server在almalinux-8容器的初始化与运行1）初始化安装 生成数据文件夹，存放在/data/ipa-data目录 直接使用宿主机网络 mkdir -p /data/ipa-datapodman run \\--rm \\--shm-size=2GB \\--name ipa-01.icinfra.cn \\--net host \\-ti \\-h ipa-01.i...", "content": "FreeIPA Server在almalinux-8容器的初始化与运行1）初始化安装 生成数据文件夹，存放在/data/ipa-data目录 直接使用宿主机网络 mkdir -p /data/ipa-datapodman run \\--rm \\--shm-size=2GB \\--name ipa-01.icinfra.cn \\--net host \\-ti \\-h ipa-01.icinfra.cn \\--read-only \\-e PASSWORD=Secret123 \\-v /data/ipa-data:/data:Z \\--dns=127.0.0.1 \\-e TZ=Asia/Shanghai \\-v /etc/localtime:/etc/localtime:ro \\--add-host=ipa-01.icinfra.cn:172.16.0.13 \\docker.io/freeipa/freeipa-server:almalinux-8 \\--allow-zone-overlap \\--no-ntp 其中，podman的选项与参数， /data/ipa-data用于存放于ipa相关的配置文件与数据。 --rm使得容器停止就删除。由于配置文件与数据都持久化到了/data/ipa-data，因此容器是无状态容器，可以随时删除并重新运行一个。 --shm-size=2GB如果不指定，默认分配64MB共享内存。 --name ipa-01.icinfra.cn用于指定容器名称。 --net host使用宿主机的网络。 ti分配tty，以及交互式。 -h ipa-01.icinfra.cn容器内的主机名。 --read-only使根文件系统只读。状态全部持久化到/data/ipa-data。 -e PASSWROD=Secret123传入PASSWORD环境变量。 -v /data/ipa-data:/data:Z将卷绑定挂载到容器中。 --dns=127.0.0.1修改/etc/resolv.conf文件内容 --add-host=ipa-01.icinfra.cn:172.16.0.13/etc/hosts增加一行ipa-server-install的选项与参数， --allow-zone-overlap --no-ntp修改DNS Server配置并重启，使得允许全部查询。[root@ipa-01 /]# cat /etc/named/ipa-options-ext.conf/* User customization for BIND named * * This file is included in /etc/named.conf and is not modified during IPA * upgrades. * * It must only contain \"options\" settings. Any other setting must be * configured in /data/etc/named/ipa-ext.conf. * * Examples: * allow-recursion { trusted_network; }; * allow-query-cache { trusted_network; }; *//* turns on IPv6 for port 53, IPv4 is on by default for all ifaces */listen-on-v6 { any; };/* dnssec-enable is obsolete and 'yes' by default */dnssec-validation no;allow-query { any; };[root@ipa-01 /]# systemctl status | grep name ├─948 grep --color=auto name ├─named-pkcs11.service │ └─286 /usr/sbin/named-pkcs11 -u named -c /etc/named.conf[root@ipa-01 /]# systemctl restart named-pkcs112) 在后台运行去掉交互式，增加-dpodman stop `podman ps -q` #停止刚才交互式运行的容器。podman run \\--rm \\--shm-size=2GB \\--name ipa-01.icinfra.cn \\--net host \\-d \\-h ipa-01.icinfra.cn \\--read-only \\-e PASSWORD=Secret123 \\-v /data/ipa-data:/data:Z \\--dns=127.0.0.1 \\-e TZ=Asia/Shanghai \\-v /etc/localtime:/etc/localtime:ro \\--add-host=ipa-01.icinfra.cn:172.16.0.13 \\docker.io/freeipa/freeipa-server:almalinux-8 \\--allow-zone-overlap \\--no-ntp增加DNS Forwarder，FreeIPA Client在almalinux-8安装与使用[root@Copy-of-VM-AlmaLinux8-tmpl-cloudinit-gui-5 ~]# cat /etc/resolv.conf; Created by cloud-init on instance boot automatically, do not edit.;# Generated by NetworkManagersearch lan icinfra.cnnameserver 172.16.0.13[root@Copy-of-VM-AlmaLinux8-tmpl-cloudinit-gui-5 ~]# ipa-client-install --hostname=ipa-client-001.icinfra.cn --server=ipa-01.icinfra.cn --domain=icinfra.cn --realm=ICINFRA.CN --principal=admin --password=Secret123 --unattendedThis program will set up IPA client.Version 4.9.12Client hostname: ipa-client-001.icinfra.cnRealm: ICINFRA.CNDNS Domain: icinfra.cnIPA Server: ipa-01.icinfra.cnBaseDN: dc=icinfra,dc=cnSynchronizing timeNo SRV records of NTP servers found and no NTP server or pool address was provided.Using default chrony configuration.Attempting to sync time with chronyc.Time synchronization was successful.Successfully retrieved CA cert Subject: CN=Certificate Authority,O=ICINFRA.CN Issuer: CN=Certificate Authority,O=ICINFRA.CN Valid From: 2023-12-17 03:55:11 Valid Until: 2043-12-17 03:55:11Enrolled in IPA realm ICINFRA.CNCreated /etc/ipa/default.confConfigured /etc/sssd/sssd.confSystemwide CA database updated.Hostname (ipa-client-001.icinfra.cn) does not have A/AAAA record.Missing reverse record(s) for address(es): 172.16.0.78.Adding SSH public key from /etc/ssh/ssh_host_rsa_key.pubAdding SSH public key from /etc/ssh/ssh_host_ecdsa_key.pubAdding SSH public key from /etc/ssh/ssh_host_ed25519_key.pubSSSD enabledConfigured /etc/openldap/ldap.confConfigured /etc/ssh/ssh_configConfigured /etc/ssh/sshd_configConfiguring icinfra.cn as NIS domain.Configured /etc/krb5.conf for IPA realm ICINFRA.CNClient configuration complete.The ipa-client-install command was successful[root@Copy-of-VM-AlmaLinux8-tmpl-cloudinit-gui-5 ~]# id adminuid=196400000(admin) gid=196400000(admins) groups=196400000(admins)参考资料https://quay.io/repository/freeipa/freeipa-server?tab=infohttps://github.com/freeipa/freeipa-container" }, { "title": "谷歌芯片设计团队如何利用GCP？", "url": "/posts/how-does-google-chip-design-team-utilize-cloud/", "categories": "icenv", "tags": "chip", "date": "2023-12-10 02:00:00 +0000", "snippet": "参考资料March 29, 2023 Google chip design team benefits from move to Google CloudMay 28, 2021 Never miss a tapeout: Faster chip design with Google CloudDecember 23, 2020 Scale your EDA flows: How Googl...", "content": "参考资料March 29, 2023 Google chip design team benefits from move to Google CloudMay 28, 2021 Never miss a tapeout: Faster chip design with Google CloudDecember 23, 2020 Scale your EDA flows: How Google Cloud enables faster verificationJanuary 20, 2022 https://cloud.google.com/blog/products/operations/write-and-deploy-cloud-monitoring-alert-notifications-to-third-party-services" }, { "title": "Cadence COSLITE Product", "url": "/posts/what-is-coslite/", "categories": "icenv", "tags": "eda", "date": "2023-12-05 02:00:00 +0000", "snippet": "COSLITE是什么在验收License时，看到多出来一个COSLITE Product。从https://e2e.ti.com/support/tools/simulation-hardware-system-design-tools-group/sim-hw-system-design/f/simulation-hardware-system-design-tools-forum/952...", "content": "COSLITE是什么在验收License时，看到多出来一个COSLITE Product。从https://e2e.ti.com/support/tools/simulation-hardware-system-design-tools-group/sim-hw-system-design/f/simulation-hardware-system-design-tools-forum/952521/pspice-for-ti-warning-lmc-07708-unable-to-validate-licenses 查看到，######################################################################### COSLITE INFORMATION########################################################################## PLEASE NOTE: Your license file may contain COSLITE product depending on# your entitlement. This license will allow some digital tools to access# support.cadence.com content (via CadenceHelp) without requiring login.# This is a zero cost license and will be active as long as the primary tool# license is active. More information is available at# https://support.cadence.com/apex/ArticleAttachmentPortal?id=a1O0V000009Mns6UAC# For any further questions, please use the feedback option in the# https://support.cadence.com site and someone from the product team will get# back to you.它是允许一些数字工具不经登录就可访问CadenceHelp的一个Product。" }, { "title": "How To Enable Newly Added Group On Existing Linux Desktop", "url": "/posts/how-to-enable-newly-added-group-on-existing-linux-desktop/", "categories": "icenv", "tags": "group", "date": "2023-11-30 03:00:00 +0000", "snippet": "场景说明令芯片设计环境的研发人员经常头疼的一件事，维护完群组后，无法在Linux桌面生效。支持人员频繁接到这样的case，只能建议ta： run ‘newgrp newly-added-group-name’, or logout the vnc and login again.在遵循Linux桌面设计范式的前提下，本文我们尽量做到让用户无感地让新加群组生效。环境说明CentOS 6.1...", "content": "场景说明令芯片设计环境的研发人员经常头疼的一件事，维护完群组后，无法在Linux桌面生效。支持人员频繁接到这样的case，只能建议ta： run ‘newgrp newly-added-group-name’, or logout the vnc and login again.在遵循Linux桌面设计范式的前提下，本文我们尽量做到让用户无感地让新加群组生效。环境说明CentOS 6.10, Gnome, Krusader效果演示定制完毕后， 新开terminal，新群组就生效了。无需用户做任何操作。 在新开terminal里打开krusader，可以浏览与编辑文件。代码示例新terminal生效新群组用户只需要运行一次本脚本即可。也可以管理员将~/.flush_groups.[c]sh文件放至NFS，用户家目录.[c|ba]shrc文件去source即可。#!/bin/bash# Author: wanlinwang# Date : Nov 30, 2023# Description: This script is to make newly added group(s) available in newly created gnome-terminal on CentOS 6.10. Run me once.################## Update .cshrc.CSHRC=~/.cshrcif [ ! -f \"$CSHRC\" ]; then touch \"$CSHRC\"fi# The line to add if it doesn't existLINE=\"source ~/.flush_groups.csh\"if ! grep -Fxq \"$LINE\" \"$CSHRC\"; then # If the line doesn't exist, add it to the file echo \"$LINE\" &gt;&gt; \"$CSHRC\"fi# Add ~/.flush_groups.cshcat &gt; ~/.flush_groups.csh &lt;&lt; 'EOF'#!/bin/csh# Writen by wanlinwang.# Date: Dec 1, 2023# Description: Dec 1, 2023：支持自动将新增群组刷新到新terminal中，对研发人员透明。提升研发人员效率，降低支持工作量。# Jan 24, 2024：去掉临时文件的读写，以子shell(bash)来替代，以提升性能。if ( ! $?new_grp_array) then # 获取当前用户在当前session的主群组以及全部群组 setenv primary_group `id -gn` set current_groups=`sh -c 'id -Gn 2&gt; /dev/null' | tr ' ' '\\n' | sort` # 获取当前用户最新的全部群组 set login_groups=`sh -c 'id -Gn $USER 2&gt; /dev/null' | tr ' ' '\\n' | sort` # 使用comm比较临时变量的内容 setenv new_grp_array `bash --noprofile -c \"comm -13 &lt;(echo $current_groups) &lt;(echo $login_groups) | tr '\\n' ' '\"`endif# iterate new_grp_arrayif (\"$new_grp_array\" != \"\") then set new_group=`echo $new_grp_array | awk '{print $1}'` setenv new_grp_array `echo $new_grp_array | awk '{$1=\"\"; print $0}' | sed 's/^[ \\t]*//'` if (\"$new_group\" != \"\") then # 切换群组，使其生效 exec newgrp $new_group endifelse set current_group=`id -gn` if ( $?primary_group ) then if ( \"$primary_group\" != \"$current_group\" ) then exec newgrp $primary_group endif endif unset current_group unsetenv primary_groupendifunsetenv new_grp_arrayEOF################## Update .bashrc.BASHRC=~/.bashrcif [ ! -f \"$BASHRC\" ]; then touch \"$BASHRC\"fi# The line to add if it doesn't existLINE=\"source ~/.flush_groups.sh\"if ! grep -Fxq \"$LINE\" \"$BASHRC\"; then # If the line doesn't exist, add it to the file echo \"$LINE\" &gt;&gt; \"$BASHRC\"fi# Add ~/.flush_groups.shcat &gt; ~/.flush_groups.sh &lt;&lt; 'EOF'# Written by wanlinwang.# Date: Dec 6, 2023# Description: Automates the process of refreshing newly added groups in new terminal sessions.# Check if new groups array existsif [ -z \"$new_grp_array\" ]; then # Retrieve the current user's primary group and all groups in the current session primary_group=$(id -gn) current_groups=$(id -Gn 2&gt;/dev/null| tr ' ' '\\n' | sort) # Get the current user's latest complete group list login_groups=$(id -Gn $USER 2&gt;/dev/null| tr ' ' '\\n' | sort) # Compare file contents using 'comm' export new_grp_array=$(comm -13 &lt;(echo $current_groups) &lt;(echo $login_groups) | tr '\\n' ' ')fi# Iterate over new_grp_arrayif [ ! -z \"$new_grp_array\" ]; then new_group=$(echo $new_grp_array | awk '{print $1}') new_grp_array=$(echo $new_grp_array | awk '{$1=\"\"; print $0}' | sed 's/^[ \\t]*//') if [ ! -z \"$new_group\" ]; then # Switch to the new group to activate it exec newgrp $new_group fielse current_group=$(id -gn) if [ -n \"$primary_group\" ]; then if [ \"$primary_group\" != \"$current_group\" ]; then exec newgrp $primary_group fi fi unset current_group unset primary_groupfiunset new_grp_arrayEOFkrusader这是一个可以继承当前shell群组的文件浏览器。需要联网。如果离线环境则手动下载回来安装。# Install krusader, a file manager. If you want to use this tool, please contact your system administrator to install.sudo yum install epel-releasesudo yum localinstall http://rpms.plnet.rs/plnet-centos6-x86_64/RPMS.plnet-compiled/krusader-2.3.0-0.1.beta1.el6.x86_64.rpm" }, { "title": "slurm安装", "url": "/posts/installing-slurm/", "categories": "icenv", "tags": "slurm", "date": "2023-11-29 03:00:00 +0000", "snippet": "提前并运行munge[root@offline-almalinux8-193-computing slurm-23.11.0]# ./configure --prefix=/tools/OSS/Slurm/23.11.0 --with-munge[root@offline-almalinux8-193-computing slurm-23.11.0]# make &amp;&amp; mak...", "content": "提前并运行munge[root@offline-almalinux8-193-computing slurm-23.11.0]# ./configure --prefix=/tools/OSS/Slurm/23.11.0 --with-munge[root@offline-almalinux8-193-computing slurm-23.11.0]# make &amp;&amp; make install配置到Slurm Configuration Tool定制，# slurm.conf file generated by configurator.html.# Put this file on all nodes of your cluster.# See the slurm.conf man page for more information.#ClusterName=ic-design-cluster-001SlurmctldHost=offline-almalinux8-193-computing.icinfra.cnSlurmctldHost=offline-almalinux8-194-computing.icinfra.cn##DisableRootJobs=NO#EnforcePartLimits=NO#Epilog=#EpilogSlurmctld=#FirstJobId=1#MaxJobId=67043328#GresTypes=#GroupUpdateForce=0#GroupUpdateTime=600#JobFileAppend=0#JobRequeue=1#JobSubmitPlugins=lua#KillOnBadExit=0#LaunchType=launch/slurm#Licenses=foo*4,bar#MailProg=/bin/mail#MaxJobCount=10000#MaxStepCount=40000#MaxTasksPerNode=512#MpiDefault=#MpiParams=ports=#-##PluginDir=#PlugStackConfig=#PrivateData=jobsProctrackType=proctrack/cgroup#Prolog=#PrologFlags=#PrologSlurmctld=#PropagatePrioProcess=0#PropagateResourceLimits=#PropagateResourceLimitsExcept=#RebootProgram=ReturnToService=1SlurmctldPidFile=/var/run/slurmctld.pidSlurmctldPort=6817SlurmdPidFile=/var/run/slurmd.pidSlurmdPort=6818SlurmdSpoolDir=/var/spool/slurmdSlurmUser=slurm#SlurmdUser=root#SrunEpilog=#SrunProlog=StateSaveLocation=/var/spool/slurmctld#SwitchType=#TaskEpilog=TaskPlugin=task/affinity,task/cgroup#TaskProlog=#TopologyPlugin=topology/tree#TmpFS=/tmp#TrackWCKey=no#TreeWidth=#UnkillableStepProgram=#UsePAM=0### TIMERS#BatchStartTimeout=10#CompleteWait=0#EpilogMsgTime=2000#GetEnvTimeout=2#HealthCheckInterval=0#HealthCheckProgram=InactiveLimit=0KillWait=30#MessageTimeout=10#ResvOverRun=0MinJobAge=300#OverTimeLimit=0SlurmctldTimeout=120SlurmdTimeout=300#UnkillableStepTimeout=60#VSizeFactor=0Waittime=0### SCHEDULING#DefMemPerCPU=0#MaxMemPerCPU=0#SchedulerTimeSlice=30SchedulerType=sched/backfillSelectType=select/cons_tres### JOB PRIORITY#PriorityFlags=#PriorityType=priority/multifactor#PriorityDecayHalfLife=#PriorityCalcPeriod=#PriorityFavorSmall=#PriorityMaxAge=#PriorityUsageResetPeriod=#PriorityWeightAge=#PriorityWeightFairshare=#PriorityWeightJobSize=#PriorityWeightPartition=#PriorityWeightQOS=### LOGGING AND ACCOUNTING#AccountingStorageEnforce=0#AccountingStorageHost=#AccountingStoragePass=#AccountingStoragePort=#AccountingStorageType=#AccountingStorageUser=#AccountingStoreFlags=#JobCompHost=#JobCompLoc=#JobCompParams=#JobCompPass=#JobCompPort=JobCompType=jobcomp/none#JobCompUser=#JobContainerType=JobAcctGatherFrequency=30#JobAcctGatherType=SlurmctldDebug=infoSlurmctldLogFile=/var/log/slurmctld.logSlurmdDebug=infoSlurmdLogFile=/var/log/slurmd.log#SlurmSchedLogFile=#SlurmSchedLogLevel=#DebugFlags=### POWER SAVE SUPPORT FOR IDLE NODES (optional)#SuspendProgram=#ResumeProgram=#SuspendTimeout=#ResumeTimeout=#ResumeRate=#SuspendExcNodes=#SuspendExcParts=#SuspendRate=#SuspendTime=### COMPUTE NODESNodeName=offline-almalinux8-19[5-7]-computing.icinfra.cn State=UNKNOWNPartitionName=debug Nodes=ALL Default=YES MaxTime=INFINITE State=UP运行Controller前台运行，看是否有报错[cloud-user@offline-almalinux8-193-computing ~]$ sudo /tools/OSS/Slurm/23.11.0/sbin/slurmctld -Dslurmctld: fatal: mkdir(/var/spool/slurmctld): Permission denied提示无权限，这里创建并修改owner，[cloud-user@offline-almalinux8-193-computing ~]$ sudo mkdir /var/spool/slurmctld &amp;&amp; sudo chown slurm /var/spool/slurmctld前台运行[cloud-user@offline-almalinux8-193-computing ~]$ sudo /tools/OSS/Slurm/23.11.0/sbin/slurmctld -Dslurmctld: error: Configured MailProg is invalidslurmctld: slurmctld version 23.11.0 started on cluster ic-design-cluster-001slurmctld: error: _shutdown_bu_thread:send/recv offline-almalinux8-194-computing.icinfra.cn: Connection refusedslurmctld: No memory enforcing mechanism configured.slurmctld: error: Could not open node state file /var/spool/slurmctld/node_state: No such file or directoryslurmctld: error: NOTE: Trying backup state save file. Information may be lost!slurmctld: No node state file (/var/spool/slurmctld/node_state.old) to recoverslurmctld: error: Could not open job state file /var/spool/slurmctld/job_state: No such file or directoryslurmctld: error: NOTE: Trying backup state save file. Jobs may be lost!slurmctld: No job state file (/var/spool/slurmctld/job_state.old) to recoverslurmctld: select/cons_tres: select_p_node_init: select/cons_tres SelectTypeParameters not specified, using default value: CR_Core_Memoryslurmctld: select/cons_tres: part_data_create_array: select/cons_tres: preparing for 1 partitionsslurmctld: error: Could not open reservation state file /var/spool/slurmctld/resv_state: No such file or directoryslurmctld: error: NOTE: Trying backup state save file. Reservations may be lostslurmctld: No reservation state file (/var/spool/slurmctld/resv_state.old) to recoverslurmctld: error: Could not open trigger state file /var/spool/slurmctld/trigger_state: No such file or directoryslurmctld: error: NOTE: Trying backup state save file. Triggers may be lost!slurmctld: No trigger state file (/var/spool/slurmctld/trigger_state.old) to recoverslurmctld: Reinitializing job accounting stateslurmctld: select/cons_tres: select_p_reconfigure: select/cons_tres: reconfigureslurmctld: select/cons_tres: part_data_create_array: select/cons_tres: preparing for 1 partitionsslurmctld: Running as primary controller后台运行[cloud-user@offline-almalinux8-193-computing ~]$ sudo /tools/OSS/Slurm/23.11.0/sbin/slurmctld运行Database略运行Compute Nodes[cloud-user@offline-almalinux8-193-computing ~]$ sudo /tools/OSS/Slurm/23.11.0/sbin/slurmctld使用查看任务队列[cloud-user@offline-almalinux8-197-computing ~]$ /tools/OSS/Slurm/23.11.0/bin/squeue JOBID PARTITION NAME USER ST TIME NODES NODELIST(REASON) 2 debug wrap cloud-us R 1:27:49 1 offline-almalinux8-195-computing.icinfra.cn查看Slurm集群信息[cloud-user@offline-almalinux8-197-computing ~]$ /tools/OSS/Slurm/23.11.0/bin/sinfo PARTITION AVAIL TIMELIMIT NODES STATE NODELISTdebug* up infinite 1 alloc offline-almalinux8-195-computing.icinfra.cndebug* up infinite 2 idle offline-almalinux8-196-computing.icinfra.cn,offline-almalinux8-197-computing.icinfra.cn[cloud-user@offline-almalinux8-194-computing ~]$ /tools/OSS/Slurm/23.11.0/bin/sinfo -NlTue Nov 28 23:53:20 2023NODELIST NODES PARTITION STATE CPUS S:C:T MEMORY TMP_DISK WEIGHT AVAIL_FE REASON offline-almalinux8-195-computing.icinfra.cn 1 debug* allocated 1 1:1:1 1 0 1 (null) none offline-almalinux8-196-computing.icinfra.cn 1 debug* allocated 1 1:1:1 1 0 1 (null) none offline-almalinux8-197-computing.icinfra.cn 1 debug* idle 1 1:1:1 1 0 1 (null) none 提交作业[cloud-user@offline-almalinux8-197-computing ~]$ /tools/OSS/Slurm/23.11.0/bin/sbatch --wrap=\"sleep 36000\"查看作业[cloud-user@offline-almalinux8-197-computing ~]$ /tools/OSS/Slurm/23.11.0/bin/sstat 2JobID MaxVMSize MaxVMSizeNode MaxVMSizeTask AveVMSize MaxRSS MaxRSSNode MaxRSSTask AveRSS MaxPages MaxPagesNode MaxPagesTask AvePages MinCPU MinCPUNode MinCPUTask AveCPU NTasks AveCPUFreq ReqCPUFreqMin ReqCPUFreqMax ReqCPUFreqGov ConsumedEnergy MaxDiskRead MaxDiskReadNode MaxDiskReadTask AveDiskRead MaxDiskWrite MaxDiskWriteNode MaxDiskWriteTask AveDiskWrite TRESUsageInAve TRESUsageInMax TRESUsageInMaxNode TRESUsageInMaxTask TRESUsageInMin TRESUsageInMinNode TRESUsageInMinTask TRESUsageInTot TRESUsageOutAve TRESUsageOutMax TRESUsageOutMaxNode TRESUsageOutMaxTask TRESUsageOutMin TRESUsageOutMinNode TRESUsageOutMinTask TRESUsageOutTot ------------ ---------- -------------- -------------- ---------- ---------- ---------- ---------- ---------- -------- ------------ -------------- ---------- ---------- ---------- ---------- ---------- -------- ---------- ------------- ------------- ------------- -------------- ------------ --------------- --------------- ------------ ------------ ---------------- ---------------- ------------ -------------- -------------- ------------------ ------------------ -------------- ------------------ ------------------ -------------- --------------- --------------- ------------------- ------------------- --------------- ------------------- ------------------- ---------------参考资料https://slurm.schedmd.com/quickstart_admin.html#build_install #slurm的构建与安装https://www.icinfra.cn/blog/2023/setting-up-munge-on-almalinux8/ #munge的安装" }, { "title": "git ssh通过squid proxy访问", "url": "/posts/ssh-over-squid-proxy/", "categories": "icenv", "tags": "squid", "date": "2023-11-28 09:51:00 +0000", "snippet": "背景现有IDC服务器A，仅可访问内网。以及一台云服务器B，可通过NAT访问外网，以及被A访问。需求A服务器需要访问github.com，做代码开发的上传下载。配置squid在B服务器上安装squid，配置/etc/squid/squid.conf，将这两行加到前面，...acl Safe_ports port 22 # sshacl SSL_ports port 22 # ssh启动squi...", "content": "背景现有IDC服务器A，仅可访问内网。以及一台云服务器B，可通过NAT访问外网，以及被A访问。需求A服务器需要访问github.com，做代码开发的上传下载。配置squid在B服务器上安装squid，配置/etc/squid/squid.conf，将这两行加到前面，...acl Safe_ports port 22 # sshacl SSL_ports port 22 # ssh启动squidsystemctl enable squid --now机器A配置git config这里，请按照一下 corkscrew 工具，再往下配置。在github.com上配置好ssh key之后，在机器A执行成功，git clone git@github.com/wanlinwang/test-repo" }, { "title": "在多台almalinux8上配置MUNGE", "url": "/posts/setting-up-munge-on-almalinux8/", "categories": "icenv", "tags": "munge", "date": "2023-11-28 08:00:00 +0000", "snippet": "背景MUNGE(MUNGE Uid ‘N’ Gid Emporium) 是一种用于创建和验证凭证的身份验证服务。 它被设计为具有高度可扩展性，可在 HPC 集群环境中使用。 它允许进程验证具有公共用户和组的主机组中另一个本地或远程进程的 UID 和 GID。 这些主机形成一个由共享加密密钥定义的安全领域。 此安全领域内的客户端可以创建和验证凭据，而无需使用 root 权限、保留端口或特定于平...", "content": "背景MUNGE(MUNGE Uid ‘N’ Gid Emporium) 是一种用于创建和验证凭证的身份验证服务。 它被设计为具有高度可扩展性，可在 HPC 集群环境中使用。 它允许进程验证具有公共用户和组的主机组中另一个本地或远程进程的 UID 和 GID。 这些主机形成一个由共享加密密钥定义的安全领域。 此安全领域内的客户端可以创建和验证凭据，而无需使用 root 权限、保留端口或特定于平台的方法。Slurm集群可以利用MUNGE来使得提交的任务以提交者的身份，在执行机执行。环境略。系统下在ldap上创建munge账号安装[root@offline-almalinux8-194-computing cloud-user]# dnf install --disablerepo=TurboVNC munge配置生成key，并放到共享目录，以供各个机器读取，[root@offline-almalinux8-194-computing ~]# create-munge-key[root@offline-almalinux8-194-computing ~]# mv /etc/munge/munge.key /home/munge/运行在集群的每台机器运行，[root@offline-almalinux8-***-computing ~]# sudo -u munge munged --key-file=/home/munge/munge.key[root@offline-almalinux8-***-computing ~]# ps -ef|grep '[m]unged'munge 4682 1 0 10:22 ? 00:00:00 munged --key-file=/home/munge/munge.key停止[root@offline-almalinux8-***-computing ~]# sudo -u munge munged --stop非系统下安装我们使用spack来安装munge，请注意需要将状态文件夹设置到/var或一个本地目录，因为每台机器运行都要维持状态。由于使用cloud-user安装的，运行时会检测整个安装目录的ownership，因此这里也用cloud-user来运行munge。[cloud-user@offline-almalinux8-193-computing ~]$ spack install munge localstatedir=/var %gcc@=13.2.0[+] /tools/OSS/spack/opt/spack/linux-almalinux8-zen4/gcc-13.2.0/bzip2-1.0.8-wjafdi26ghg2ostgp6fre2jtufxgtole[+] /tools/OSS/spack/opt/spack/linux-almalinux8-zen4/gcc-13.2.0/libgpg-error-1.47-akx562yeurfuc3q3mwdsm2vq3cpbiaaz[+] /tools/OSS/spack/opt/spack/linux-almalinux8-zen4/gcc-13.2.0/zlib-ng-2.1.4-uyqju5xvdx5h3acp5q3wuczoejvypzqr[+] /tools/OSS/spack/opt/spack/linux-almalinux8-zen4/gcc-13.2.0/libgcrypt-1.10.3-zeoosgjkjxum2rg4eooio3wg5fc2i2jm[+] /tools/OSS/spack/opt/spack/linux-almalinux8-zen4/gcc-13.2.0/openssl-3.1.3-vh3m7mfa7a5nnbkmhctiukwnz5ugffna[+] /tools/OSS/spack/opt/spack/linux-almalinux8-zen4/gcc-13.2.0/munge-0.5.15-oska4u2fxfsz2c3xhhexoznkzbmckeh5配置生成key[cloud-user@offline-almalinux8-193-computing ~]$ /tools/OSS/spack/opt/spack/linux-almalinux8-zen4/gcc-13.2.0/munge-0.5.15-oska4u2fxfsz2c3xhhexoznkzbmckeh5/sbin/mungekey --verbosemungekey: Info: Created \"/tools/OSS/spack/opt/spack/linux-almalinux8-zen4/gcc-13.2.0/munge-0.5.15-oska4u2fxfsz2c3xhhexoznkzbmckeh5/etc/munge/munge.key\" with 1024-bit key创建状态文件夹[cloud-user@offline-almalinux8-193-computing ~]$ sudo mkdir -p -m 0700 /var/lib/munge /var/log/munge[cloud-user@offline-almalinux8-193-computing ~]$ sudo mkdir -p -m 0755 /var/run/munge[cloud-user@offline-almalinux8-193-computing ~]$ sudo chown cloud-user /var/lib/munge /var/log/munge /var/run/munge运行[cloud-user@offline-almalinux8-193-computing ~]$ /tools/OSS/spack/opt/spack/linux-almalinux8-zen4/gcc-13.2.0/munge-0.5.15-oska4u2fxfsz2c3xhhexoznkzbmckeh5/sbin/munged停止[cloud-user@offline-almalinux8-193-computing ~]$ /tools/OSS/spack/opt/spack/linux-almalinux8-zen4/gcc-13.2.0/munge-0.5.15-oska4u2fxfsz2c3xhhexoznkzbmckeh5/sbin/munged --stop验证munge输出到文本，然后unmunge解密munge -n &gt; munge.txtunmunge &lt; munge.txt输出到管道，然后unmunge解密[admin@offline-almalinux8-195-computing cloud-user]$ /tools/OSS/spack/opt/spack/linux-almalinux8-zen4/gcc-13.2.0/munge-0.5.15-oska4u2fxfsz2c3xhhexoznkzbmckeh5/bin/munge -n | /tools/OSS/spack/opt/spack/linux-almalinux8-zen4/gcc-13.2.0/munge-0.5.15-oska4u2fxfsz2c3xhhexoznkzbmckeh5/bin/unmunge STATUS: Success (0)ENCODE_HOST: offline-almalinux8-195-computing.icinfra.cn (127.0.0.1)ENCODE_TIME: 2023-11-28 02:43:13 -0500 (1701157393)DECODE_TIME: 2023-11-28 02:43:13 -0500 (1701157393)TTL: 300CIPHER: aes128 (4)MAC: sha256 (5)ZIP: none (0)UID: admin (1451400000)GID: admins (1451400000)LENGTH: 0可以看到，成功了。参考资料https://dun.github.io/munge/https://github.com/dun/munge/wiki/Installation-Guide#securing-the-installationhttps://github.com/dun/munge/wiki/Man-7-munge" }, { "title": "Rocky/Alma Linux 8 上安装图形化界面", "url": "/posts/install-Xfce-and-TurboVNC-on-Rocky-or-Alma-Linux-8/", "categories": "icenv", "tags": "xfce", "date": "2023-11-09 01:56:00 +0000", "snippet": "XFCE桌面环境XFCE 桌面环境作为通用桌面环境 (CDE) 的一个分支而创建，体现了模块化和可重用性的传统 Unix 哲学。您可以在几乎任何版本的 Linux 上安装 XFCE，包括 Rocky Linux。它也是最易于与替代窗口管理器（例如 Awesome 或 i3）结合使用的桌面环境之一。然而，此过程将帮助您启动并运行 Rocky Linux 和更典型的 XFCE 安装。先决条件工作...", "content": "XFCE桌面环境XFCE 桌面环境作为通用桌面环境 (CDE) 的一个分支而创建，体现了模块化和可重用性的传统 Unix 哲学。您可以在几乎任何版本的 Linux 上安装 XFCE，包括 Rocky Linux。它也是最易于与替代窗口管理器（例如 Awesome 或 i3）结合使用的桌面环境之一。然而，此过程将帮助您启动并运行 Rocky Linux 和更典型的 XFCE 安装。先决条件工作站或笔记本电脑希望运行 XFCE 作为桌面而不是默认的 GNOME 桌面安装 Rocky Linux 最小化在本节中，您需要成为 root 用户，或者能够sudo提升您的权限。在安装 Rocky Linux 时，我们使用了以下几组软件包： Minimal Standard运行系统更新首先，运行服务器更新命令。系统将重建存储库缓存。通过这种方式，系统 cab 可以识别可用的包。dnf update启用dnf仓库您需要 EPEL 存储库中的 XFCE 非官方存储库才能在 Rocky 8.x 版本上运行。通过输入以下内容启用此dnf仓库：dnf install epel-release回答“Y”即可安装。您还需要 Powertools 和 lightdm 仓库。现在启用这些：dnf config-manager --set-enabled powertoolsdnf copr enable stenstorp/lightdm同样，您将看到有关dnf仓库库的警告消息。继续并回答Y提示。检查群内可用的环境和工具现在dnf仓库已启用，请运行以下命令来检查所有内容。首先，检查您的存储库列表：dnf repolist您应该得到以下信息，显示所有已启用的存储库：appstream Rocky Linux 8 - AppStreambaseos Rocky Linux 8 - BaseOScopr:copr.fedorainfracloud.org:stenstorp:lightdm Copr repo for lightdm owned by stenstorpepel Extra Packages for Enterprise Linux 8 - x86_64epel-modular Extra Packages for Enterprise Linux Modular 8 - x86_64extras Rocky Linux 8 - Extraspowertools Rocky Linux 8 - PowerTools运行以下命令来检查 XFCE：dnf grouplist您应该在列表底部看到“Xfce”。再运行dnf update一次以确保所有启用的存储库都读入系统。安装包要安装 XFCE，请运行：dnf groupinstall \"xfce\"还要安装 lightdm：dnf install lightdm最后步骤gdm在dnf groupinstall \"xfce\"期间添加并启用，需要禁用它：systemctl disable gdm现在您可以启用lightdm：sed -r -i 's#^user-sessions=.*#user-sessions=xfce#g' /etc/lightdm/lightdm.confsystemctl enable lightdm --now您需要在启动后告诉系统仅使用图形用户界面。将默认目标系统设置为GUI界面：systemctl set-default graphical.target然后重新启动：reboot您最终应该在 XFCE GUI 中看到登录提示，当您登录时，您将拥有所有 XFCE 环境。命令集合# 安装xfce环境dnf updatednf install epel-releasednf config-manager --set-enabled powertoolsdnf copr enable stenstorp/lightdmdnf groupinstall \"xfce\"dnf groupinstall \"Fonts\"dnf install lightdmsystemctl disable gdmsed -r -i 's#^user-sessions=.*#user-sessions=xfce#g' /etc/lightdm/lightdm.confsystemctl enable lightdm --now# 安装TurboVNCTIMESTAMP=`date +%Y%m%d%H%M%S` yum -y install wgetyum -y install perl # firewalldsystemctl disable firewalld --now # selinuxsed -i_bak`date +%Y%m%d%H%M%S` \\ 's/^\\s*SELINUX=.*/SELINUX=disabled/g' \\/etc/selinux/config # add a file to disable non-privilege users' powermanagementmkdir -p /etc/xdg/xfce4/kioskcat &gt; /etc/xdg/xfce4/kiosk/kioskrc &lt;&lt; EOF[xfce4-session]Shutdown=rootEOF # setup for TurboVNCwget https://raw.githubusercontent.com/TurboVNC/repo/main/TurboVNC.repo -O /etc/yum.repos.d/TurboVNC.repoyum -y install turbovnc # modify conf for TurboVNCsed -i_bak${TIMESTAMP} \\ -e 's/#\\s*$wm = .*/$wm = \"xfce\";/g' \\ -e 's/#\\s*$serverArgs = .*/$serverArgs = \"-listen tcp\";/g' \\ -e 's/#\\s*$securityTypes = .*/$securityTypes = \"TLSOtp, TLSPlain, X509Otp, X509Plain,OTP, UnixLogin, Plain\";/g' \\ /etc/turbovncserver.conf sed -i_bak${TIMESTAMP} \\ -e 's/^#\\s*permitted-security-types = .*/permitted-security-types = TLSOtp, TLSPlain, X509Otp, X509Plain, OTP/g' \\ /etc/turbovncserver-security.conf # modify conf for ssh and sshdecho \"AcceptEnv DISPLAY\" &gt;&gt; /etc/ssh/sshd_configsystemctl restart sshdecho \"SendEnv DISPLAY\" &gt;&gt; /etc/ssh/ssh_config # swicth to grahphicalsystemctl set-default graphical.targetsystemctl isolate graphical.targetreboot结论XFCE 是一个具有简单界面的轻量环境。它是 Rocky Linux 上默认 GNOME 桌面的替代方案。资料https://docs.rockylinux.org/guides/desktop/xfce_installation/" }, { "title": "ssh时提示no matching host key type found. Their offer：rsa-sha2-512,rsa-sha2-256", "url": "/posts/ssh-no-matching-host-key-type-found/", "categories": "icenv", "tags": "ssh", "date": "2023-11-09 01:56:00 +0000", "snippet": "ssh时提示no matching host key type found. Their offer：rsa-sha2-512,rsa-sha2-256遇到这样提示时，可以手动指定HostKeyAlgorithms，while true; do ssh -N -D 1080 -i /drives/c/Users/wanlinwang/.ssh/id_rsa -o HostKeyAlgorit...", "content": "ssh时提示no matching host key type found. Their offer：rsa-sha2-512,rsa-sha2-256遇到这样提示时，可以手动指定HostKeyAlgorithms，while true; do ssh -N -D 1080 -i /drives/c/Users/wanlinwang/.ssh/id_rsa -o HostKeyAlgorithms=+rsa-sha2-512 wanlinwang@open; done" }, { "title": "chat.openai.com提示Unable to load history", "url": "/posts/chatgpt-unable-to-load-history/", "categories": "icenv", "tags": "chatgpt", "date": "2023-11-08 15:00:00 +0000", "snippet": "今天chat.openai.com登录后，提示Unable to load history打开F12发现很多403 forbidden的：原来是访问的部分URI，被openai block了。解决方法：VPS访问openai之间，再用WARP套一层，openai没那么容易去封WARP如此大的公网IP池。", "content": "今天chat.openai.com登录后，提示Unable to load history打开F12发现很多403 forbidden的：原来是访问的部分URI，被openai block了。解决方法：VPS访问openai之间，再用WARP套一层，openai没那么容易去封WARP如此大的公网IP池。" }, { "title": "gcc编译时无法提示没有这样的指令", "url": "/posts/no-such-instruction/", "categories": "icenv", "tags": "gcc", "date": "2023-11-07 15:28:00 +0000", "snippet": "由于编译的gcc，没有将binutils编进去，从而它使用了系统下的as (binutils提供的)汇编命令。而系统下的as命令版本太低，不识别新CPU的flag。解决方法是：重新编gcc，将新版本的binutils编进去了。", "content": "由于编译的gcc，没有将binutils编进去，从而它使用了系统下的as (binutils提供的)汇编命令。而系统下的as命令版本太低，不识别新CPU的flag。解决方法是：重新编gcc，将新版本的binutils编进去了。" }, { "title": "自动化下载群晖共享的文件", "url": "/posts/automating-file-downloading-from-Synology-NAS/", "categories": "icenv", "tags": "automation", "date": "2023-11-07 15:28:00 +0000", "snippet": "接到需求，需要从合作伙伴提供的群晖NAS上，批量下载大量文件。手动下载太费事费时，没有价值；并且PC的带宽有限，只能将批量串行下载，手动的话中间容易出现空闲，导致总的下载时长很长。因此写了脚本做自动化下载，如下：from selenium import webdriverfrom selenium.webdriver.common.keys import Keysfrom selenium....", "content": "接到需求，需要从合作伙伴提供的群晖NAS上，批量下载大量文件。手动下载太费事费时，没有价值；并且PC的带宽有限，只能将批量串行下载，手动的话中间容易出现空闲，导致总的下载时长很长。因此写了脚本做自动化下载，如下：from selenium import webdriverfrom selenium.webdriver.common.keys import Keysfrom selenium.webdriver.common.by import Byfrom selenium.webdriver.chrome.service import Servicefrom webdriver_manager.chrome import ChromeDriverManagerfrom selenium.webdriver.chrome.options import Optionsimport timeimport pandas as pdfrom selenium.webdriver.support.ui import WebDriverWaitfrom selenium.webdriver.support import expected_conditions as ECdef is_download_completed(directory): \"\"\" Check if all files in the specified directory have finished downloading. \"\"\" for filename in os.listdir(directory): # 下载过程中，临时文件的名字是.crdownload，因此这里判断是否有这样的文件 if filename.endswith('.crdownload') or filename.endswith('.part'): return False return Truedef download(link, pw): # 设置Chrome选项以静默模式运行（无界面模式） chrome_options = Options() chrome_options.add_argument(\"--headless\") # 设置下载文件的默认目录到 F:\\Downloads prefs = { \"download.default_directory\": r\"F:\\Downloads\", # 使用原始字符串来避免转义 \"download.prompt_for_download\": False, \"download.directory_upgrade\": True, \"safebrowsing_for_trusted_sources_enabled\": False, \"safebrowsing.enabled\": False } chrome_options.add_experimental_option(\"prefs\", prefs) # 初始化WebDriver service = Service(ChromeDriverManager().install()) driver = webdriver.Chrome(service=service, options=chrome_options) # 打开登录页面 driver.get(link) # 填写登录信息并提交表单 wait = WebDriverWait(driver, 10) password_field = wait.until(EC.element_to_be_clickable((By.ID, \"login_passwd\"))) password_field.send_keys(pw) driver.find_element(By.ID, \"ext-gen62\").click() # 等待页面加载 time.sleep(5) # 定位到下载链接并点击 download_link = driver.find_element(By.ID, \"ext-gen71\") download_link.click() # 等待文件下载完成 while not is_download_completed(download_path): time.sleep(1) # 每隔1秒检查一次 # 关闭浏览器 driver.quit()if __name__ == \"__main__\": # 指定Excel文件的路径 file_path = \"F:\\\\Downloads\\\\files2download_from_Synology.xlsx\" df = pd.read_excel(file_path, usecols=['链接', '密码'], engine='openpyxl') for _, row in df.iterrows(): link, pw = *row print(f\"Downloading {link} with password {pw}\") download(link, pw)运行，开始下载。" }, { "title": "获取git仓库的tags列表", "url": "/posts/get-all-tags-for-git-repos/", "categories": "icenv", "tags": "github", "date": "2023-11-03 14:28:00 +0000", "snippet": "#!/bin/env python3import requestsfrom datetime import datetimedef get_versions(owner, repo): url = f'https://api.github.com/repos/riscv-collab/riscv-gnu-toolchain/tags' response = requests.ge...", "content": "#!/bin/env python3import requestsfrom datetime import datetimedef get_versions(owner, repo): url = f'https://api.github.com/repos/riscv-collab/riscv-gnu-toolchain/tags' response = requests.get(url) response.raise_for_status() # Check for errors tags = response.json() print(f\"Total number of tags is {len(tags)}\") for tag in tags: tag_name = tag['name'] try: tag_date = datetime.strptime(tag_name, \"%Y.%m.%d\") if tag_date &gt;= datetime.strptime(\"2023.09.01\", \"%Y.%m.%d\"): commit_sha = tag['commit']['sha'] print(f' version(') print(f' \"{tag_name}\",') print(f' tag=\"{tag_name}\",') print(f' commit=\"{commit_sha}\",') print(f' submodules=True,') print(f' )') except: pass# Replace 'owner' and 'repo' with the GitHub repository owner and nameowner = 'owner'repo = 'repo'get_versions(owner, repo)" }, { "title": "IC设计环境Linux服务器的D(uninterruptable sleep)状态的进程", "url": "/posts/D-state-process/", "categories": "icenv", "tags": "linux", "date": "2023-11-01 02:28:00 +0000", "snippet": "在IC设计环境的Linux服务器中，进程状态“D”代表不可中断的睡眠状态（Uninterruptible Sleep）。这通常意味着进程正在等待某种I/O操作，例如网络通信或磁盘操作。通常情况下，这种状态是暂时的。但是，如果进程长时间处于D状态，可能会暗示系统存在问题。少量D状态进程时的处理 分析原因：首先，需要确定进程为何处于D状态。可以使用ps或top命令查看处于D状态的进程。...", "content": "在IC设计环境的Linux服务器中，进程状态“D”代表不可中断的睡眠状态（Uninterruptible Sleep）。这通常意味着进程正在等待某种I/O操作，例如网络通信或磁盘操作。通常情况下，这种状态是暂时的。但是，如果进程长时间处于D状态，可能会暗示系统存在问题。少量D状态进程时的处理 分析原因：首先，需要确定进程为何处于D状态。可以使用ps或top命令查看处于D状态的进程。同时，dmesg和/var/log/messages可以用来检查内核日志，以便查找潜在的硬件问题或文件系统错误。 监控I/O：使用iotop或iostat等工具监控I/O使用情况，找出是否有过量的I/O请求导致的瓶颈。 检查硬件：若进程处于D状态是由于硬件问题，比如坏的硬盘或者有问题的网络连接，检查硬件状态并进行维修或更换。 升级驱动和内核：有时候，旧的驱动或内核中的bug可能导致D状态。确保系统和所有驱动都是最新版本。 等待：如果D状态不是永久性的，有时简单地等待一段时间，让进程完成它的I/O操作是可行的。 大量D状态进程时的处理 系统负载分析：使用vmstat和mpstat等工具来分析系统负载，识别是CPU瓶颈、内存问题还是I/O问题。 检查文件系统：使用fsck命令检查和修复文件系统错误。如果是网络文件系统（如NFS），检查网络连接和服务器状态。 追查特定资源：通过lsof和fuser命令确定进程正在访问的资源，这可能会揭示为何这么多进程卡在D状态。 减少I/O竞争：如果可能，减少对磁盘或网络的并发访问，优化应用程序的I/O模式。 考虑硬件故障：如果硬件故障是导致大量D状态进程的原因，需要更深入地检查硬件。 紧急响应：在极端情况下，如果大量的D状态进程导致服务器无法正常工作，可能需要考虑重启系统。在重启前，应尽可能地安全地关闭服务和进程，以避免数据损失。 联系专家：如果上述措施都不能解决问题，可能需要联系系统管理员或专家进行深入分析。 在处理这些问题时，保持系统的数据和日志记录非常重要，这样可以帮助分析问题的根本原因。而且，在做出重大改变前，确保有数据备份是个好习惯。如果你不是系统管理员，解决这些问题时最好与他们合作。这里也探讨下，遇到大量D状态进程，如何清理： D状态进程为孤儿进程1时，执行kill传递SIGKILL信号，可以kill掉。 D状态进程为非孤儿进程2时，执行kill发送任何类型信号，均不响应。这也就是为什么直接kill -9杀不掉，而将该用户的全部进程杀掉就可以，是因为全部杀时，D状态的父进程被杀了之后，D状态进程就变为孤儿进程了，也就符合情况2了。 系统重启可，将所有D状态进程清理掉。 脚注： 其父进程PID是1 &#8617;&#xfe0e; 其父进程PID不是1 &#8617;&#xfe0e; " }, { "title": "一个收集LSF处于不同状态job数量的collector", "url": "/posts/collector-for-lsf-jobs-in-different-status/", "categories": "icenv", "tags": "lsf", "date": "2023-10-30 14:25:00 +0000", "snippet": "基于 https://github.com/icinfra/lsf_exporter 提供的LSF collector的样例，以及EDACAD群友希望增加对处于不同状态的job的统计展示，这里提供一个// 作者: wanlinwang// 日期: 2023-10-30// 描述: 这个文件包含了Prometheus的collector实现，用于收集LSF job状态信息。package co...", "content": "基于 https://github.com/icinfra/lsf_exporter 提供的LSF collector的样例，以及EDACAD群友希望增加对处于不同状态的job的统计展示，这里提供一个// 作者: wanlinwang// 日期: 2023-10-30// 描述: 这个文件包含了Prometheus的collector实现，用于收集LSF job状态信息。package collectorimport (\t\"bytes\"\t\"os/exec\"\t\"strconv\"\t\"strings\"\t\"github.com/go-kit/log\"\t\"github.com/prometheus/client_golang/prometheus\")type lsfJobCollector struct {\tRunJobs *prometheus.Desc\tPendJobs *prometheus.Desc\tSuspJobs *prometheus.Desc\tlogger log.Logger}func init() {\tregisterCollector(\"lsfjobs\", defaultEnabled, NewLSFJobCollector)}func NewLSFJobCollector(logger log.Logger) (Collector, error) {\treturn &amp;lsfJobCollector{\t\tRunJobs: prometheus.NewDesc(\t\t\tprometheus.BuildFQName(namespace, \"lsfjobs\", \"run\"),\t\t\t\"The total number of RUNNING jobs.\",\t\t\tnil, nil,\t\t),\t\tPendJobs: prometheus.NewDesc(\t\t\tprometheus.BuildFQName(namespace, \"lsfjobs\", \"pend\"),\t\t\t\"The total number of PENDING jobs.\",\t\t\tnil, nil,\t\t),\t\tSuspJobs: prometheus.NewDesc(\t\t\tprometheus.BuildFQName(namespace, \"lsfjobs\", \"susp\"),\t\t\t\"The total number of SUSPENDED jobs.\",\t\t\tnil, nil,\t\t),\t\tlogger: logger,\t}, nil}func (c *lsfJobCollector) Update(ch chan&lt;- prometheus.Metric) error {\tjobStats, err := getLSFJobStats(c.logger)\tif err != nil {\t\treturn err\t}\tch &lt;- prometheus.MustNewConstMetric(c.RunJobs, prometheus.GaugeValue, float64(jobStats.Run))\tch &lt;- prometheus.MustNewConstMetric(c.PendJobs, prometheus.GaugeValue, float64(jobStats.Pend))\tch &lt;- prometheus.MustNewConstMetric(c.SuspJobs, prometheus.GaugeValue, float64(jobStats.Susp))\treturn nil}type JobStats struct {\tRun int\tPend int\tSusp int}func getLSFJobStats(logger log.Logger) (*JobStats, error) {\tcmd := exec.Command(\"bash\", \"-c\", \"bqueues\")\tvar out bytes.Buffer\tcmd.Stdout = &amp;out\terr := cmd.Run()\tif err != nil {\t\treturn nil, err\t}\tlines := strings.Split(out.String(), \"\\n\")\ttotalRun, totalPend, totalSusp := 0, 0, 0\t// 从第二行开始处理，以忽略 header 行\tfor i, line := range lines {\t\tif i == 0 {\t\t\tcontinue // skip header line\t\t}\t\tfields := strings.Fields(line)\t\tif len(fields) &gt;= 8 {\t\t\trun, err := strconv.Atoi(fields[9])\t\t\tif err == nil {\t\t\t\ttotalRun += run\t\t\t}\t\t\tpend, err := strconv.Atoi(fields[8])\t\t\tif err == nil {\t\t\t\ttotalPend += pend\t\t\t}\t\t\tsusp, err := strconv.Atoi(fields[10])\t\t\tif err == nil {\t\t\t\ttotalSusp += susp\t\t\t}\t\t}\t}\treturn &amp;JobStats{\t\tRun: totalRun,\t\tPend: totalPend,\t\tSusp: totalSusp,\t}, nil}参考资料https://www.ibm.com/docs/en/spectrum-lsf/10.1.0?topic=status-find-batch-system#bhostsbqueues9786__title__3" }, { "title": "离线环境bazel构建，如何解决外部依赖？", "url": "/posts/resolving-dependencies-during-bazel-build-in-offline-environment/", "categories": "icenv", "tags": "bazel", "date": "2023-10-30 08:53:00 +0000", "snippet": "bazel外部依赖的解决步骤 在项目根目录执行bazel fetch //... ，将所有外部依赖抓到本地的cache目录（~/.cache/bazel）下。将该目录传到内网服务器的对应目录。 如https://github.com/chipsalliance/riscv-dv 这个项目，其remotejdk11_linux没有被步骤1下载，手动下载好到一个目录/pa...", "content": "bazel外部依赖的解决步骤 在项目根目录执行bazel fetch //... ，将所有外部依赖抓到本地的cache目录（~/.cache/bazel）下。将该目录传到内网服务器的对应目录。 如https://github.com/chipsalliance/riscv-dv 这个项目，其remotejdk11_linux没有被步骤1下载，手动下载好到一个目录/path/to/dependencies。将该目录传到内网服务器。 在内网服务器，执行构建命令 bazel build --cxxopt='-std=c++17' --distdir=/path/to/dependencies //... 踩过的坑步骤1还可以逐个识别需要下载的包，放到一个目录下，然后在WORKSPACE中定义的依赖的url将互联网地址（http[s]://开头的）修改到本地文件地址（file://开头的）。但是这个可操作性不强，直接依赖尚可识别，但是间接依赖不好弄，还得一个个弄。参考资料https://bazel.build/run/build?hl=zh-cn#fetching-external-dependencieshttps://bazel.build/reference/command-line-reference?hl=zh-cn#analyze-profile-options" }, { "title": "将已有的spack安装目录串起来，实现复用", "url": "/posts/chaining-spack-installations/", "categories": "icenv", "tags": "spack", "date": "2023-10-27 11:00:00 +0000", "snippet": "根据这里 https://spack.readthedocs.io/en/latest/chain.html 介绍，可以将一个或多个已存在的spack安装目录串起来，实现复用。这在spack版本升级时非常有用，spack在不定期地迭代更新，但是每一个spack版本默认将包安装在其 opt/spack/ 目录下，如果想升级版本时则无法利用旧版本已安装的那些包。利用该特性，可以实现对旧版本spa...", "content": "根据这里 https://spack.readthedocs.io/en/latest/chain.html 介绍，可以将一个或多个已存在的spack安装目录串起来，实现复用。这在spack版本升级时非常有用，spack在不定期地迭代更新，但是每一个spack版本默认将包安装在其 opt/spack/ 目录下，如果想升级版本时则无法利用旧版本已安装的那些包。利用该特性，可以实现对旧版本spack已安装的包的复用。如下所示，cat /tools/opensrc/spack-0.20.1/etc/spack/defaults/upstreams.yamlupstreams: spack-instance-1: install_tree: /tools/opensrc/spack-0.20.0/opt/spack modules: tcl: /tools/opensrc/spack-0.20.0/share/spack/modules" }, { "title": "解析FLEXlm lmutil lmstat输出并保存", "url": "/posts/FLEXlm-lmutil-lmstat-output-parsing-and-storaging/", "categories": "icenv", "tags": "license", "date": "2023-10-24 15:34:00 +0000", "snippet": "数据库表设计 user 表: 列名 数据类型 说明 id INTEGER PRIMARY KEY 主键 username TEXT 用户名 server 表: 列名 数据类型 说明 ...", "content": "数据库表设计 user 表: 列名 数据类型 说明 id INTEGER PRIMARY KEY 主键 username TEXT 用户名 server 表: 列名 数据类型 说明 id INTEGER PRIMARY KEY 主键 hostname TEXT 主机名 vendor 表: 列名 数据类型 说明 id INTEGER PRIMARY KEY 主键 vendor_daemon_name TEXT 供应商守护进程名 license_type 表: 列名 数据类型 说明 id INTEGER PRIMARY KEY 主键 type TEXT 许可类型 feature 表: 列名 数据类型 说明 id INTEGER PRIMARY KEY 主键 feature_name TEXT 特性名称 license_usage_log 表: 列名 数据类型 说明 id INTEGER PRIMARY KEY 主键 user_id INTEGER 用户ID，外键 workstation_id INTEGER 工作站ID，外键 sessionid INTEGER sessionid，从日志条目解析出来的 start_time TEXT 开始时间 end_time TEXT 结束时间 vendor_id INTEGER vendor ID，外键 lic_server_id INTEGER license server ID，外键 lic_type_id INTEGER license_type ID，外键 feature_id INTEGER feature ID，外键 additional_key TEXT 部分feature有额外的key 每个表格通过主键和外键相互关联，为日志解析和数据存储提供结构支持。初始化数据库#!/Users/wanlinwang/spack/opt/spack/darwin-ventura-m1/apple-clang-14.0.3/python-3.10.8-b7rgkczw4yfgrkbgttbcbur3ksmwho5d/bin/python3import sqlite3conn = sqlite3.connect('license_logging.db') # 创建或连接到license.db数据库cursor = conn.cursor()# 创建user表cursor.execute('''CREATE TABLE IF NOT EXISTS user ( id INTEGER PRIMARY KEY, username TEXT)''')# 创建server表cursor.execute('''CREATE TABLE IF NOT EXISTS server ( id INTEGER PRIMARY KEY, hostname TEXT)''')# 创建vendor表cursor.execute('''CREATE TABLE IF NOT EXISTS vendor ( id INTEGER PRIMARY KEY, vendor_daemon_name TEXT)''')# 创建license_type表cursor.execute('''CREATE TABLE IF NOT EXISTS license_type ( id INTEGER PRIMARY KEY, type TEXT)''')# 创建feature表cursor.execute('''CREATE TABLE IF NOT EXISTS feature ( id INTEGER PRIMARY KEY, feature_name TEXT)''')# 创建license_usage_log表，它将其他表关联起来cursor.execute('''CREATE TABLE IF NOT EXISTS license_usage_log( id INTEGER PRIMARY KEY, user_id INTEGER, workstation_id INTEGER, sessionid INTEGER, start_time TEXT, end_time TEXT, vendor_id INTEGER, lic_server_id INTEGER, lic_type_id INTEGER, feature_id INTEGER, additional_key TEXT, FOREIGN KEY(user_id) REFERENCES user(id), FOREIGN KEY(workstation_id) REFERENCES server(id), FOREIGN KEY(vendor_id) REFERENCES vendor(id), FOREIGN KEY(lic_server_id) REFERENCES server(id), FOREIGN KEY(lic_type_id) REFERENCES license_type(id), FOREIGN KEY(feature_id) REFERENCES feature(id))''')conn.commit() # 提交创建表的操作conn.close() # 关闭数据库连接定期执行，存入/更新数据库#!/Users/wanlinwang/spack/opt/spack/darwin-ventura-m1/apple-clang-14.0.3/python-3.10.8-b7rgkczw4yfgrkbgttbcbur3ksmwho5d/bin/python3import sqlite3import subprocessimport refrom datetime import datetimeDB_PATH = 'license_logging.db'def run_lmstat(CDS_LIC_FILE): cmd = f\"lmstat -a -c {CDS_LIC_FILE}\" return subprocess.check_output(cmd, shell=True).decode('utf-8')def extract_data_from_output(output): features_data = [] lines = output.split('\\n') current_feature = None for line in lines: if 'Users of' in line: # Get the feature name current_feature = line.split()[2].strip(':') lic_type = \"unknown\" elif current_feature and current_feature in line: vendor_info = re.search(r'.*vendor:\\s*(\\w+).*', line) if vendor_info: current_vendor = vendor_info.group(1) elif \"floating license\" in line: lic_type = \"floating license\" elif current_feature and ', start' in line: # 格式\"user_01 y260.ic.cn y260.ic.cn:1.0 Xcelium Single Core Engine (v21.000) (y162/5280 801), start Thu 10/19 9:57\" user_info = re.search(r'(\\w+)\\s+([\\w.]+)\\s+[\\w.]*:[\\d.]+\\s+[^(]*\\(([\\w.]+)\\)\\s+\\(([\\w]+)/(\\d+)\\s+(\\d+)\\),\\s*start\\s*(\\w+ \\d+/\\d+ \\d+:\\d+)', line) if user_info: start_time = datetime.strptime(user_info.group(7), \"%a %m/%d %H:%M\").replace(year=datetime.now().year) if start_time &gt; datetime.now(): start_time = start_time.replace(year=start_time.year - 1) features_data.append({ \"feature\": current_feature, \"vendor\": current_vendor, \"lic_type\": lic_type, \"username\": user_info.group(1), \"workstation\": user_info.group(2), \"version\": user_info.group(3), \"lic_server\": user_info.group(4), \"port\": user_info.group(5), \"sessionid\": user_info.group(6), \"start_time\": start_time.strftime(\"%Y-%m-%d %H:%M:%S\") }) return features_datadef get_or_insert_id(cursor, table, column, value): cursor.execute(f'SELECT id FROM {table} WHERE {column}=?', (value,)) result = cursor.fetchone() if not result: cursor.execute(f'INSERT INTO {table}({column}) VALUES (?)', (value,)) return cursor.lastrowid return result[0]def update_database(data): conn = sqlite3.connect(DB_PATH) cursor = conn.cursor() for entry in data: # Resolve foreign key dependencies user_id = get_or_insert_id(cursor, 'user', 'username', entry['username']) feature_id = get_or_insert_id(cursor, 'feature', 'feature_name', entry['feature']) vendor_id = get_or_insert_id(cursor, 'vendor', 'vendor_daemon_name', entry['vendor']) lic_type_id = get_or_insert_id(cursor, 'license_type', 'type', entry['lic_type']) workstation_id = get_or_insert_id(cursor, 'server', 'hostname', entry['workstation']) lic_server_id = get_or_insert_id(cursor, 'server', 'hostname', entry['lic_server']) # Check if entry exists in license_usage_log cursor.execute('''SELECT id FROM license_usage_log WHERE feature_id=? AND start_time=? AND sessionid=?''', (feature_id, entry[\"start_time\"], entry[\"sessionid\"])) log_id = cursor.fetchone() timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\") if log_id: # Update end_time cursor.execute('UPDATE license_usage_log SET end_time=? WHERE id=?', (timestamp, log_id[0])) else: # Insert new entry cursor.execute(''' INSERT INTO license_usage_log(user_id, workstation_id, start_time, end_time, vendor_id, lic_server_id, lic_type_id, feature_id, sessionid) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)''', (user_id, workstation_id, entry[\"start_time\"], timestamp, vendor_id, lic_server_id, lic_type_id, feature_id, entry[\"sessionid\"])) conn.commit() conn.close()if __name__ == \"__main__\": CDS_LIC_FILE=\"5280@lic-server-01:5280@lic-server-02\" all_output = run_lmstat(CDS_LIC_FILE) for output in re.split(r\"-{8,}\", all_output): data = extract_data_from_output(output) update_database(data)测试数据 output = \"\"\"Users of Affirma_sim_analysis_env: (Total of 8 licenses issued; Total of 3 licenses in use) \"Affirma_sim_analysis_env\" v23.0, vendor: cdslmd, expiry: 15-jan-2024 vendor_string: UHD:PERM floating license user_01 TENCENT64.site :11 (v16.000) (lic460/5280 101), start Wed 10/18 12:37 user_02 server-0431840.ic.cn server-0431840.ic.cn:1.0 (v16.000) (lic460/5280 716), start Wed 10/18 17:24 user_03 server-2381620.ic.cn server-2381620.ic.cn:4.0 (v16.000) (lic460/5280 2123), start Thu 10/19 6:56Users of Xcelium_Single_Core: (Total of 8 licenses issued; Total of 3 licenses in use) \"Xcelium_Single_Core\" v21.000, vendor: cdslmd, expiry: 15-jan-2024 vendor_string: UHD:PERM floating license user_03 TENCENT64.site :11 Xcelium Single Core Engine (v21.000) (lic460/5280 101), start Wed 10/18 12:37 user_02 TENCENT64.site :4 Xcelium Single Core Engine (v21.000) (lic460/5280 301), start Wed 10/18 12:37 user_01 TENCENT64.site :80 Xcelium Single Core Engine (v21.000) (lic460/5280 401), start Wed 10/18 12:37\"\"\"" }, { "title": "VNC分辨率与缩放率设置", "url": "/posts/vnc-resolution-and-scaling-factor/", "categories": "icenv", "tags": "vnc", "date": "2023-10-23 04:34:00 +0000", "snippet": "在4k显示器原样4k显示：图片丢失。修改到2k显示：图片丢失。", "content": "在4k显示器原样4k显示：图片丢失。修改到2k显示：图片丢失。" }, { "title": "鼠标滚轮切换xfce4 workspace", "url": "/posts/mouse-wheel-to-switch-xfce4-workspaces/", "categories": "icenv", "tags": "xfce4", "date": "2023-10-23 04:34:00 +0000", "snippet": "在xfce4桌面，鼠标滚轮禁止切换workspace：命令行设置$ xfconf-query -c xfwm4 -l | grep workspace/general/cycle_workspaces/general/scroll_workspaces/general/toggle_workspaces/general/workspaces_count/general/workspaces_...", "content": "在xfce4桌面，鼠标滚轮禁止切换workspace：命令行设置$ xfconf-query -c xfwm4 -l | grep workspace/general/cycle_workspaces/general/scroll_workspaces/general/toggle_workspaces/general/workspaces_count/general/workspaces_names/general/wrap_workspaces$ xfconf-query -c xfwm4 -p /general/scroll_workspacestrue$ xfconf-query -c xfwm4 -p /general/scroll_workspaces -s false图形化设置略。" }, { "title": "License报告的方案调研与思路", "url": "/posts/license-report/", "categories": "icenv", "tags": "license", "date": "2023-10-23 04:34:00 +0000", "snippet": "https://www.openlm.com/blog/application-note-1030-openlm-license-usage-monitoring-according-to-projects-v1-8/由于VENDOR Daemon写的REPORT LOG是加密的，无法被除FLEXnet Manager之外的其它软件打开。因此，OPENLM的项目费用统计，不是通过读取REPO...", "content": "https://www.openlm.com/blog/application-note-1030-openlm-license-usage-monitoring-according-to-projects-v1-8/由于VENDOR Daemon写的REPORT LOG是加密的，无法被除FLEXnet Manager之外的其它软件打开。因此，OPENLM的项目费用统计，不是通过读取REPORT LOG来获得的，而是通过其它小技巧获得的： 通过给用户assign唯一的项目； 通过在用户的workstation部署OpenLM Agent获取，定期或者触发式弹窗让用户选择当前正在工作的project是什么； 后向兼容LM_PROJECT变量来获取项目信息，这个也是需要以某种方式（root部署在每台workstation的OpenLM Agent？）将用户环境中的LM_PROJECT变量以时序的方式记录下来，供生成报告时使用。" }, { "title": "nfs v4的问题", "url": "/posts/nfs-v4-problem/", "categories": "icenv", "tags": "nfs", "date": "2023-10-18 11:49:00 +0000", "snippet": "由于nfs v4的misbehavior导致NFS Store Pool for Session exhausted.https://kb.netapp.com/onprem/ontap/da/NAS/Unable_to_mount_volume_using_NFSv4.1_due_to_NFS_Store_Pool_for_Session_exhaustedhttps://kb.netap...", "content": "由于nfs v4的misbehavior导致NFS Store Pool for Session exhausted.https://kb.netapp.com/onprem/ontap/da/NAS/Unable_to_mount_volume_using_NFSv4.1_due_to_NFS_Store_Pool_for_Session_exhaustedhttps://kb.netapp.com/onprem/ontap/da/NAS/Unable_to_mount_volume_using_NFSv4.1_due_to_NFS_Store_Pool_for_Session_exhausted" }, { "title": "svn authz文件的通配符", "url": "/posts/svn-authz-wildcard/", "categories": "icenv", "tags": "", "date": "2023-10-16 15:00:00 +0000", "snippet": "在新版本subversion的通配匹配与精确匹配，路径有重叠时，顺序应为——通配在前，精确配置在后。参考文档：https://subversion.apache.org/docs/release-notes/1.10.html#authzperf", "content": "在新版本subversion的通配匹配与精确匹配，路径有重叠时，顺序应为——通配在前，精确配置在后。参考文档：https://subversion.apache.org/docs/release-notes/1.10.html#authzperf" }, { "title": "License管理器应用", "url": "/posts/license-manager-app/", "categories": "icenv", "tags": "license", "date": "2023-10-16 15:00:00 +0000", "snippet": "读取License文件，并存入sqlite3数据库。#!/Users/wanlinwang/spack/opt/spack/darwin-ventura-m1/apple-clang-14.0.3/python-3.10.8-b7rgkczw4yfgrkbgttbcbur3ksmwho5d/bin/python3import sqlite3import reimport argparsede...", "content": "读取License文件，并存入sqlite3数据库。#!/Users/wanlinwang/spack/opt/spack/darwin-ventura-m1/apple-clang-14.0.3/python-3.10.8-b7rgkczw4yfgrkbgttbcbur3ksmwho5d/bin/python3import sqlite3import reimport argparsedef parse_license_file(filename): with open(filename, 'r') as f: content = f.read() start_index = content.find(\"## PRODUCT TO FEATURE MAPPING\") products_data = content[start_index:].split(\"# Product Id :\") products = [] for product_data in products_data[1:]: product = {} product['id'] = product_data.split(\",\")[0].strip() product['name'] = re.search(r'Product Name: (.+)', product_data).group(1).strip() product['version'] = re.search(r'\\[Version: (.+?)\\]', product_data).group(1).strip() product['features'] = re.findall(r'Feature: (.+?)\\s*\\[', product_data) product['dates'] = re.findall(r'Start Date: (.+?) Exp Date: (.+?)\\s*Product Qty: (\\d+)', product_data) products.append(product) return productsdef store_to_db(products, filename): conn = sqlite3.connect('license.db') cursor = conn.cursor() # Create tables cursor.execute('''CREATE TABLE IF NOT EXISTS LicenseFiles (LicenseFileId INTEGER PRIMARY KEY AUTOINCREMENT, FileName TEXT UNIQUE, hostname TEXT, hostid TEXT, lmgrd_port TEXT, vendor_daemon_port TEXT, lmgrd_file_id INTEGER, vendor_daemon_file_id INTEGER, options_file_id INTEGER)''') cursor.execute(\"INSERT OR IGNORE INTO LicenseFiles (FileName) VALUES (?)\", (filename,)) cursor.execute(\"SELECT LicenseFileId FROM LicenseFiles WHERE FileName=?\", (filename,)) license_file_id = cursor.fetchone()[0] cursor.execute('''CREATE TABLE IF NOT EXISTS LicenseRelatedFiles (ExecutableFileId INTEGER PRIMARY KEY AUTOINCREMENT, FileName TEXT UNIQUE)''') cursor.execute('''CREATE TABLE IF NOT EXISTS Features (FeatureId INTEGER PRIMARY KEY AUTOINCREMENT, FeatureName TEXT UNIQUE)''') cursor.execute('''CREATE TABLE IF NOT EXISTS Products (ProductId TEXT PRIMARY KEY, ProductName TEXT)''') cursor.execute('''CREATE TABLE IF NOT EXISTS ProductFeatureRelation (RelationId INTEGER PRIMARY KEY AUTOINCREMENT, ProductId TEXT, FeatureId INTEGER, FOREIGN KEY(ProductId) REFERENCES Products(ProductId), FOREIGN KEY(FeatureId) REFERENCES Features(FeatureId))''') cursor.execute('''CREATE TABLE IF NOT EXISTS ProductDates (DateId INTEGER PRIMARY KEY AUTOINCREMENT, ProductId TEXT, StartDate DATE, EndDate DATE, Version TEXT, Quantity INTEGER, LicenseFileId INTEGER, FOREIGN KEY(ProductId) REFERENCES Products(ProductId), FOREIGN KEY(LicenseFileId) REFERENCES LicenseFiles(LicenseFileId))''') for product in products: cursor.execute(\"INSERT OR REPLACE INTO Products (ProductId, ProductName) VALUES (?, ?)\", (product['id'], product['name'])) for feature in product['features']: cursor.execute(\"INSERT OR IGNORE INTO Features (FeatureName) VALUES (?)\", (feature,)) cursor.execute(\"SELECT FeatureId FROM Features WHERE FeatureName=?\", (feature,)) feature_id = cursor.fetchone()[0] cursor.execute(\"SELECT 1 FROM ProductFeatureRelation WHERE ProductId=? AND FeatureId=?\", (product['id'], feature_id)) if not cursor.fetchone(): cursor.execute(\"INSERT INTO ProductFeatureRelation (ProductId, FeatureId) VALUES (?, ?)\", (product['id'], feature_id)) for start_date, end_date, quantity in product['dates']: cursor.execute(\"SELECT 1 FROM ProductDates WHERE ProductId=? AND StartDate=? AND EndDate=? AND Version=? AND LicenseFileId=?\", (product['id'], start_date, end_date, product['version'], license_file_id)) if not cursor.fetchone(): cursor.execute(\"INSERT INTO ProductDates (ProductId, StartDate, EndDate, Version, Quantity, LicenseFileId) VALUES (?, ?, ?, ?, ?, ?)\", (product['id'], start_date, end_date, product['version'], quantity, license_file_id)) conn.commit() conn.close()def main(): parser = argparse.ArgumentParser(description=\"Process License Files and Store to Database\") parser.add_argument('license_files', metavar='N', type=str, nargs='+', help='License file(s) to process') args = parser.parse_args() for filename in args.license_files: products = parse_license_file(filename) store_to_db(products, filename)if __name__ == \"__main__\": main()读取sqlite3数据库，并显示在客户端内，#!/home/centos/spack/opt/spack/linux-centos7-x86_64_v4/gcc-13.2.0/python-3.10.10-64a4t27o3c2cnk23lenooydikdsiqzgv/bin/python3import sqlite3import tkinter as tkfrom tkinter import ttkfrom contextlib import contextmanagerimport tkinter.messageboxfrom datetime import datetime, timedeltafrom collections import defaultdictfrom tkinter import filedialogimport openpyxldef get_row_color(start_date, end_date): current_date = datetime.now().date() end_date_obj = datetime.strptime(end_date, \"%d-%b-%Y\").date() if end_date_obj &lt; current_date: return \"light gray\" elif current_date &lt;= end_date_obj &lt;= (current_date + timedelta(days=14)): return \"red\" else: return \"black\"@contextmanagerdef get_db_connection(): conn = sqlite3.connect('license.db') try: yield conn finally: conn.close()def execute_query(query, params=()): with get_db_connection() as conn: cursor = conn.cursor() cursor.execute(query, params) return cursor.fetchall()def execute_commit(query, params=()): with get_db_connection() as conn: cursor = conn.cursor() cursor.execute(query, params) conn.commit()def retrieve_license_info_by_feature(feature_name): query = \"\"\" SELECT pd.StartDate, pd.EndDate, pd.Quantity, lf.FileName, p.ProductId FROM ProductDates pd JOIN Products p ON pd.ProductId = p.ProductId JOIN ProductFeatureRelation pfr ON p.ProductId = pfr.ProductId JOIN Features f ON pfr.FeatureId = f.FeatureId JOIN LicenseFiles lf ON pd.LicenseFileId = lf.LicenseFileId WHERE f.FeatureName = ? \"\"\" return execute_query(query, (feature_name,))def retrieve_license_info_by_product(product_id): query = \"\"\" SELECT pd.StartDate, pd.EndDate, pd.Quantity, lf.FileName, p.ProductId FROM ProductDates pd JOIN Products p ON pd.ProductId = p.ProductId JOIN LicenseFiles lf ON pd.LicenseFileId = lf.LicenseFileId WHERE p.ProductId = ? \"\"\" return execute_query(query, (product_id,))def get_all_features(): return [row[0] for row in execute_query(\"SELECT FeatureName FROM Features\")]def get_all_products(): return [row[0] for row in execute_query(\"SELECT ProductId FROM Products\")]def get_all_license_files(): return [row[0] for row in execute_query(\"SELECT FileName FROM LicenseFiles\")]def get_all_license_related_files(): return [row[0] for row in execute_query(\"SELECT FileName FROM LicenseRelatedFiles\")]def on_search_by_feature(): tree_by_feature.delete(*tree_by_feature.get_children()) # Clear the treeview feature_name = feature_name_combobox.get() results = retrieve_license_info_by_feature(feature_name) sorted_results = sorted(results, key=lambda x: datetime.strptime(x[1], \"%d-%b-%Y\")) for result in sorted_results: color = get_row_color(result[0], result[1]) tree_by_feature.insert(\"\", \"end\", values=result, tags=(color,)) tree_by_feature.tag_configure(color, foreground=color)def on_search_by_product(): tree_by_product.delete(*tree_by_product.get_children()) # Clear the treeview product_id = product_id_combobox.get() results = retrieve_license_info_by_product(product_id) sorted_results = sorted(results, key=lambda x: datetime.strptime(x[1], \"%d-%b-%Y\")) for result in sorted_results: color = get_row_color(result[0], result[1]) tree_by_product.insert(\"\", \"end\", values=result, tags=(color,)) tree_by_product.tag_configure(color, foreground=color)def load_license_info(event): data = execute_query(\"SELECT hostname, hostid, lmgrd_port, vendor_daemon_port, lmgrd_file_id, vendor_daemon_file_id, options_file_id FROM LicenseFiles WHERE FileName=?\", (license_file_combobox.get(),)) if data: data = data[0] hostname_entry.delete(0, tk.END) hostid_entry.delete(0, tk.END) lmgrd_port_entry.delete(0, tk.END) vendor_daemon_port_entry.delete(0, tk.END) # Clear all entries and comboboxes first hostname_entry.delete(0, tk.END) hostid_entry.delete(0, tk.END) lmgrd_port_entry.delete(0, tk.END) vendor_daemon_port_entry.delete(0, tk.END) lmgrd_file_combobox.set('') vendor_daemon_file_combobox.set('') options_file_combobox.set('') if data: if data[0]: hostname_entry.insert(0, data[0]) if data[1]: hostid_entry.insert(0, data[1]) if data[2]: lmgrd_port_entry.insert(0, data[2]) if data[3]: vendor_daemon_port_entry.insert(0, data[3]) if data[4]: lmgrd_file = execute_query(\"SELECT FileName FROM LicenseRelatedFiles WHERE ExecutableFileId=?\", (data[4],)) if lmgrd_file: lmgrd_file = lmgrd_file[0] lmgrd_file_combobox.set(lmgrd_file) if data[5]: vendor_daemon_file = execute_query(\"SELECT FileName FROM LicenseRelatedFiles WHERE ExecutableFileId=?\", (data[5],)) if vendor_daemon_file: vendor_daemon_file = vendor_daemon_file[0] vendor_daemon_file_combobox.set(vendor_daemon_file) if data[6]: options_file = execute_query(\"SELECT FileName FROM LicenseRelatedFiles WHERE ExecutableFileId=?\", (data[6],)) if options_file: options_file = options_file[0] options_file_combobox.set(options_file) if (not hostname_entry.get() and not lmgrd_port_entry.get() and not vendor_daemon_port_entry.get() and not lmgrd_file_combobox.get() and not vendor_daemon_file_combobox.get() and not options_file_combobox.get()): copy_from_prev_button['state'] = tk.NORMAL else: copy_from_prev_button['state'] = tk.DISABLEDdef check_inputs_filled(): # Check if all required fields are filled if (license_file_combobox.get() and hostname_entry.get() and hostid_entry.get() and lmgrd_port_entry.get() and lmgrd_file_combobox.get() and vendor_daemon_file_combobox.get()): save_button['state'] = tk.NORMAL modify_button['state'] = tk.NORMAL else: save_button['state'] = tk.DISABLED modify_button['state'] = tk.DISABLEDdef copy_from_previous_file(): license_file_name = license_file_combobox.get() if not license_file_name: tkinter.messagebox.showerror(\"Error\", \"Please select a License File first.\") return # Extract hostid from the license file's filename try: hostid = license_file_name.split('_')[2] except IndexError: tkinter.messagebox.showerror(\"Error\", \"Invalid License File name format.\") return data = execute_query(\"SELECT hostname, lmgrd_port, vendor_daemon_port, lmgrd_file_id, vendor_daemon_file_id, options_file_id FROM LicenseFiles WHERE hostid=? ORDER BY LicenseFileId DESC LIMIT 1\", (hostid,)) if data: data = data[0] else: tkinter.messagebox.showinfo(\"Info\", \"No previous data found for the given Host ID.\") return hostname, lmgrd_port, vendor_daemon_port, lmgrd_file_id, vendor_daemon_file_id, options_file_id = data # Populate the fields hostname_entry.delete(0, tk.END) hostname_entry.insert(0, hostname) hostid_entry.delete(0, tk.END) hostid_entry.insert(0, hostid) lmgrd_port_entry.delete(0, tk.END) lmgrd_port_entry.insert(0, lmgrd_port) vendor_daemon_port_entry.delete(0, tk.END) vendor_daemon_port_entry.insert(0, vendor_daemon_port) # Fetch filenames for the file IDs lmgrd_file = execute_query(\"SELECT FileName FROM LicenseRelatedFiles WHERE ExecutableFileId=?\", (lmgrd_file_id,)) if lmgrd_file: lmgrd_file = lmgrd_file[0] lmgrd_file_combobox.set(lmgrd_file) vendor_daemon_file = execute_query(\"SELECT FileName FROM LicenseRelatedFiles WHERE ExecutableFileId=?\", (vendor_daemon_file_id,)) if vendor_daemon_file: vendor_daemon_file = vendor_daemon_file[0] vendor_daemon_file_combobox.set(vendor_daemon_file) if options_file_id: options_file = execute_query(\"SELECT FileName FROM LicenseRelatedFiles WHERE ExecutableFileId=?\", (options_file_id,)) if options_file: options_file = options_file[0] options_file_combobox.set(options_file) # Enable the \"Copy From Previous File\" button only when the other fields are empty if not hostname_entry.get() and not lmgrd_port_entry.get() and not vendor_daemon_port_entry.get(): copy_from_prev_button['state'] = tk.NORMAL else: copy_from_prev_button['state'] = tk.DISABLEDdef save_license_info(): license_file_id = execute_query(\"SELECT LicenseFileId FROM LicenseFiles WHERE FileName=?\", (license_file_combobox.get(),)) if license_file_id: license_file_id = license_file_id[0] lmgrd_file = lmgrd_file_combobox.get() vendor_daemon_file = vendor_daemon_file_combobox.get() options_file = options_file_combobox.get() update_sub_str_list = [] insert_sub_str_list = [] value_sub_str_list = [] if lmgrd_file: execute_commit(\"INSERT OR IGNORE INTO LicenseRelatedFiles (FileName) VALUES (?)\", (lmgrd_file,)) lmgrd_file_id = execute_query(\"SELECT ExecutableFileId FROM LicenseRelatedFiles WHERE FileName=?\", (lmgrd_file,)) if lmgrd_file_id: lmgrd_file_id = lmgrd_file_id[0][0] update_sub_str_list.append(\"lmgrd_file_id=?\") insert_sub_str_list.append(\"lmgrd_file_id\") value_sub_str_list.append(lmgrd_file_id) if vendor_daemon_file: execute_commit(\"INSERT OR IGNORE INTO LicenseRelatedFiles (FileName) VALUES (?)\", (vendor_daemon_file,)) vendor_daemon_file_id = execute_query(\"SELECT ExecutableFileId FROM LicenseRelatedFiles WHERE FileName=?\", (vendor_daemon_file,)) if vendor_daemon_file_id: vendor_daemon_file_id = vendor_daemon_file_id[0][0] update_sub_str_list.append(\"vendor_daemon_file_id=?\") insert_sub_str_list.append(\"vendor_daemon_file_id\") value_sub_str_list.append(vendor_daemon_file_id) if options_file: # Check if options_file exists. execute_commit(\"INSERT OR IGNORE INTO LicenseRelatedFiles (FileName) VALUES (?)\", (options_file,)) options_file_id = execute_query(\"SELECT ExecutableFileId FROM LicenseRelatedFiles WHERE FileName=?\", (options_file,)) if options_file_id: options_file_id = options_file_id[0][0] update_sub_str_list.append(\"options_file_id=?\") insert_sub_str_list.append(\"options_file_id\") value_sub_str_list.append(options_file_id) if license_file_id: # Update the existing record #cursor.execute(\"UPDATE LicenseFiles SET hostname=?, hostid=?, lmgrd_port=?, vendor_daemon_port=?, lmgrd_file_id=?, vendor_daemon_file_id=?, options_file_id=? WHERE LicenseFileId=?\", # (hostname_entry.get(), hostid_entry.get(), lmgrd_port_entry.get(), vendor_daemon_port_entry.get(), lmgrd_file_id, vendor_daemon_file_id, options_file_id, license_file_id[0])) if lmgrd_file or vendor_daemon_file or options_file: param = ( hostname_entry.get(), hostid_entry.get(), lmgrd_port_entry.get(), vendor_daemon_port_entry.get(), *value_sub_str_list, license_file_id[0] ) execute_commit(f\"UPDATE LicenseFiles SET hostname=?, hostid=?, lmgrd_port=?, vendor_daemon_port=?, {','.join(update_sub_str_list)} WHERE LicenseFileId=?\", param) else: execute_commit(\"UPDATE LicenseFiles SET hostname=?, hostid=?, lmgrd_port=?, vendor_daemon_port=? WHERE LicenseFileId=?\", (hostname_entry.get(), hostid_entry.get(), lmgrd_port_entry.get(), vendor_daemon_port_entry.get(), license_file_id[0])) else: # Insert a new record #cursor.execute(\"INSERT INTO LicenseFiles (FileName, hostname, hostid, lmgrd_port, vendor_daemon_port, lmgrd_file_id, vendor_daemon_file_id, options_file_id) VALUES (?, ?, ?, ?, ?, ?, ?, ?)\", # (license_file_combobox.get(), hostname_entry.get(), hostid_entry.get(), lmgrd_port_entry.get(), vendor_daemon_port_entry.get(), lmgrd_file_id, vendor_daemon_file_id, options_file_id)) if lmgrd_file or vendor_daemon_file or options_file: param = ( license_file_combobox.get(), hostname_entry.get(), hostid_entry.get(), lmgrd_port_entry.get(), vendor_daemon_port_entry.get(), *value_sub_str_list ) execute_commit(f\"INSERT INTO LicenseFiles (FileName, hostname, hostid, lmgrd_port, vendor_daemon_port, {','.join(insert_sub_str_list)}) VALUES (?, ?, ?, ?, ?, {','.join(['?'] * len(insert_sub_str_list))})\", param) else: execute_commit(\"INSERT INTO LicenseFiles (FileName, hostname, hostid, lmgrd_port, vendor_daemon_port, lmgrd_file_id, vendor_daemon_file_id, options_file_id) VALUES (?, ?, ?, ?, ?)\", (license_file_combobox.get(), hostname_entry.get(), hostid_entry.get(), lmgrd_port_entry.get(), vendor_daemon_port_entry.get())) #conn.commit() # Disable \"Save\" button after saved. save_button['state'] = tk.DISABLED tk.messagebox.showinfo(\"Info\", \"License file config saved successfully!\")app = tk.Tk()app.title(\"License Manager\")notebook = ttk.Notebook(app)notebook.pack(pady=10, padx=10, expand=True, fill='both')# Tab for Feature Nametab_feature = ttk.Frame(notebook)notebook.add(tab_feature, text=\"By Feature Name\")feature_names = get_all_features()ttk.Label(tab_feature, text=\"Feature Name:\").grid(row=0, column=0, sticky=tk.W, pady=5, padx=5)feature_name_combobox = ttk.Combobox(tab_feature, values=feature_names, width=30)feature_name_combobox.grid(row=0, column=1, pady=5, padx=5)ttk.Button(tab_feature, text=\"Search\", command=on_search_by_feature).grid(row=0, column=2, pady=5, padx=5)tree_by_feature = ttk.Treeview(tab_feature, columns=(\"StartDate\", \"EndDate\", \"Quantity\", \"FileName\", \"ProductId\"), show=\"headings\")tree_by_feature.heading(\"StartDate\", text=\"Start Date\")tree_by_feature.heading(\"EndDate\", text=\"End Date\")tree_by_feature.heading(\"Quantity\", text=\"Quantity\")tree_by_feature.heading(\"FileName\", text=\"License File\")tree_by_feature.heading(\"ProductId\", text=\"Product Id\")tree_by_feature.grid(row=1, column=0, columnspan=3, pady=10, padx=5, sticky=(tk.W, tk.E))# Tab for Product Idtab_product = ttk.Frame(notebook)notebook.add(tab_product, text=\"By Product Id\")product_ids = get_all_products()ttk.Label(tab_product, text=\"Product Id:\").grid(row=0, column=0, sticky=tk.W, pady=5, padx=5)product_id_combobox = ttk.Combobox(tab_product, values=product_ids, width=30)product_id_combobox.grid(row=0, column=1, pady=5, padx=5)ttk.Button(tab_product, text=\"Search\", command=on_search_by_product).grid(row=0, column=2, pady=5, padx=5)tree_by_product = ttk.Treeview(tab_product, columns=(\"StartDate\", \"EndDate\", \"Quantity\", \"FileName\", \"ProductId\"), show=\"headings\")tree_by_product.heading(\"StartDate\", text=\"Start Date\")tree_by_product.heading(\"EndDate\", text=\"End Date\")tree_by_product.heading(\"Quantity\", text=\"Quantity\")tree_by_product.heading(\"FileName\", text=\"License File\")tree_by_product.heading(\"ProductId\", text=\"Product Id\")tree_by_product.grid(row=1, column=0, columnspan=3, pady=10, padx=5, sticky=(tk.W, tk.E))# Tab for License Settingstab_settings = ttk.Frame(notebook)notebook.add(tab_settings, text=\"License Settings\")license_files = get_all_license_files()ttk.Label(tab_settings, text=\"License File:\").grid(row=0, column=0, sticky=tk.W, pady=5, padx=5)license_file_combobox = ttk.Combobox(tab_settings, values=license_files, width=64)license_file_combobox.grid(row=0, column=1, pady=5, padx=5)license_file_combobox.bind(\"&lt;&lt;ComboboxSelected&gt;&gt;\", load_license_info)ttk.Label(tab_settings, text=\"Hostname:\").grid(row=1, column=0, sticky=tk.W, pady=5, padx=5)hostname_entry = ttk.Entry(tab_settings, width=64)hostname_entry.grid(row=1, column=1, pady=5, padx=5)ttk.Label(tab_settings, text=\"Host ID:\").grid(row=2, column=0, sticky=tk.W, pady=5, padx=5)hostid_entry = ttk.Entry(tab_settings, width=64)hostid_entry.grid(row=2, column=1, pady=5, padx=5)ttk.Label(tab_settings, text=\"Lmgrd Port:\").grid(row=3, column=0, sticky=tk.W, pady=5, padx=5)lmgrd_port_entry = ttk.Entry(tab_settings, width=64)lmgrd_port_entry.grid(row=3, column=1, pady=5, padx=5)ttk.Label(tab_settings, text=\"Vendor Daemon Port:\").grid(row=4, column=0, sticky=tk.W, pady=5, padx=5)vendor_daemon_port_entry = ttk.Entry(tab_settings, width=64)vendor_daemon_port_entry.grid(row=4, column=1, pady=5, padx=5)license_related_files = get_all_license_related_files()ttk.Label(tab_settings, text=\"LMGRD FILE:\").grid(row=5, column=0, sticky=tk.W, pady=5, padx=5)lmgrd_file_combobox = ttk.Combobox(tab_settings, values=license_related_files, width=64)lmgrd_file_combobox.grid(row=5, column=1, pady=5, padx=5)ttk.Label(tab_settings, text=\"VENDOR DAEMON FILE:\").grid(row=6, column=0, sticky=tk.W, pady=5, padx=5)vendor_daemon_file_combobox = ttk.Combobox(tab_settings, values=license_related_files, width=64)vendor_daemon_file_combobox.grid(row=6, column=1, pady=5, padx=5)ttk.Label(tab_settings, text=\"OPTIONS FILE:\").grid(row=7, column=0, sticky=tk.W, pady=5, padx=5)options_file_combobox = ttk.Combobox(tab_settings, values=license_related_files, width=64)options_file_combobox.grid(row=7, column=1, pady=5, padx=5)# Bind the check_inputs_filled function to the inputshostname_entry.bind(\"&lt;KeyRelease&gt;\", lambda e: check_inputs_filled())hostid_entry.bind(\"&lt;KeyRelease&gt;\", lambda e: check_inputs_filled())lmgrd_port_entry.bind(\"&lt;KeyRelease&gt;\", lambda e: check_inputs_filled())vendor_daemon_port_entry.bind(\"&lt;KeyRelease&gt;\", lambda e: check_inputs_filled())lmgrd_file_combobox.bind(\"&lt;&lt;ComboboxSelected&gt;&gt;\", lambda e: check_inputs_filled())vendor_daemon_file_combobox.bind(\"&lt;&lt;ComboboxSelected&gt;&gt;\", lambda e: check_inputs_filled())options_file_combobox.bind(\"&lt;&lt;ComboboxSelected&gt;&gt;\", lambda e: check_inputs_filled())save_button = ttk.Button(tab_settings, text=\"Save to DB\", command=save_license_info, state=tk.DISABLED)save_button.grid(row=8, column=1, pady=10, padx=5, sticky=tk.E)copy_from_prev_button = ttk.Button(tab_settings, text=\"Copy From Previous File\", command=copy_from_previous_file, state=tk.DISABLED)copy_from_prev_button.grid(row=9, column=1, pady=10, padx=5, sticky=tk.W)def modify_license_file(): license_file = license_file_combobox.get() hostname = hostname_entry.get() hostid = hostid_entry.get() lmgrd_port = lmgrd_port_entry.get() vendor_daemon_port = vendor_daemon_port_entry.get() vendor_daemon_file = vendor_daemon_file_combobox.get() options_file = options_file_combobox.get() with open(license_file, 'r') as f: lines = f.readlines() modified = False for i, line in enumerate(lines): if line.startswith(\"SERVER\"): if line != f\"SERVER {hostname} {hostid} {lmgrd_port}\\n\": lines[i] = f\"SERVER {hostname} {hostid} {lmgrd_port}\\n\" modified = True elif line.startswith(\"DAEMON\"): daemon_line = f\"DAEMON cdslmd {vendor_daemon_file}\" if options_file: daemon_line = daemon_line + f\" OPTIONS={options_file}\" if vendor_daemon_port: daemon_line = daemon_line + f\" PORT={vendor_daemon_port}\" if options_file and line != f\"{daemon_line}\\n\": lines[i] = f\"{daemon_line}\\n\" modified = True if modified: with open(license_file, 'w') as f: f.writelines(lines) tk.messagebox.showinfo(\"Info\", \"License file modified successfully!\") else: tk.messagebox.showinfo(\"Info\", \"License file is already up-to-date!\") # Disable modify_button modify_button['state'] = tk.DISABLED# 在License Settings tab中添加Modify按钮modify_button = ttk.Button(tab_settings, text=\"Modify Lic File\", command=modify_license_file, state=tk.DISABLED)modify_button.grid(row=9, column=1, pady=10, padx=5, sticky=tk.E)# 比较两个License文件差异def compare_license_files(): file1 = license_file_combobox1.get() file2 = license_file_combobox2.get() if not file1 or not file2: tk.messagebox.showerror(\"Error\", \"Please select both license files.\") return data1 = retrieve_license_info_by_file(file1) data2 = retrieve_license_info_by_file(file2) # Convert data to a dictionary with product_id as key and list of date ranges as values dict1 = defaultdict(list) dict2 = defaultdict(list) for item in data1: dict1[item[4]].append(item) for item in data2: dict2[item[4]].append(item) compare_tree.delete(*compare_tree.get_children()) # Clear the treeview for product_id, date_ranges1 in dict1.items(): if product_id in dict2: date_ranges2 = dict2[product_id] for range1 in date_ranges1: for range2 in date_ranges2: if range1 != range2: compare_tree.insert(\"\", \"end\", values=(product_id, range1[2], range2[2], range1[0] + \" to \" + range1[1], range2[0] + \" to \" + range2[1])) del dict2[product_id] else: for range1 in date_ranges1: compare_tree.insert(\"\", \"end\", values=(product_id, range1[2], \"Not in File 2\", range1[0] + \" to \" + range1[1], \"Not in File 2\")) for product_id, date_ranges2 in dict2.items(): for range2 in date_ranges2: compare_tree.insert(\"\", \"end\", values=(product_id, \"Not in File 1\", range2[2], \"Not in File 1\", range2[0] + \" to \" + range2[1]))def retrieve_license_info_by_file(file_name): query = \"\"\" SELECT pd.StartDate, pd.EndDate, pd.Quantity, lf.FileName, p.ProductId FROM ProductDates pd JOIN Products p ON pd.ProductId = p.ProductId JOIN LicenseFiles lf ON pd.LicenseFileId = lf.LicenseFileId WHERE lf.FileName = ? \"\"\" return execute_query(query, (file_name,))# Code for New Tab for Comparing License Filestab_compare = ttk.Frame(notebook)notebook.add(tab_compare, text=\"Compare Lic Files\")license_files = get_all_license_files()ttk.Label(tab_compare, text=\"License File 1:\").grid(row=0, column=0, sticky=tk.W, pady=5, padx=5)license_file_combobox1 = ttk.Combobox(tab_compare, values=license_files, width=30)license_file_combobox1.grid(row=0, column=1, pady=5, padx=5)ttk.Label(tab_compare, text=\"License File 2:\").grid(row=1, column=0, sticky=tk.W, pady=5, padx=5)license_file_combobox2 = ttk.Combobox(tab_compare, values=license_files, width=30)license_file_combobox2.grid(row=1, column=1, pady=5, padx=5)ttk.Button(tab_compare, text=\"Compare\", command=compare_license_files).grid(row=2, column=0, columnspan=2, pady=5, padx=5)compare_tree = ttk.Treeview(tab_compare, columns=(\"ProductId\", \"Quantity1\", \"Quantity2\", \"DateRange1\", \"DateRange2\"), show=\"headings\")compare_tree.heading(\"ProductId\", text=\"Product Id\")compare_tree.heading(\"Quantity1\", text=\"Quantity (File 1)\")compare_tree.heading(\"Quantity2\", text=\"Quantity (File 2)\")compare_tree.heading(\"DateRange1\", text=\"Date Range (File 1)\")compare_tree.heading(\"DateRange2\", text=\"Date Range (File 2)\")compare_tree.grid(row=3, column=0, columnspan=2, pady=10, padx=5, sticky=(tk.W, tk.E))# License Acceptancedef load_csv_file(): filepath = filedialog.askopenfilename(filetypes=[(\"CSV Files\", \"*.csv\"), (\"All Files\", \"*.*\")]) if not filepath: return data = {} with open(filepath, 'r') as file: reader = csv.reader(file) next(reader) # skip header for row in reader: product_id, quantity = row data[product_id] = int(quantity) return datadef compare_license_to_csv(): license_file = license_file_combobox3.get() csv_data = load_csv_file() if not license_file or not csv_data: tk.messagebox.showerror(\"Error\", \"Please select both license file and CSV file.\") return license_data = retrieve_license_info_by_file(license_file) # Convert license data to a dictionary license_dict = defaultdict(list) for item in license_data: license_dict[item[4]].append(item) acceptance_tree.delete(*acceptance_tree.get_children()) # Clear the treeview for product_id, quantity in csv_data.items(): if product_id in license_dict: quantities = \", \".join([str(item[2]) for item in license_dict[product_id][-1::-1]]) date_ranges = \", \".join([str(item[2]) + \":\" + item[0] + \" to \" + item[1] for item in license_dict[product_id][-1::-1]]) acceptance_tree.insert(\"\", \"end\", values=(product_id, quantity, quantities, date_ranges)) del license_dict[product_id] else: acceptance_tree.insert(\"\", \"end\", values=(product_id, quantity, \"Not in License File\", \"Not in License File\")) for product_id, items in license_dict.items(): quantities = \", \".join([str(item[2]) for item in items[-1::-1]]) date_ranges = \", \".join([str(item[2]) + \":\" + item[0] + \" to \" + item[1] for item in items[-1::-1]]) acceptance_tree.insert(\"\", \"end\", values=(product_id, \"Not in CSV\", quantities, date_ranges))def export_to_excel(): file_name = tk.filedialog.asksaveasfilename(defaultextension=\".xlsx\", filetypes=[(\"Excel files\", \"*.xlsx\"), (\"All Files\", \"*.*\")]) if not file_name: return wb = openpyxl.Workbook() ws = wb.active ws.title = \"License Acceptance\" # Add headers headers = [\"Product ID\", \"CSV Quantity\", \"License Quantity\", \"Date Ranges\"] for col_num, header in enumerate(headers, 1): col_letter = openpyxl.utils.get_column_letter(col_num) ws[f\"{col_letter}1\"] = header ws[f\"{col_letter}1\"].font = openpyxl.styles.Font(bold=True) # Add data from the treeview for row_num, row_id in enumerate(acceptance_tree.get_children(), 2): row_data = acceptance_tree.item(row_id)[\"values\"] for col_num, cell_data in enumerate(row_data, 1): ws.cell(row=row_num, column=col_num, value=cell_data) wb.save(file_name) tk.messagebox.showinfo(\"Info\", f\"Data exported to {file_name} successfully!\")# Tab for License Acceptancetab_acceptance = ttk.Frame(notebook)notebook.add(tab_acceptance, text=\"License Acceptance\")license_files = get_all_license_files()ttk.Label(tab_acceptance, text=\"License File:\").grid(row=0, column=0, sticky=tk.W, pady=5, padx=5)license_file_combobox3 = ttk.Combobox(tab_acceptance, values=license_files, width=64)license_file_combobox3.grid(row=0, column=1, pady=5, padx=5)ttk.Button(tab_acceptance, text=\"Compare\", command=compare_license_to_csv).grid(row=0, column=2, pady=5, padx=5)export_button = ttk.Button(tab_acceptance, text=\"Export to Excel\", command=export_to_excel)export_button.grid(row=3, column=1, pady=10, padx=5, sticky=tk.E)acceptance_tree = ttk.Treeview(tab_acceptance, columns=(\"ProductId\", \"CSV QTY\", \"License QTY\", \"Date Ranges\"), show=\"headings\")acceptance_tree.heading(\"ProductId\", text=\"Product Id\")acceptance_tree.heading(\"CSV QTY\", text=\"CSV QTY\")acceptance_tree.heading(\"License QTY\", text=\"License QTY\")acceptance_tree.heading(\"Date Ranges\", text=\"Date Ranges\")acceptance_tree.grid(row=1, column=0, columnspan=3, pady=10, padx=5, sticky=(tk.W, tk.E))# About Tabtab_about = ttk.Frame(notebook)notebook.add(tab_about, text=\"关于\")ttk.Label(tab_about, text=\"作者：wanlinwang\").grid(row=0, column=0, pady=10, padx=10)ttk.Label(tab_about, text=\"日期：Oct-16-2023\").grid(row=1, column=0, pady=10, padx=10)ttk.Label(tab_about, text=\"帮助：如有疑问，请联系wanlinwang\").grid(row=2, column=0, pady=10, padx=10)app.mainloop()" }, { "title": "vnc灰屏", "url": "/posts/vnc-grey-screen/", "categories": "", "tags": "vnc", "date": "2023-10-13 02:13:00 +0000", "snippet": "在Ubuntu 18服务器上，从root账号的terminal里，执行su user01，然后执行vncserver启动一个vnc桌面。从vncviewer去连接时提示Failed to connect to socket /run/user/0/bus: Permission denied，并且屏幕是灰屏的。这个问题是因为你从 root 用户切换到 user01 时，某些环境变量（特别是关...", "content": "在Ubuntu 18服务器上，从root账号的terminal里，执行su user01，然后执行vncserver启动一个vnc桌面。从vncviewer去连接时提示Failed to connect to socket /run/user/0/bus: Permission denied，并且屏幕是灰屏的。这个问题是因为你从 root 用户切换到 user01 时，某些环境变量（特别是关于 D-Bus 的）没有被正确地设置。这导致 VNC 试图连接到 root 用户的 D-Bus 会话，而不是 user01 的会话。为了解决这个问题，你可以尝试以下步骤： 使用完整的登录 shell 切换到 user01: 当你使用 su user01 时，你只是简单地切换到了 user01，但没有加载 user01 的完整环境。为了加载完整的环境，你应该使用以下命令： su -l user01 手动设置 XDG_RUNTIME_DIR: 如果上述方法不起作用，你可以尝试手动设置 XDG_RUNTIME_DIR 环境变量。这个变量通常指向 /run/user/&lt;UID&gt;，其中 &lt;UID&gt; 是用户的 UID。 export XDG_RUNTIME_DIR=/run/user/$(id -u) 启动 VNC 服务器: 在设置了正确的环境变量之后，你可以尝试再次启动 VNC 服务器。 考虑使用 vncserver 的完整路径: 有时，确保你使用的是正确的 vncserver 也很重要。你可以使用 which vncserver 来查找其完整路径，然后使用该路径来启动它。 检查 VNC 日志: 如果你仍然遇到问题，你应该检查 VNC 的日志文件，通常位于 ~/.vnc/ 目录下。这可能会给你更多关于问题的线索。 确保 D-Bus 正在运行: 你可以使用以下命令来检查 D-Bus 是否正在为 user01 运行： ps aux | grep dbus | grep user01 希望这些步骤能帮助你解决问题！" }, { "title": "cloud-init模板镜像的创建与使用", "url": "/posts/preparing-cloud-init-template/", "categories": "", "tags": "pve", "date": "2023-10-13 01:00:00 +0000", "snippet": "Abstract本文介绍，在Proxmox Virtual Environment（pve）上，cloud-init模板镜像的创建与使用。StepsPrepare a VM这里使用CentOS 7.9.2209虚拟机Install cloud-initapt-get install cloud-initAdd Cloud-Init CD-ROM driveShutdown the VM. E...", "content": "Abstract本文介绍，在Proxmox Virtual Environment（pve）上，cloud-init模板镜像的创建与使用。StepsPrepare a VM这里使用CentOS 7.9.2209虚拟机Install cloud-initapt-get install cloud-initAdd Cloud-Init CD-ROM driveShutdown the VM. Execute blow code snippet on pve host,qm set 10071 --ide2 local-xfs:cloudinitqm set 10071 --boot order=scsi0qm template 10071Deploying Cloud-Init Templatesqm clone 10071 171 --name CentOS-7-9-001qm set 171 --sshkey ~/.ssh/id_rsa.pubqm set 171 --ipconfig0 ip=172.16.0.171/24,gw=172.16.0.1" }, { "title": "merge synopsys license file", "url": "/posts/merge-synospsy-license-file/", "categories": "icenv", "tags": "license", "date": "2023-08-22 14:04:58 +0000", "snippet": "对Synopsys License File的管理 修改从Synopsys获取的密钥： 只能修改许可证文件中的SERVER和VENDOR行，确保SERVER行包含正确的服务器主机名，VENDOR行包含snpslmd守护程序的完整路径。 任何更改都必须以ASCII文本格式保存。 不要添加、删除或修改许可证文件中的任何INCREMENT行，这样做会...", "content": "对Synopsys License File的管理 修改从Synopsys获取的密钥： 只能修改许可证文件中的SERVER和VENDOR行，确保SERVER行包含正确的服务器主机名，VENDOR行包含snpslmd守护程序的完整路径。 任何更改都必须以ASCII文本格式保存。 不要添加、删除或修改许可证文件中的任何INCREMENT行，这样做会使License无效。 如果从Synopsys获取临时密钥，可以将其附加到现有购买的License文件中，但需要删除重复的SERVER、VENDOR和USE_SERVER行。 使用sssverify程序验证密钥： 在使用来自Synopsys的任何新密钥文件之前，运行”SCL sssverify”实用程序来检查文件中的任何错误。 如果License文件没有错误，您将看到类似以下消息的输出：”License file integrity check PASSED”。 如果License文件损坏，您将收到相应的错误消息，并建议不使用该License文件。 确认SCL正在提供License Feature： 检查SCL服务器调试日志文件以查找启动错误。 确保lmgrd和snpslmd已正确启动，没有出现”SSS”错误。 如果调试日志文件中存在与SSS相关的错误消息，需要采取相应的措施来解决问题。多个Synopsys License被管理员合并完后，经常出现如下错误。请确保每个License File含[0,1]个SSS feature块，以及[0,n]个SSST feature块。 管理临时密钥： 临时密钥需要SSST功能。最好放在单独的服务器，以防止其被后续的生产密钥覆盖。 添加或删除临时密钥时，必须作为一个块进行操作，而不是单独处理每个密钥。 这些是对License管理的一些重要事项的总结。详细的指南和步骤可以在提供的PDF文档中找到。不像Cadence家每个hostid提供一个完整的License文件，Synopsys家的License是可合并的（一个购买的，与一个或多个临时的合并，除此之外的其余场景避免合并）。这里提供合并脚本，供参考：新版本#!/bin/env python3# Author: wanlinwang# Date: 27-Dec-2023# Synopsys License文件合并，遵循：合并后的文件，保留最多一个有效期内的SSS及其feature，保留零个或多个有效期内的SSST及其feature。# 程序流程图\"\"\"+---------------------------+| Parse Command Line Args || - Use argparse || - Accept -i and -o flags |+---------------------------+ | V+---------------------------+| Read and Parse License || Files || - Read each input file || - Split into feature || blocks || - Parse for name, trans- || action ID, and exp. date|+---------------------------+ | V+---------------------------+| Process and Merge || Features || - Classify as SSS or SSST || - Keep latest non-expired || SSS &amp; related features || - Keep all non-expired || SSST &amp; related features |+---------------------------+ | V+---------------------------+| Output Merged License || Content || - Write to specified || output file |+---------------------------+\"\"\"import argparseimport refrom datetime import datetimedef parse_feature_block(block): feature_name_and_expiration_date = re.search(r\"INCREMENT (\\w+) \\w+ \\S+ (\\d{2}-\\w{3}-\\d{4})\", block) transaction_id_match = re.search(r\"SN=[RT]K:[\\w-]+:[\\w-]+:(\\d+)\", block) feature_name = feature_name_and_expiration_date.group(1) if feature_name_and_expiration_date else None expiration_date = feature_name_and_expiration_date.group(2) if feature_name_and_expiration_date else None transaction_id = transaction_id_match.group(1) if transaction_id_match else None expiration_date = datetime.strptime(expiration_date, \"%d-%b-%Y\") if expiration_date else None return { \"name\": feature_name, \"transaction_id\": transaction_id, \"expiration_date\": expiration_date, \"block\": block }def parse_license_file(file_content): blocks = re.split(r'(?&lt;!#)INCREMENT', file_content)[1:] blocks = [f\"INCREMENT {b.strip()}\" for b in blocks] return [parse_feature_block(block) for block in blocks]def is_block_expired(block): return block['expiration_date'] and datetime.now() &gt; block['expiration_date']def merge_features(license_files_contents): all_blocks = [] for file_content in license_files_contents: all_blocks.extend(parse_license_file(file_content)) sss_blocks = [b for b in all_blocks if b['name'] == 'SSS' and not is_block_expired(b)] ssst_blocks = [b for b in all_blocks if b['name'] == 'SSST' and not is_block_expired(b)] # Keep only the latest SSS block if sss_blocks: latest_sss = max(sss_blocks, key=lambda b: b['expiration_date']) sss_transaction_id = latest_sss['transaction_id'] sss_related_blocks = [b for b in all_blocks if b['transaction_id'] == sss_transaction_id] else: sss_related_blocks = [] # Keep all non-expired SSST blocks and their associated features ssst_transaction_ids = set(b['transaction_id'] for b in ssst_blocks) ssst_related_blocks = [b for b in all_blocks if b['transaction_id'] in ssst_transaction_ids] merged_content = [b['block'] for b in sss_related_blocks + ssst_related_blocks] return \"\\n\".join(merged_content)def main(): parser = argparse.ArgumentParser(description=\"Merge Synopsys license files.\") parser.add_argument('-i', '--input', nargs='+', required=True, help=\"Input license files\") parser.add_argument('-o', '--output', required=True, help=\"Output merged license file\") args = parser.parse_args() license_files = args.input output_file = args.output license_contents = [open(file_path, 'r').read() for file_path in license_files] merged_license = merge_features(license_contents) with open(output_file, \"w\") as f: f.write(merged_license)if __name__ == \"__main__\": main()旧版本#!/bin/python3# Author: wanlinwang# Date: 23-Aug-2023# 本程序对未到期的feature进行合并。TODO：尚未考虑多个SSS与SSST块的场景，26-Dec-2023import sysimport datetimedef is_feature_expired(feature): # 从INCREMENT行中获取过期日期 fields = feature.split() if len(fields) &gt; 4: expire_date_str = fields[4] try: expire_date = datetime.datetime.strptime(expire_date_str, '%d-%b-%Y').date() today = datetime.date.today() return expire_date &lt; today except ValueError: return False # 如果日期格式不正确或不存在，我们将其视为未过期 return Falsedef merge_license_files(filenames): header_lines = [] features = [] for index, filename in enumerate(filenames): with open(filename, 'r') as f: content = f.read().strip() # 对于第一个license文件，获取所有非INCREMENT行作为header # 对于第二个及以后的license文件，只获取注释行 if not header_lines or index &gt; 0: for line in content.split(\"\\n\"): if not line.startswith(\"INCREMENT\"): # 只从第二个及之后的文件中获取注释行 if index == 0 or line.startswith(\"#\"): header_lines.append(line) else: break feature_blocks = content.split(\"INCREMENT\") # 假设每个feature块是以INCREMENT开始 for feature in feature_blocks[1:]: feature_with_prefix = \"INCREMENT\" + feature # 因为我们通过INCREMENT来分割，所以需要添加回去 if not is_feature_expired(feature_with_prefix): features.append(feature_with_prefix) return \"\\n\".join(header_lines + features)if __name__ == \"__main__\": if len(sys.argv) &lt; 3: print(\"Usage: python merge_licenses.py &lt;output_file&gt; &lt;license_file1&gt; [license_file2 ...]\") sys.exit(1) output_file = sys.argv[1] license_files = sys.argv[2:] merged_content = merge_license_files(license_files) with open(output_file, 'w') as f: f.write(merged_content) print(f\"Merged licenses saved to {output_file}.\")参考资料Synopsys License Verification" }, { "title": "ipa dns forwarder的注意事项", "url": "/posts/ipa-dns-forwarder/", "categories": "icenv", "tags": "ipa", "date": "2023-08-22 14:04:58 +0000", "snippet": "一、global DNS forwarder，在CentOS 7.9与CentOS 8.8上， 如果安装时指定了(global) DNS forwarder，安装完毕之后，使用ipa dnsconfig-mod --forwarder=8.8.8.8这样修改(global) DNS forwarder是不生效的。这可能是一个bug。 如果安装时没有指定(global) DNS forwa...", "content": "一、global DNS forwarder，在CentOS 7.9与CentOS 8.8上， 如果安装时指定了(global) DNS forwarder，安装完毕之后，使用ipa dnsconfig-mod --forwarder=8.8.8.8这样修改(global) DNS forwarder是不生效的。这可能是一个bug。 如果安装时没有指定(global) DNS forwarder，安装完毕之后，使用ipa dnsconfig-mod --forwarder=8.8.8.8这样设置(global) DNS forwarder是生效的。二、指定domain的DNS forwarder，在CentOS 7.9与CentOS 8.8上，在安装完毕之后，使用ipa dnsforwardzone-add google.com --skip-overlap-check --forwarder=8.8.8.8这样修改，在解析 google.com 时这个DNS forwarder是生效的。综上，1）在安装FreeIPA或IdM时，请不要指定DNS Forwarder，安装之后再设置即可；2）如果已有的FreeIPA或IdM已经设置了DNS Forwarder，但这个DNS Forwarder变得不可用，那可以使用ipa dnsforwardzone-add google.com --skip-overlap-check --forwarder=8.8.8.8语句为指定的域设置DNS Forwarder查询。" }, { "title": "CentOS 7.9上的FreeIPA HA 架构", "url": "/posts/freeipa-ha-on-centos7/", "categories": "icenv", "tags": "freeipa", "date": "2023-08-09 12:49:19 +0000", "snippet": "机器在proxmox virtual environment的虚拟机，防火墙在master与replica上执行，sudo firewall-cmd --add-service={freeipa-ldap,freeipa-ldaps,dns,mountd,rpc-bind} --permanent &amp;&amp; sudo firewall-cmd --reload包安装在master...", "content": "机器在proxmox virtual environment的虚拟机，防火墙在master与replica上执行，sudo firewall-cmd --add-service={freeipa-ldap,freeipa-ldaps,dns,mountd,rpc-bind} --permanent &amp;&amp; sudo firewall-cmd --reload包安装在master与replica上执行，sudo yum install -y freeipa-server ipa-server-dnsipa server配置如果上游DNS没有设置master与replica的解析记录，则我们在master与replica/etc/hosts加上映射关系，sudo tee -a /etc/hosts &gt; /dev/null &lt;&lt;EOF172.16.0.188 ipa-server-01.icinfra.cn172.16.0.189 ipa-server-02.icinfra.cnEOFsudo cp -a /etc/hosts /etc/cloud/templates/hosts.redhat.tmpl配置HA Master，sudo ipa-server-install --setup-dns --domain=icinfra.cn --realm=ICINFRA.CN --hostname=ipa-server-01.icinfra.cn --admin-password=Secret123 --ds-password=Secret123 --no-reverse --allow-zone-overlap --auto-forwarders -U==============================================================================Setup completeNext steps:\t1. You must make sure these network ports are open:\t\tTCP Ports:\t\t * 80, 443: HTTP/HTTPS\t\t * 389, 636: LDAP/LDAPS\t\t * 88, 464: kerberos\t\t * 53: bind\t\tUDP Ports:\t\t * 88, 464: kerberos\t\t * 53: bind\t\t * 123: ntp\t2. You can now obtain a kerberos ticket using the command: 'kinit admin'\t This ticket will allow you to use the IPA tools (e.g., ipa user-add)\t and the web user interface.Be sure to back up the CA certificates stored in /root/cacert.p12These files are required to create replicas. The password for thesefiles is the Directory Manager password[centos@vm-centos7-9-188 ~]$ 配置HA replica，sudo tee /etc/resolv.conf &gt; /dev/null &lt;&lt;EOF# 这里设置master为DNS服务器，在ipa-client-install时才会加入DNS记录，否则不加入。nameserver 172.16.0.188search icinfra.cnEOFsudo ipa-client-install --domain=icinfra.cn --server=ipa-server-01.icinfra.cn --hostname=ipa-server-02.icinfra.cn --enable-dns-updates -p admin -w Secret123 -Usudo ipa-replica-install --setup-dns --auto-forwarders -p Secret123sudo ipa-ca-install -p Secret123客户端配置sudo tee /etc/resolv.conf &gt; /dev/null &lt;&lt;EOF# 这里设置master与replica为DNS服务器，在ipa-client-install时才会加入DNS记录，否则不加入。nameserver 172.16.0.188nameserver 172.16.0.189search icinfra.cnEOFsudo yum install -y ipa-clientsudo ipa-client-install --server=ipa-server-01.icinfra.cn --server=ipa-server-02.icinfra.cn --domain=icinfra.cn -p admin -w Secret123 -U参考资料https://blog.csdn.net/thesre/article/details/117791657https://blog.csdn.net/thesre/article/details/124896546" }, { "title": "版本库彻底删除文件", "url": "/posts/svn-git-permanently-delete-files/", "categories": "", "tags": "", "date": "2023-08-09 12:08:45 +0000", "snippet": "wanlinwang, 2023/08/08SVN（Subversion）操作总结方法一：只保留一个Revision关键点： 使用svnadmin dump导出最新的revision。步骤如下：# step1: 获取最新的revision号svnlook youngest /path/to/svn/repo_dir# step2: 执行热备份（不保留日志）svnadmin hotcopy -...", "content": "wanlinwang, 2023/08/08SVN（Subversion）操作总结方法一：只保留一个Revision关键点： 使用svnadmin dump导出最新的revision。步骤如下：# step1: 获取最新的revision号svnlook youngest /path/to/svn/repo_dir# step2: 执行热备份（不保留日志）svnadmin hotcopy --clean-logs /path/to/svn/repo_dir /path/to/svn/repo_new_dir01# step3: 导出最新revisionsvnadmin dump /path/to/svn/repo_new_dir01 -r &lt;youngest_revision&gt;:&lt;youngest_revision&gt; &gt; /path/to/svn/repo_in_youngest_revision.dump# step4: 创建新的仓库svnadmin create --fs-type fsfs /path/to/svn/repo_new_dir# step5: 将导出的revision加载到新的仓库svnadmin load /path/to/svn/repo_new_dir &lt; /path/to/svn/repo_in_youngest_revision.dump# step6: 重命名仓库目录mv /path/to/svn/repo_dir /path/to/svn/repo_dir_bak20230808mv /path/to/svn/repo_new_dir /path/to/svn/repo_dir说明： 这种方法只保留了最新的revision。由于Subversion是基于节点增量存储，对没有修改的文件和目录会引用早期的revision，因此执行svnadmin dump -r &lt;youngest_revision&gt;时，会对每个节点进行递归重建，操作较为耗时。方法二：保留所有Revision关键点： 使用svndumpfilter命令。步骤如下：# step1: 导出整个仓库svnadmin dump /path/to/svn/repo_dir &gt; repo_dir.dump# step2: 使用svndumpfilter过滤不需要的目录cat repo_dir.dump | svndumpfilter exclude path/to/dir1 path/to/dir2 &gt; filtered.dump# step3: 创建新的仓库svnadmin create --fs-type fsfs /path/to/svn/repo_new_dir# step4: 将过滤后的数据加载到新仓库svnadmin load /path/to/svn/repo_new_dir &lt; filtered.dump# step5: 重命名仓库目录mv /path/to/svn/repo_dir /path/to/svn/repo_dir_bak20230808mv /path/to/svn/repo_new_dir /path/to/svn/repo_dir说明： 该方法保留所有的revision，仅通过过滤不需要的目录来实现精简。由于是导出全部revision，并且只做简单的过滤，操作相对较为快速。方法三：保留所有Revision（基于路径限制）关键点： 通过path-based限制访问并使用svnsync同步仓库。步骤如下：# step1: 在authz文件中定义待删除的目录或文件为不可读。# step2: 执行svnsync复制仓库。说明： 此方法未完全调研，但其主要思想是通过限制访问路径，再进行同步复制。这种方法可能对某些场景适用，但具体效果需要进一步验证。比较表 方法 效果 耗时 备注 方法一 删除历史revision 长 需要重新checkout一份仓库 方法二 保留所有revision 短 需要重新checkout一份仓库 方法三 未调研 未调研 未调研 结论：选择方法二经测试和讨论，推荐采用方法二，即保留所有的revision，并通过svndumpfilter进行过滤。这是一个较为高效且简单的解决方案。测试记录方法一： 耗时：约3小时8:54 svnlook youngest test_repo_bak202307280005018:55 svn info file:///data/user/wanin/test_repo_bak2023072800050110:05 svnadmin dump test_repo_bak20230728000501 -r 11998 &gt; test_repo_dump_r11998.dmp10:06 svnadmin create --fs-type fsfs test_repo_dump_r11998_new_repo10:06 svnadmin load test_repo_dump_r11998_new_repo &lt; test_repo_dump_r11998.dmp10:05 完成时间约：1小时55分钟方法二： 耗时：约43分钟仓库test_repo_bak20230808201044有12000个revision。20:55 svnadmin dump test_repo_bak20230808201044 &gt; test_repo_bak20230808201044.dump21:14 ls test_repo_bak20230808201044.dump21:15 cat test_repo_bak20230808201044.dump | svndumpfilter exclude `cat filelist.txt | xargs` &gt; test_repo_bak20230808201044_filtered.dump21:19 svnadmin create --fs-type fsfs test_repo_bak20230808201044_filtered21:38 svnadmin load test_repo_bak20230808201044_filtered &lt; test_repo_bak20230808201044_filtered.dumpGit操作参考参考文档：从存储库中删除敏感数据 - GitHub 文档" }, { "title": "libreoffice不能保存", "url": "/posts/cannot-save-file-with-libreoffice/", "categories": "icenv", "tags": "", "date": "2023-08-07 08:15:00 +0000", "snippet": "使用env LD_LIBRARY_PATH= /tools/opensrc/LibreOffice/7.3.0/opt/libreoffice7.3/program/soffice -env:UserInstallation=file:///tmp/wanlinwang/libreoffice7.3无法保存文件，重启了TurboVNC就好了。但根因未找到。", "content": "使用env LD_LIBRARY_PATH= /tools/opensrc/LibreOffice/7.3.0/opt/libreoffice7.3/program/soffice -env:UserInstallation=file:///tmp/wanlinwang/libreoffice7.3无法保存文件，重启了TurboVNC就好了。但根因未找到。" }, { "title": "SOCKS代理ChatGPT", "url": "/posts/socks-proxy/", "categories": "", "tags": "", "date": "2023-08-04 11:36:49 +0000", "snippet": "首先，我们需要在你的Windows 10或MacOS系统上使用SSH设置SOCKS代理。然后，我们将在浏览器上安装和配置SwitchyOmega插件，以使所有访问chat.openai.com的请求都通过这个代理服务器。第一步：设置SOCKS代理对于Windows 10： 首先，你需要在你的Windows系统上安装SSH客户端。你可以选择使用Git Bash，它可以从这个链接下载。...", "content": "首先，我们需要在你的Windows 10或MacOS系统上使用SSH设置SOCKS代理。然后，我们将在浏览器上安装和配置SwitchyOmega插件，以使所有访问chat.openai.com的请求都通过这个代理服务器。第一步：设置SOCKS代理对于Windows 10： 首先，你需要在你的Windows系统上安装SSH客户端。你可以选择使用Git Bash，它可以从这个链接下载。 安装完成后，打开Git Bash。 在Git Bash中，输入下面的命令（用你的实际情况替换&lt;username&gt;,&lt;proxy-server&gt;和&lt;port&gt;）：        ssh -D &lt;port&gt; -N &lt;username&gt;@&lt;proxy-server&gt;     如：         while true; do ssh -i /drives/c/Users/wanlinwang/.ssh/id_rsa -N -D 1080 root@rn-5bxxxx.thesre.lol; done      这条命令将在本地的8080端口上启动一个SOCKS代理，所有通过此代理的流量都将通过proxy-server.com服务器传输。 输入密码，如果你的服务器配置了公钥认证，可能需要提供私钥。 对于MacOS： 打开Terminal。 输入同样的命令：        ssh -D &lt;port&gt; -N &lt;username&gt;@&lt;proxy-server&gt;     第二步：配置SwitchyOmega 在Chrome或Firefox浏览器中安装SwitchyOmega插件。 在浏览器的地址栏中输入chrome://extensions/（Chrome）或about:addons（Firefox），然后找到SwitchyOmega并点击“选项”。 在SwitchyOmega的选项页面，点击左侧的“新建情景模式”。 输入情景模式的名称，例如“SOCKS Proxy”，然后选择“代理服务器”。 在“代理协议和服务器”部分，选择SOCKS5，输入127.0.0.1作为服务器地址，端口设置为你在第一步中选择的端口，例如1080。 点击左侧的“自动切换”，然后在“规则列表规则”中添加一条新的规则。在“主机通配符”中输入*.openai.com，然后在“情景模式”中选择你刚刚创建的“SOCKS Proxy”。 点击“应用选项”。 现在，当你访问任何以.openai.com结尾的网站时，你的请求将通过你在第一步中设置的SOCKS代理服务器转发。" }, { "title": "synopsys dev not in", "url": "/posts/synopsys-dve/", "categories": "icenv", "tags": "", "date": "2023-07-15 23:39:01 +0000", "snippet": "问题行业群问到，vcs带的dve命令启动报错ERROR - Unable to find valid DVE installation in $VCS_HOME/gui/dve, please download DVE installation package and install it under $VCS_HOME。分析这个错误提示表明你正在试图运行Synopsys VCS的DVE (...", "content": "问题行业群问到，vcs带的dve命令启动报错ERROR - Unable to find valid DVE installation in $VCS_HOME/gui/dve, please download DVE installation package and install it under $VCS_HOME。分析这个错误提示表明你正在试图运行Synopsys VCS的DVE (Design Vision Environment) 图形界面，但是在你设置的$VCS_HOME环境变量指定的目录下没有找到有效的DVE安装。这可能是因为DVE没有被正确安装，或者$VCS_HOME环境变量没有被正确设置。要解决这个问题，你可以尝试以下步骤： 确认DVE是否已经被正确安装。在你的Synopsys VCS安装目录下，应该有一个名为gui/dve的子目录。如果这个目录不存在，那么你可能需要重新安装DVE。 检查$VCS_HOME环境变量是否已经被正确设置。你可以在终端中输入echo $VCS_HOME来查看这个环境变量的值。这个值应该是你的Synopsys VCS安装目录的路径。如果这个值不正确，你需要更新$VCS_HOME环境变量的设置。 在C shell中，你可以使用以下命令来临时设置$VCS_HOME环境变量： setenv VCS_HOME /path/to/your/vcs/installation 要永久设置这个环境变量，你可以将上述export命令添加到你的shell启动脚本中，如C shell的~/.cshrc。 如果上述步骤都不能解决问题，那么你可能需要从Synopsys下载并重新安装DVE到$VCS_HOME目录下。 如果你还有问题，或者不确定如何进行，你可能需要联系Synopsys的技术支持获取帮助。" }, { "title": "Subversion Performance", "url": "/posts/subversion-performance/", "categories": "icenv", "tags": "svn", "date": "2023-06-12 13:46:33 +0000", "snippet": "背景据作者了解，截止至本文写作，芯片研发业务大多在使用CentOS/RHEL 7，其中7.9是final版本，使用的最多。还有些因历史项目与老旧工具版本，在使用CentOS/RHEL 5或者6的。在这些环境下，IT部署svn，一般是直接yum install subversion进行安装的。以CentOS 7.9为例，安装的是1.7.14版本的svn。软件在迭代升级过程中，除修复bug，新增...", "content": "背景据作者了解，截止至本文写作，芯片研发业务大多在使用CentOS/RHEL 7，其中7.9是final版本，使用的最多。还有些因历史项目与老旧工具版本，在使用CentOS/RHEL 5或者6的。在这些环境下，IT部署svn，一般是直接yum install subversion进行安装的。以CentOS 7.9为例，安装的是1.7.14版本的svn。软件在迭代升级过程中，除修复bug，新增feature，还有很重要的一点是带来性能提升。subversion也不例外，可以参考wandisco公司做的benchmark1。实验由wandisco公司提供的benchmark可以得到规律：subversion版本越高，获得的性能越强。我们用自己的环境做实验，当前版本1.7.14 vs. 最新稳定版本1.14.1。环境说明 序号 环境一 环境二 服务器 CentOS 7.9 CentOS 7.9 SVN Server 1.14.1 1.7.14 SVN Client 1.14.1 1.7.14 测试仓库所属业务 验证 验证 checkout仓库node数量     checkout仓库rev数量 14885 14885 update rev至 15669 15669 实验数据 序号 环境一 环境二 时间%降低至 co 63.470u 22.431s 110.595u 24.920s 63% co 63.467u 22.718s 113.484u 25.144s 62% up 44.089u 16.353s 84.621u 19.304s 58% up 43.856u 16.083s 83.391u 19.075s 58% 结论在常见的checkout与upadte场景下，svn 1.14.1比1.7.14性能更强——耗时降低至60%左右。鉴于实验结论，我们可以将svn升级到新版本以获得更优的性能。 http://live.wandisco.com/Fuhrmann_SVNlive2014%20Benchmarking%20SVN.pdf &#8617;&#xfe0e; " }, { "title": "a post with custom blockquotes", "url": "/posts/custom-blockquotes/", "categories": "sample-posts", "tags": "formatting, blockquotes", "date": "2023-05-12 19:53:00 +0000", "snippet": "This post shows how to add custom styles for blockquotes. Based on jekyll-gitbook implementation.We decided to support the same custom blockquotes as in jekyll-gitbook, which are also found in a lo...", "content": "This post shows how to add custom styles for blockquotes. Based on jekyll-gitbook implementation.We decided to support the same custom blockquotes as in jekyll-gitbook, which are also found in a lot of other sites’ styles. The styles definitions can be found on the _base.scss file, more specifically:/* Tips, warnings, and dangers */.post .post-content blockquote { &amp;.block-tip { border-color: var(--global-tip-block); background-color: var(--global-tip-block-bg); p { color: var(--global-tip-block-text); } h1, h2, h3, h4, h5, h6 { color: var(--global-tip-block-title); } } &amp;.block-warning { border-color: var(--global-warning-block); background-color: var(--global-warning-block-bg); p { color: var(--global-warning-block-text); } h1, h2, h3, h4, h5, h6 { color: var(--global-warning-block-title); } } &amp;.block-danger { border-color: var(--global-danger-block); background-color: var(--global-danger-block-bg); p { color: var(--global-danger-block-text); } h1, h2, h3, h4, h5, h6 { color: var(--global-danger-block-title); } }}A regular blockquote can be used as following:&gt; This is a regular blockquote&gt; and it can be used as usual This is a regular blockquoteand it can be used as usualThese custom styles can be used by adding the specific class to the blockquote, as follows:&gt; ##### TIP&gt;&gt; A tip can be used when you want to give advice&gt; related to a certain content.{: .block-tip } TIP A tip can be used when you want to give advicerelated to a certain content.&gt; ##### WARNING&gt;&gt; This is a warning, and thus should&gt; be used when you want to warn the user{: .block-warning } WARNING This is a warning, and thus shouldbe used when you want to warn the user&gt; ##### DANGER&gt;&gt; This is a danger zone, and thus should&gt; be used carefully{: .block-danger } DANGER This is a danger zone, and thus shouldbe used carefully" }, { "title": "Checkout request rejected by vendor-defined checkout filter报错", "url": "/posts/Checkout-request-rejected-by-vendor-defined-checkout-filter/", "categories": "icenv", "tags": "license", "date": "2023-05-10 00:43:45 +0000", "snippet": "问题软件运行报错Checkout request rejected by vendor-defined checkout filterFeature: Proto********S-RTLicense path: 27020@hostnameFlexNet Licensing error:-53,234Please choose another license.原因https://docs....", "content": "问题软件运行报错Checkout request rejected by vendor-defined checkout filterFeature: Proto********S-RTLicense path: 27020@hostnameFlexNet Licensing error:-53,234Please choose another license.原因https://docs.flexera.com/fnmea/2020r1/ConceptGuide/Content/helplibrary/License_Denials.htm 可获得该报错的解释，The application has a built-in test for the license that failed and rejected the license checkout. 。解决在License Server侧，执行lmutil lmreread -c &lt;license.txt&gt;一下license file解决。" }, { "title": "spack打开modules", "url": "/posts/enable-modules-with-spack/", "categories": "icenv", "tags": "spack", "date": "2023-05-07 09:13:22 +0000", "snippet": "背景spack是HPC使用最广的包管理器之一。最近行业内朋友频繁遇到一个问题：在使用新版本spack安装完工具后，未生成工具的modulefile。解决根据官网介绍，https://spack.readthedocs.io/en/latest/module_file_support.html#write-a-configuration-file可以打开tcl、lmod或者二者都打开。", "content": "背景spack是HPC使用最广的包管理器之一。最近行业内朋友频繁遇到一个问题：在使用新版本spack安装完工具后，未生成工具的modulefile。解决根据官网介绍，https://spack.readthedocs.io/en/latest/module_file_support.html#write-a-configuration-file可以打开tcl、lmod或者二者都打开。" }, { "title": "Python pillow修图", "url": "/posts/modify-image-with-pillow/", "categories": "icenv", "tags": "python", "date": "2023-05-07 02:47:38 +0000", "snippet": "背景以指定参数去调用Grafana可视化界面API生成图片。但API未提供修改图片（如title或其它区域）的功能，直接作为报告发送可能传达的信息不够清晰。步骤获取图片按照本文的步骤获取图片（数值已马赛克）：修图需求 将title修改掉； total Mean去掉，不重要。编码先安装好pillow模块pip3 install pillow然后码#!/usr/bin/env python3...", "content": "背景以指定参数去调用Grafana可视化界面API生成图片。但API未提供修改图片（如title或其它区域）的功能，直接作为报告发送可能传达的信息不够清晰。步骤获取图片按照本文的步骤获取图片（数值已马赛克）：修图需求 将title修改掉； total Mean去掉，不重要。编码先安装好pillow模块pip3 install pillow然后码#!/usr/bin/env python3# wanlinwang# 07-May-2023# 处理500x250的图片，修改标题，再抹掉部分信息。from PIL import Image, ImageFont, ImageDrawfilename=\"/Users/wanlinwang/image_processing/过去30天的License使用报告_20230407000000_to_20230507000000_raw.png\"filename_dst=\"/Users/wanlinwang/image_processing/过去30天的License使用报告_20230407000000_to_20230507000000_dest.png\"im = Image.open(filename)W, H = im.sizetitle_font = ImageFont.truetype('/Users/wanlinwang/image_processing/fonts/NotoSerifSC-Black.otf', 25)image_editable = ImageDraw.Draw(im)title_text=\"过去30天的License使用报告\"# (x0, y0, x1, y1), 填充黑色，抹掉原titleimage_editable.rectangle((0, 0, W, 36), fill=\"black\")# 加上新titleimage_editable.text((W/2, 0), title_text, (237, 230, 211), anchor='ma', font=title_font)# (x0, y0, x1, y1), 填充黑色，抹掉total Meanimage_editable.rectangle((135, 222, W, H), fill=\"black\")# 保存图片文件im.save(filename_dst)效果参考资料 ImageDraw.text()锚点参数说明：https://pillow.readthedocs.io/en/stable/reference/ImageDraw.html#PIL.ImageDraw.ImageDraw.text 获取图片像素点，在Windows上可以使用画图打开图片，将鼠标停留在图片任意像素点，即可在左下方显示像素点的坐标位置。在MacOS暂未找到方法，欢迎留言。" }, { "title": "从Grafana获取panel图片", "url": "/posts/rendering-image-from-grafana-panel/", "categories": "icenv", "tags": "report", "date": "2023-05-06 01:23:19 +0000", "snippet": "前言日常工作，有这样的需求：以指定的时间区间以及变量，获得Grafana panel图，并将多张图以邮件的方式发送到领导。步骤 先创建API key 获得Panel的图片链接打开Dashboard，在需要生成图片的Panel上，点击下拉-&gt;Share， 如果未安装Grafana image render plugin，则点击并按照提示安装，安装完毕后如下图所示...", "content": "前言日常工作，有这样的需求：以指定的时间区间以及变量，获得Grafana panel图，并将多张图以邮件的方式发送到领导。步骤 先创建API key 获得Panel的图片链接打开Dashboard，在需要生成图片的Panel上，点击下拉-&gt;Share， 如果未安装Grafana image render plugin，则点击并按照提示安装，安装完毕后如下图所示，复制“Direct link rendered image”链接。 在Python里，请求步骤2获得的链接，将response.content以二进制保存到文件里，该文件即是图片文件。此外，如果需要对图片进行部分遮盖、写文字，可以使用pillow模块。" }, { "title": "超线程", "url": "/posts/hyperthreading/", "categories": "icenv", "tags": "ht", "date": "2023-05-05 11:10:58 +0000", "snippet": "简介超线程是Intel与AMD的一项技术，通过在两个线程之间共享硬件资源，使得单cpu对操作系统而言是两个vcpu。超线程共享一个物理核心以及它的缓存系统。因为huancun 是共享的，所以在超线程之间移动数据不会有太多损失。但这也意味着如果在同一个物理核心的多个超线程运行的不同进程之间没有任何共享的数据，则每个虚拟核心的缓存大小只有真实物理核心的一半。对于内存受限的应用程序而言，将缓存减半...", "content": "简介超线程是Intel与AMD的一项技术，通过在两个线程之间共享硬件资源，使得单cpu对操作系统而言是两个vcpu。超线程共享一个物理核心以及它的缓存系统。因为huancun 是共享的，所以在超线程之间移动数据不会有太多损失。但这也意味着如果在同一个物理核心的多个超线程运行的不同进程之间没有任何共享的数据，则每个虚拟核心的缓存大小只有真实物理核心的一半。对于内存受限的应用程序而言，将缓存减半可能是一个严重的打击。因此，超线程有利有弊。许多HPC关闭了超线程，因为一些程序使用超线程反而更慢。如果我们使用超线程，我们总是希望进程靠近，这样共享缓存对两个虚拟处理器都有利。" }, { "title": "Process Sched", "url": "/posts/process-sched/", "categories": "", "tags": "", "date": "2023-04-27 08:47:12 +0000", "snippet": "构造用例使用perf抓取查看间隔，这里频率是250。也就是每4ms来看一次。开启准确的调度。开启HRTICK，实际上用得少。cat /proc//schedrenice 调整进程优先级。组调度。cgroup负载均衡。RCU是很重要的一个RCU stall detect", "content": "构造用例使用perf抓取查看间隔，这里频率是250。也就是每4ms来看一次。开启准确的调度。开启HRTICK，实际上用得少。cat /proc//schedrenice 调整进程优先级。组调度。cgroup负载均衡。RCU是很重要的一个RCU stall detect" }, { "title": "XDG_DATA_DIRS变量导致im-chooser不正常", "url": "/posts/XDG_DATA_DIRS-variable-cause-im-chooser-not-working/", "categories": "icenv", "tags": "im", "date": "2023-04-26 11:38:12 +0000", "snippet": "问题描述CentOS 7.9桌面用户，重新登录的vnc会话，运行im-chooser无法在右上角唤起输入法选择器。问题定位通过二分排除法定位到是spack安装的vim的modulefile里，好几句设置XDG_DATA_DIRS语句导致，prepend-path XDG_DATA_DIRS \"/tools/opensrc/spack/opt/spack/linux-tlinux2-icela...", "content": "问题描述CentOS 7.9桌面用户，重新登录的vnc会话，运行im-chooser无法在右上角唤起输入法选择器。问题定位通过二分排除法定位到是spack安装的vim的modulefile里，好几句设置XDG_DATA_DIRS语句导致，prepend-path XDG_DATA_DIRS \"/tools/opensrc/spack/opt/spack/linux-tlinux2-icelake/gcc-11.2.0/atk-2.36.0-44etyekjnugxjiz6tblr7zddv5igvzn2/share\"问题根因TODO参考资料 XDG_DATA_DIRS变量介绍： https://specifications.freedesktop.org/basedir-spec/basedir-spec-latest.html CentOS 7.9桌面用户安装中文输入法：https://blog.csdn.net/thesre/article/details/125595496" }, { "title": "降低Environment Modules的I/O Load", "url": "/posts/reduce-io-load/", "categories": "icenv", "tags": "modules", "date": "2023-04-12 04:34:10 +0000", "snippet": "背景在前司的多个数据中心中，每个数据中心都有多个集群，单个集群规模可以达到数千台物理机。当大量验证任务并发时，我们常常会遇到NFS卡死的问题。用户在执行ls命令时，可能会卡住几十秒，甚至无法响应。问题爆发后，CAD与IT部门之间出现了相互推诿的情况： CAD部门抱怨IT提供的存储性能太差，无法满足正常的业务需求； IT部门则责怪CAD没有合理引导业务，将许多不必要的I/O操作去除。分析通...", "content": "背景在前司的多个数据中心中，每个数据中心都有多个集群，单个集群规模可以达到数千台物理机。当大量验证任务并发时，我们常常会遇到NFS卡死的问题。用户在执行ls命令时，可能会卡住几十秒，甚至无法响应。问题爆发后，CAD与IT部门之间出现了相互推诿的情况： CAD部门抱怨IT提供的存储性能太差，无法满足正常的业务需求； IT部门则责怪CAD没有合理引导业务，将许多不必要的I/O操作去除。分析通过深入分析，发现问题的根源来自双方： CAD部门未能深入定制业务流程和脚本，很多任务是随意发展的。CAD自有的脚本和工具也缺乏性能优化； IT部门将项目目录与工具目录放在同一存储机头，未能将不同的业务隔离开。再加上CAD依赖的各种环境，导致在项目目录下执行ls命令时，需要从工具目录读取大量信息。解决方案（或缓解措施）针对不同根因，我们分别展开了讨论，并制定了解决方案。由于涉及的点较多，后续有机会再详细展开。本文将重点介绍如何通过Environment Modules减少I/O负载。2020年：首次提出优化方案在2020年时，开源社区的Environment Modules（TCL版）虽然实现了常见功能，但未关注性能优化。在我们的环境中，MODULEPATH路径下有约5000个modulefile文件，每次执行module av命令时，需要遍历MODULEPATH路径，并读取每个文件的第一行来判断是否存在Magic cookie，从而确定是否为有效的modulefile文件。当时我正好跟随李智慧学习缓存架构，我们开始对如何通过缓存优化Environment Modules的性能展开讨论。最终，我们提出了可行的方案： 缓存方案：每次安装完工具后，EDA管理员会将module av命令的结果以特定格式存储到一个文本文件中（缓存文件）。 包装命令：用户执行经过包装的module av命令时，命令只读取缓存文件，而不会再次遍历整个MODULEPATH路径。这种方式将每次执行的任务从用户每次递归遍历和读取几千个文件，转换为管理员一次递归遍历和读取几千个文件+用户每次读取一个缓存文件，极大地提升了用户的体验。2023年：开源社区对性能的进一步关注到了2023年，开源社区也开始关注Environment Modules的性能优化。在官方文档中，我们看到了几种优化I/O负载的技术： 使用TCL扩展库优化Modules通过使用专门为Modules优化的TCL扩展库，可以减少不必要的ioctl、fcntl和readlink系统调用，并且将getents的数量降低到50%。这些优化显著减少了I/O负载。 rc文件迁移至根层级将每个深层次的.modulerc与.version文件迁移到MODULEPATH路径的根层级。这样做可以显著减少access、stat、open、read和close系统调用的次数，从而减少I/O负担。 不再检查Magic Cookie在早期版本中，Environment Modules会通过读取每个modulefile的第一行来判断是否有效。然而，在我们的生产环境中，MODULEPATH路径下的文件几乎都是有效的modulefile。为了提高性能，我们可以取消这一Magic cookie的检查，从而减少不必要的open、read和close操作。 虚拟modules虚拟modules是一种缓存方案，将modulefile的路径缓存到.modulerc文件中。执行module av时，读取.modulerc即可直接获取所有modulefile路径，从而避免了遍历目录和读取多个文件的操作。 Module cache另一种缓存方案是使用module cachebuild命令，在每个MODULEPATH路径下创建缓存文件。执行module av时，直接读取缓存文件，而不需要再次遍历目录。虽然该方案会在每个路径下生成缓存文件，但它的性能与我之前的单一缓存方案相近，已经接近于理想的性能。 总结通过对Environment Modules的性能优化，我通过以下几种手段有效降低了I/O负载： 使用缓存来减少用户对文件系统的重复遍历； 利用TCL扩展库、rc文件迁移和取消Magic cookie检查来减少不必要的I/O操作； 使用虚拟modules和module cache进一步减少读取操作，提高性能。这些措施显著提升了环境中module av命令的响应速度，缓解了NFS卡死问题，也优化了CAD和IT部门之间的配合和工作效率。" }, { "title": "Linux下的rc file是什么？", "url": "/posts/what-are-rc-files-on-linux/", "categories": "icenv", "tags": "linux", "date": "2023-04-11 06:49:31 +0000", "snippet": "问题我们经常看到.cshrc，.bashrc这些“rc file”，它们为什么被称为“rc file”？介绍在Linux系统中，rc file是一个用于配置shell环境的文件。”rc”通常代表”run commands”或”resource configuration”，因此rc文件也称为运行命令或资源配置文件。据信它起源于 1965 年左右的 MIT 兼容时间共享系统 (CTSS) 的 ...", "content": "问题我们经常看到.cshrc，.bashrc这些“rc file”，它们为什么被称为“rc file”？介绍在Linux系统中，rc file是一个用于配置shell环境的文件。”rc”通常代表”run commands”或”resource configuration”，因此rc文件也称为运行命令或资源配置文件。据信它起源于 1965 年左右的 MIT 兼容时间共享系统 (CTSS) 的 runcom 工具。不同的shell可能有不同的rc文件名和位置。以下是一些常见的Linux shell及其对应的rc文件： Bash shell：~/.bashrc Zsh shell：~/.zshrc Ksh shell：~/.kshrc Csh shell：~/.cshrc Tcsh shell：~/.tcshrc当用户登录Linux系统时，shell会读取其对应的rc文件，并执行其中包含的命令和配置。这些命令和配置可以包括设置环境变量、定义别名、加载模块、设置提示符等。用户可以编辑其rc文件来自定义其shell环境。例如，可以添加自定义的别名，以便更快速地执行常用的命令，或者添加环境变量以定制其工作环境。需要注意的是，rc文件是shell启动时自动执行的，因此在编辑rc文件时要小心，确保不会意外地执行危险的命令或配置。" }, { "title": "Environment Modules是如何工作的？", "url": "/posts/how-does-environment-modules-work/", "categories": "icenv", "tags": "modules", "date": "2023-04-11 04:35:20 +0000", "snippet": "前言Environment Modules在我们芯片研发中已经耳熟能详了，那它是如何工作的呢？很多人对这个比较陌生，常常会问为什么我一个 .cshrc 只能够在 c shell 里 source，而一个 modulefile 例如 modulename 能够在多种 shell 环境中使用。目的本文通过对一个已经初始化好的 Environment Modules 环境的 module load...", "content": "前言Environment Modules在我们芯片研发中已经耳熟能详了，那它是如何工作的呢？很多人对这个比较陌生，常常会问为什么我一个 .cshrc 只能够在 c shell 里 source，而一个 modulefile 例如 modulename 能够在多种 shell 环境中使用。目的本文通过对一个已经初始化好的 Environment Modules 环境的 module load 步骤分析，来看它是如何工作的。解析bash 环境我们从命令开始，逐步分析一个初始化好的环境。首先来看 module 命令，它是一个 bash 函数，调用了 bash 函数 _module_raw：[centos@computing-server-133 ~]$ echo $0-bash[centos@computing-server-133 ~]$ type modulemodule is a functionmodule () { local _mlredir=1; if [ -n \"${MODULES_REDIRECT_OUTPUT+x}\" ]; then if [ \"$MODULES_REDIRECT_OUTPUT\" = '0' ]; then _mlredir=0; else if [ \"$MODULES_REDIRECT_OUTPUT\" = '1' ]; then _mlredir=1; fi; fi; fi; case \" $@ \" in *' --no-redirect '*) _mlredir=0 ;; *' --redirect '*) _mlredir=1; ;; esac; if [ $_mlredir -eq 0 ]; then _module_raw \"$@\"; else _module_raw \"$@\" 2&gt;&amp;1; fi}_module_raw 也是 bash 函数，它调用了 tclsh 程序，读取 tcl 脚本以及参数，生成更改环境的语句，再将其作为 eval 的参数，对当前 shell 做出更改。[centos@computing-server-133 ~]$ type _module_raw_module_raw is a function_module_raw () { eval \"$(/nfs/tools/os/spack/opt/spack/linux-centos7-x86_64_v4/gcc-12.2.0/tcl-8.6.12-5rkwrb3btdklgrkshepg5cctyigmfm37/bin/tclsh '/nfs/tools/os/spack/opt/spack/linux-centos7-x86_64_v4/gcc-12.2.0/environment-modules-5.2.0-upsh6wzxsg7airzqpjayrvoapfrtgttp/libexec/modulecmd.tcl' bash \"$@\")\"; _mlstatus=$?; return $_mlstatus}我们以加载 tcl-8.6.12-gcc-12.2.0-5rkwrb3 这个 modulefile 作为示例：[centos@computing-server-133 ~]$ ml show tcl-8.6.12-gcc-12.2.0-5rkwrb3-------------------------------------------------------------------/nfs/tools/os/spack/share/spack/modules/linux-centos7-x86_64_v4/tcl-8.6.12-gcc-12.2.0-5rkwrb3:module-whatis {Tcl (Tool Command Language) is a very powerful but easy to learn dynamic programming language, suitable for a very wide range of uses, including web and desktop applications, networking, administration, testing and many more. Open source and business-friendly, Tcl is a mature yet evolving language that is truly cross platform, easily deployed and highly extensible.}module load zlib-1.2.13-gcc-12.2.0-pobtkn4prepend-path --delim : PATH /nfs/tools/os/spack/opt/spack/linux-centos7-x86_64_v4/gcc-12.2.0/tcl-8.6.12-5rkwrb3btdklgrkshepg5cctyigmfm37/binprepend-path --delim : MANPATH /nfs/tools/os/spack/opt/spack/linux-centos7-x86_64_v4/gcc-12.2.0/tcl-8.6.12-5rkwrb3btdklgrkshepg5cctyigmfm37/manprepend-path --delim : MANPATH /nfs/tools/os/spack/opt/spack/linux-centos7-x86_64_v4/gcc-12.2.0/tcl-8.6.12-5rkwrb3btdklgrkshepg5cctyigmfm37/share/manprepend-path --delim : PKG_CONFIG_PATH /nfs/tools/os/spack/opt/spack/linux-centos7-x86_64_v4/gcc-12.2.0/tcl-8.6.12-5rkwrb3btdklgrkshepg5cctyigmfm37/lib/pkgconfigprepend-path --delim : CMAKE_PREFIX_PATH /nfs/tools/os/spack/opt/spack/linux-centos7-x86_64_v4/gcc-12.2.0/tcl-8.6.12-5rkwrb3btdklgrkshepg5cctyigmfm37/.setenv TCL_LIBRARY /nfs/tools/os/spack/opt/spack/linux-centos7-x86_64_v4/gcc-12.2.0/tcl-8.6.12-5rkwrb3btdklgrkshepg5cctyigmfm37/lib/tcl8.6-------------------------------------------------------------------[centos@computing-server-133 ~]$ mlNo Modulefiles Currently Loaded.[centos@computing-server-133 ~]$ /nfs/tools/os/spack/opt/spack/linux-centos7-x86_64_v4/gcc-12.2.0/tcl-8.6.12-5rkwrb3btdklgrkshepg5cctyigmfm37/bin/tclsh '/nfs/tools/os/spack/opt/spack/linux-centos7-x86_64_v4/gcc-12.2.0/environment-modules-5.2.0-upsh6wzxsg7airzqpjayrvoapfrtgttp/libexec/modulecmd.tcl' bash load tcl-8.6.12-gcc-12.2.0-5rkwrb3PATH=/nfs/tools/os/spack/opt/spack/linux-centos7-x86_64_v4/gcc-12.2.0/tcl-8.6.12-5rkwrb3btdklgrkshepg5cctyigmfm37/bin:/nfs/tools/os/spack/opt/spack/linux-centos7-x86_64_v4/gcc-12.2.0/environment-modules-5.2.0-upsh6wzxsg7airzqpjayrvoapfrtgttp/bin:/nfs/tools/os/spack/bin:/opt/ibm/lsfsuite/lsf/10.1/linux2.6-glibc2.3-x86_64/etc:/opt/ibm/lsfsuite/lsf/10.1/linux2.6-glibc2.3-x86_64/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/home/centos/.local/bin:/home/centos/bin; export PATH;__MODULES_SHARE_MANPATH=:1; export __MODULES_SHARE_MANPATH;MANPATH=/nfs/tools/os/spack/opt/spack/linux-centos7-x86_64_v4/gcc-12.2.0/tcl-8.6.12-5rkwrb3btdklgrkshepg5cctyigmfm37/share/man:/nfs/tools/os/spack/opt/spack/linux-centos7-x86_64_v4/gcc-12.2.0/tcl-8.6.12-5rkwrb3btdklgrkshepg5cctyigmfm37/man:/nfs/tools/os/spack/opt/spack/linux-centos7-x86_64_v4/gcc-12.2.0/zlib-1.2.13-pobtkn4lnv467woi4cerdauysxm42mn2/share/man:/opt/ibm/lsfsuite/lsf/10.1/man:; export MANPATH;__MODULES_LMPREREQ=tcl-8.6.12-gcc-12.2.0-5rkwrb3\\&amp;zlib-1.2.13-gcc-12.2.0-pobtkn4; export __MODULES_LMPREREQ;_LMFILES_=/nfs/tools/os/spack/share/spack/modules/linux-centos7-x86_64_v4/zlib-1.2.13-gcc-12.2.0-pobtkn4:/nfs/tools/os/spack/share/spack/modules/linux-centos7-x86_64_v4/tcl-8.6.12-gcc-12.2.0-5rkwrb3; export _LMFILES_;LOADEDMODULES=zlib-1.2.13-gcc-12.2.0-pobtkn4:tcl-8.6.12-gcc-12.2.0-5rkwrb3; export LOADEDMODULES;CMAKE_PREFIX_PATH=/nfs/tools/os/spack/opt/spack/linux-centos7-x86_64_v4/gcc-12.2.0/tcl-8.6.12-5rkwrb3btdklgrkshepg5cctyigmfm37/.:/nfs/tools/os/spack/opt/spack/linux-centos7-x86_64_v4/gcc-12.2.0/zlib-1.2.13-pobtkn4lnv467woi4cerdauysxm42mn2/.; export CMAKE_PREFIX_PATH;TCL_LIBRARY=/nfs/tools/os/spack/opt/spack/linux-centos7-x86_64_v4/gcc-12.2.0/tcl-8.6.12-5rkwrb3btdklgrkshepg5cctyigmfm37/lib/tcl8.6; export TCL_LIBRARY;__MODULES_LMTAG=zlib-1.2.13-gcc-12.2.0-pobtkn4\\&amp;auto-loaded; export __MODULES_LMTAG;PKG_CONFIG_PATH=/nfs/tools/os/spack/opt/spack/linux-centos7-x86_64_v4/gcc-12.2.0/tcl-8.6.12-5rkwrb3btdklgrkshepg5cctyigmfm37/lib/pkgconfig:/nfs/tools/os/spack/opt/spack/linux-centos7-x86_64_v4/gcc-12.2.0/zlib-1.2.13-pobtkn4lnv467woi4cerdauysxm42mn2/lib/pkgconfig; export PKG_CONFIG_PATH;test 0;[centos@computing-server-133 ~]$ which tclsh/nfs/tools/os/spack/opt/spack/linux-centos7-x86_64_v4/gcc-12.2.0/tcl-8.6.12-5rkwrb3btdklgrkshepg5cctyigmfm37/bin/tclsh可以看到它生成了的语句，包括了 modulefile 里显式对 PATH、MANPATH、PKG_CONFIG_PATH、CMAKE_PREFIX_PATH 等环境变量的修改，还包括了用户未定义的，对 Environment Modules 工具自身使用的变量做了修改。执行完查询后，tclsh 并没有被加载上。需要将这些语句传入 eval，才能在当前 shell 环境生效：[centos@computing-server-133 ~]$ eval `/nfs/tools/os/spack/opt/spack/linux-centos7-x86_64_v4/gcc-12.2.0/tcl-8.6.12-5rkwrb3btdklgrkshepg5cctyigmfm37/bin/tclsh '/nfs/tools/os/spack/opt/spack/linux-centos7-x86_64_v4/gcc-12.2.0/environment-modules-5.2.0-upsh6wzxsg7airzqpjayrvoapfrtgttp/libexec/modulecmd.tcl' bash load tcl-8.6.12-gcc-12.2.0-5rkwrb3`Loading tcl-8.6.12-gcc-12.2.0-5rkwrb3 Loading requirement: zlib-1.2.13-gcc-12.2.0-pobtkn4[centos@computing-server-133 ~]$ which tclsh/nfs/tools/os/spack/opt/spack/linux-centos7-x86_64_v4/gcc-12.2.0/tcl-8.6.12-5rkwrb3btdklgrkshepg5cctyigmfm37/bin/tclshc shell 环境在 csh 环境中，module 是一个 alias，同样地，它将生成的更改环境的语句传入 eval，使得环境修改生效。[centos@computing-server-133 ~]$ echo $0csh[centos@computing-server-133 ~]$ which modulemodule: \t aliased to set _prompt=$prompt:q; set prompt=\"\"; eval \"`/nfs/tools/os/spack/opt/spack/linux-centos7-x86_64_v4/gcc-12.2.0/tcl-8.6.12-5rkwrb3btdklgrkshepg5cctyigmfm37/bin/tclsh '/nfs/tools/os/spack/opt/spack/linux-centos7-x86_64_v4/gcc-12.2.0/environment-modules-5.2.0-upsh6wzxsg7airzqpjayrvoapfrtgttp/libexec/modulecmd.tcl' csh !*:q`\"; set _exit=\"$status\"; set prompt=$_prompt:q; unset _prompt; test 0 = $_exit同样的，我们加载 tcl-8.6.12-gcc-12.2.0-5rkwrb3 这个 modulefile：[centos@computing-server-133 ~]$ /nfs/tools/os/spack/opt/spack/linux-centos7-x86_64_v4/gcc-12.2.0/tcl-8.6.12-5rkwrb3btdklgrkshepg5cctyigmfm37/bin/tclsh '/nfs/tools/os/spack/opt/spack/linux-centos7-x86_64_v4/gcc-12.2.0/environment-modules-5.2.0-upsh6wzxsg7airzqpjayrvoapfrtgttp/libexec/modulecmd.tcl' csh load tcl-8.6.12-gcc-12.2.0-5rkwrb3setenv PATH /nfs/tools/os/spack/opt/spack/linux-centos7-x86_64_v4/gcc-12.2.0/tcl-8.6.12-5rkwrb3btdklgrkshepg5cctyigmfm37/bin:/opt/ibm/lsfsuite/lsf/10.1/linux2.6-glibc2.3-x86_64/etc:/opt/ibm/lsfsuite/lsf/10.1/linux2.6-glibc2.3-x86_64/bin:/nfs/tools/os/spack/opt/spack/linux-centos7-x86_64_v4/gcc-12.2.0/environment-modules-5.2.0-upsh6wzxsg7airzqpjayrvoapfrtgttp/bin:/nfs/tools/os/spack/bin:/usr/local/bin:/usr/bin:/usr/local/sbin:/usr/sbin:/home/centos/.local/bin:/home/centos/bin;setenv __MODULES_SHARE_MANPATH :1;setenv MANPATH /nfs/tools/os/spack/opt/spack/linux-centos7-x86_64_v4/gcc-12.2.0/tcl-8.6.12-5rkwrb3btdklgrkshepg5cctyigmfm37/share/man:/nfs/tools/os/spack/opt/spack/linux-centos7-x86_64_v4/gcc-12.2.0/tcl-8.6.12-5rkwrb3btdklgrkshepg5cctyigmfm37/man:/nfs/tools/os/spack/opt/spack/linux-centos7-x86_64_v4/gcc-12.2.0/zlib-1.2.13-pobtkn4lnv467woi4cerdauysxm42mn2/share/man:/opt/ibm/lsfsuite/lsf/10.1/man:;setenv __MODULES_LMPREREQ tcl-8.6.12-gcc-12.2.0-5rkwrb3\\&amp;zlib-1.2.13-gcc-12.2.0-pobtkn4;setenv _LMFILES_ /nfs/tools/os/spack/share/spack/modules/linux-centos7-x86_64_v4/zlib-1.2.13-gcc-12.2.0-pobtkn4:/nfs/tools/os/spack/share/spack/modules/linux-centos7-x86_64_v4/tcl-8.6.12-gcc-12.2.0-5rkwrb3;setenv LOADEDMODULES zlib-1.2.13-gcc-12.2.0-pobtkn4:tcl-8.6.12-gcc-12.2.0-5rkwrb3;setenv CMAKE_PREFIX_PATH /nfs/tools/os/spack/opt/spack/linux-centos7-x86_64_v4/gcc-12.2.0/tcl-8.6.12-5rkwrb3btdklgrkshepg5cctyigmfm37/.:/nfs/tools/os/spack/opt/spack/linux-centos7-x86_64_v4/gcc-12.2.0/zlib-1.2.13-pobtkn4lnv467woi4cerdauysxm42mn2/.;setenv TCL_LIBRARY /nfs/tools/os/spack/opt/spack/linux-centos7-x86_64_v4/gcc-12.2.0/tcl-8.6.12-5rkwrb3btdklgrkshepg5cctyigmfm37/lib/tcl8.6;setenv __MODULES_LMTAG zlib-1.2.13-gcc-12.2.0-pobtkn4\\&amp;auto-loaded;setenv PKG_CONFIG_PATH /nfs/tools/os/spack/opt/spack/linux-centos7-x86_64_v4/gcc-12.2.0/tcl-8.6.12-5rkwrb3btdklgrkshepg5cctyigmfm37/lib/pkgconfig:/nfs/tools/os/spack/opt/spack/linux-centos7-x86_64_v4/gcc-12.2.0/zlib-1.2.13-pobtkn4lnv467woi4cerdauysxm42mn2/lib/pkgconfig;test 0;Loading tcl-8.6.12-gcc-12.2.0-5rkwrb3 Loading requirement: zlib-1.2.13-gcc-12.2.0-pobtkn4[centos@computing-server-133 ~]$ which tclsh/nfs/tools/os/spack/opt/spack/linux-centos7-x86_64_v4/gcc-12.2.0/tcl-8.6.12-5rkwrb3btdklgrkshepg5cctyigmfm37/bin/tclsh总结上述介绍了 Environment Modules 对环境的修改原理。主要是通过对 tcl 语句的 modulefile 解析，生成对应 shell 类型的修改语句，再通过 eval 语句来完成对当前 shell 的环境修改。真正难得的是它如何生成对环境修改的语句。后续我们将深入探讨如何解析 modulefile 并生成环境更改语句。TODO如何解析 modulefile 并生成环境更改语句。" }, { "title": "解锁new bing的使用", "url": "/posts/new-bing-unlocking-in-cn/", "categories": "", "tags": "aigc", "date": "2023-03-30 02:47:25 +0000", "snippet": "New Bing的注册New Bing的访问问题一：未看到“聊天”按钮访问 https://www.bing.com/new 没有“聊天”按钮出现，如何打开New Bing的chat进行对话呢？如下图所示如下两图所示，将Country/Region设置为United States回到 https://www.bing.com/new 可以看到“聊天”现身问题二：提示Sorry, looks ...", "content": "New Bing的注册New Bing的访问问题一：未看到“聊天”按钮访问 https://www.bing.com/new 没有“聊天”按钮出现，如何打开New Bing的chat进行对话呢？如下图所示如下两图所示，将Country/Region设置为United States回到 https://www.bing.com/new 可以看到“聊天”现身问题二：提示Sorry, looks like your network settings are preventing access to this feature.配置 X-Forwarded-For 1.1.1.1" }, { "title": "new bing绘画", "url": "/posts/new-bing-create/", "categories": "", "tags": "aigc", "date": "2023-03-28 23:51:00 +0000", "snippet": "new bing推出了图片生成，地址请它画：一副很美的春天景色，微风细雨，苔痕上阶绿草色入帘青，油纸伞，柳絮飘飘，三两只鸟飞过。原图如下", "content": "new bing推出了图片生成，地址请它画：一副很美的春天景色，微风细雨，苔痕上阶绿草色入帘青，油纸伞，柳絮飘飘，三两只鸟飞过。原图如下" }, { "title": "离线自动化安装开源工具的方案探索", "url": "/posts/offline-packages-installing/", "categories": "icenv", "tags": "linux", "date": "2023-03-26 00:50:22 +0000", "snippet": "背景包括芯片设计公司在内，许多研发型公司为了数据安全与网络安全，会将其研发环境与互联网隔绝开来，从物理上禁止了数据在内外部自由流通，也禁止了来自外部的网络攻击。安全与效率总是不能够双双完美的，这种架构保证了安全，在很多需要数据传输、访问在线服务的场景上，这种架构就给效率打了折扣。研发环境开源工具的安装与管理，就是场景之一。设计方案Spack离线安装与使用的Use Case在线安装与使用的活动...", "content": "背景包括芯片设计公司在内，许多研发型公司为了数据安全与网络安全，会将其研发环境与互联网隔绝开来，从物理上禁止了数据在内外部自由流通，也禁止了来自外部的网络攻击。安全与效率总是不能够双双完美的，这种架构保证了安全，在很多需要数据传输、访问在线服务的场景上，这种架构就给效率打了折扣。研发环境开源工具的安装与管理，就是场景之一。设计方案Spack离线安装与使用的Use Case在线安装与使用的活动图离线安装与使用的活动图部署图实施方案下载与初始化Spack在centos7-9-online机器执行下载spack，配置初始化spack[centos@centos7-9-online os]$ git clone -c feature.manyFiles=true https://github.com/spack/spack.gitCloning into 'spack'...remote: Enumerating objects: 445711, done.remote: Counting objects: 100% (331/331), done.remote: Compressing objects: 100% (236/236), done.remote: Total 445711 (delta 162), reused 199 (delta 46), pack-reused 445380Receiving objects: 100% (445711/445711), 225.50 MiB | 18.27 MiB/s, done.Resolving deltas: 100% (182172/182172), done.[centos@localhost os]$ echo \". `readlink -f spack/share/spack/setup-env.sh`\" &gt;&gt; ~/.bashrc将spack目录拷贝到离线环境CentOS 7.9的/tools/os/目录，并配置其初始化[centos@centos7-9-offline ]$ echo \". /tools/os/spack/share/spack/setup-env.sh\" &gt;&gt; ~/.bashrc安装与配置编译器分别于centos7-9-online、centos7-9-offline的机器执行[centos@centos7-9-online ~]$ sudo yum install -y gcc gcc-c++ gcc-gfortran #安装编译器[centos@centos7-9-online ~]$ sudo yum install -y patch bzip2 lbzip2 readline-devel unzip #spack install时，有些基础的会被常见的包依赖。[centos@centos7-9-online ~]$ spack compiler find==&gt; Added 1 new compiler to /home/centos/.spack/linux/compilers.yaml gcc@4.8.5 gcc@12.2.0==&gt; Compilers are defined in the following files: /home/centos/.spack/linux/compilers.yaml[centos@centos7-9-online ~]$ cat /home/centos/.spack/linux/compilers.yamlcompilers:- compiler: spec: gcc@4.8.5 paths: cc: /usr/bin/gcc cxx: /usr/bin/g++ f77: /usr/bin/gfortran fc: /usr/bin/gfortran flags: {} operating_system: centos7 target: x86_64 modules: [] environment: {} extra_rpaths: []- compiler: spec: gcc@12.2.0 paths: cc: /nfs/tools/os/gcc/12.2.0/bin/gcc cxx: /nfs/tools/os/gcc/12.2.0/bin/g++ f77: /nfs/tools/os/gcc/12.2.0/bin/gfortran fc: /nfs/tools/os/gcc/12.2.0/bin/gfortran flags: {} operating_system: centos7 target: x86_64 modules: [] environment: {} extra_rpaths: []mirror在centos7-9-online机器[centos@centos7-9-online ~]$ mkdir /local/tools/os/spack/pkgs-mirror #创建mirror目录[centos@centos7-9-online ~]$ spack mirror create --directory /local/tools/os/spack/pkgs-mirror --dependencies vim +gtk +gui +lua +perl +python +ruby +x +cscope #这里以mirror vim为例==&gt; Concretizing input specs==&gt; Installing patchelf-0.13.1-x5afxqz2rtlfbcpghu5l542rhhbw3md7==&gt; No binary for patchelf-0.13.1-x5afxqz2rtlfbcpghu5l542rhhbw3md7 found: installing from source==&gt; Fetching https://github.com/NixOS/patchelf/releases/download/0.13.1/patchelf-0.13.1.tar.gz==&gt; No patches needed for patchelf==&gt; patchelf: Executing phase: 'autoreconf'==&gt; patchelf: Executing phase: 'configure'==&gt; patchelf: Executing phase: 'build'==&gt; patchelf: Executing phase: 'install'==&gt; patchelf: Successfully installed patchelf-0.13.1-x5afxqz2rtlfbcpghu5l542rhhbw3md7 Stage: 31.52s. Autoreconf: 0.00s. Configure: 1.15s. Build: 2.17s. Install: 0.03s. Total: 34.92s[+] /home/centos/.spack/bootstrap/store/linux-centos7-x86_64/gcc-4.8.5/patchelf-0.13.1-x5afxqz2rtlfbcpghu5l542rhhbw3md7==&gt; Fetching https://mirror.spack.io/bootstrap/github-actions/v0.4/build_cache/linux-centos7-x86_64-gcc-10.2.1-clingo-bootstrap-spack-prqkzynv2nwko5mktitebgkeumuxkveu.spec.json==&gt; Fetching https://mirror.spack.io/bootstrap/github-actions/v0.4/build_cache/linux-centos7-x86_64/gcc-10.2.1/clingo-bootstrap-spack/linux-centos7-x86_64-gcc-10.2.1-clingo-bootstrap-spack-prqkzynv2nwko5mktitebgkeumuxkveu.spack==&gt; Installing \"clingo-bootstrap@spack%gcc@10.2.1~docs~ipo+python+static_libstdcpp build_type=Release arch=linux-centos7-x86_64\" from a buildcache==&gt; Adding package at-spi2-atk@2.38.0 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/cf/cfa008a5af822b36ae6287f18182c40c91dd699c55faa38605881ed175ca464f.tar.xz==&gt; Adding package at-spi2-core@2.47.90 to mirror==&gt; Fetching http://ftp.gnome.org/pub/gnome/sources/at-spi2-core/2.47/at-spi2-core-2.47.90.tar.xz==&gt; Adding package atk@2.38.0 to mirror==&gt; Fetching http://ftp.gnome.org/pub/gnome/sources/atk/2.38/atk-2.38.0.tar.xz==&gt; Adding package autoconf@2.69 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/95/954bd69b391edc12d6a4a51a2dd1476543da5c6bbf05a95b59dc0dd6fd4c2969.tar.gz==&gt; Fetching https://mirror.spack.io/_source-cache/archive/ea/eaa3f69d927a853313a0b06e2117c51adab6377a2278549b05abc5df93643e16==&gt; Fetching https://mirror.spack.io/_source-cache/archive/77/7793209b33013dc0f81208718c68440c5aae80e7a1c4b8d336e382525af791a7==&gt; Fetching https://mirror.spack.io/_source-cache/archive/35/35c449281546376449766f92d49fc121ca50e330e60fefcfc9be2af3253082c2==&gt; Fetching https://mirror.spack.io/_source-cache/archive/a4/a49dd5bac3b62daa0ff688ab4d508d71dbd2f4f8d7e2a02321926346161bf3ee==&gt; Adding package autoconf-archive@2023.02.20 to mirror==&gt; Fetching https://ftpmirror.gnu.org/autoconf-archive/autoconf-archive-2023.02.20.tar.xz==&gt; Fetching https://mirror.spack.io/_source-cache/archive/13/139214f5104f699f868dc87a14378e1e694a3c2539efa0de6f878024f3d7c66d==&gt; Adding package automake@1.16.5 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/07/07bd24ad08a64bc17250ce09ec56e921d6343903943e99ccf63bbf0705e34605.tar.gz==&gt; Adding package bdftopcf@1.1 to mirror==&gt; Fetching https://www.x.org/archive/individual/app/bdftopcf-1.1.tar.gz==&gt; Adding package berkeley-db@18.1.40 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/0c/0cecb2ef0c67b166de93732769abdeba0555086d51de1090df325e18ee8da9c8.tar.gz==&gt; Adding package binutils@2.40 to mirror==&gt; Fetching https://ftpmirror.gnu.org/binutils/binutils-2.40.tar.bz2==&gt; Adding package bison@3.8.2 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/06/06c9e13bdf7eb24d4ceb6b59205a4f67c2c7e7213119644430fe82fbd14a0abb.tar.gz==&gt; Adding package bzip2@1.0.8 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/ab/ab5a03176ee106d3f0fa90e381da478ddae405918153cca248e682cd0c4a2269.tar.gz==&gt; Adding package ca-certificates-mozilla@2023-01-10 to mirror==&gt; Fetching https://curl.se/ca/cacert-2023-01-10.pem==&gt; Adding package cairo@1.16.0 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/5e/5e7b29b3f113ef870d1e3ecf8adf21f923396401604bda16d44be45e66052331.tar.xz==&gt; Adding package cmake@3.25.2 to mirror==&gt; Fetching https://github.com/Kitware/CMake/releases/download/v3.25.2/cmake-3.25.2.tar.gz==&gt; Fetching https://github.com/Kitware/CMake/releases/download/v3.25.2/cmake-3.25.2.tar.gz==&gt; Adding package cscope@15.9 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/c5/c5505ae075a871a9cd8d9801859b0ff1c09782075df281c72c23e72115d9f159.tar.gz==&gt; Adding package curl@8.0.1 to mirror==&gt; Fetching http://curl.haxx.se/download/curl-8.0.1.tar.bz2==&gt; Adding package dbus@1.13.6 to mirror==&gt; Fetching https://dbus.freedesktop.org/releases/dbus/dbus-1.13.6.tar.gz==&gt; Adding package diffutils@3.9 to mirror==&gt; Fetching https://ftpmirror.gnu.org/diffutils/diffutils-3.9.tar.xz==&gt; Adding package docbook-xml@4.5 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/4e/4e4e037a2b83c98c6c94818390d4bdd3f6e10f6ec62dd79188594e26190dc7b4.zip==&gt; Adding package docbook-xsl@1.79.2 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/31/316524ea444e53208a2fb90eeb676af755da96e1417835ba5f5eb719c81fa371.tar.bz2==&gt; Adding package elfutils@0.189 to mirror==&gt; Fetching https://sourceware.org/pub/elfutils/0.189/elfutils-0.189.tar.bz2==&gt; Fetching https://mirror.spack.io/_source-cache/archive/d7/d786d49c28d7f0c8fc27bab39ca8714e5f4d128c7f09bb18533a8ec99b38dbf8==&gt; Adding package expat@2.5.0 to mirror==&gt; Fetching https://github.com/libexpat/libexpat/releases/download/R_2_5_0/expat-2.5.0.tar.bz2==&gt; Warning: Error while fetching expat@2.5.0 All fetchers failed for spack-stage-expat-2.5.0-yfnrdymdzqycrzk6upmebtvxa2g5motq==&gt; Adding package findutils@4.9.0 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/a2/a2bfb8c09d436770edc59f50fa483e785b161a3b7b9d547573cb08065fd462fe.tar.xz==&gt; Adding package fixesproto@5.0 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/67/67865a0e3cdc7dec1fd676f0927f7011ad4036c18eb320a2b41dbd56282f33b8.tar.gz==&gt; Adding package flex@2.6.3 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/68/68b2742233e747c462f781462a2a1e299dc6207401dac8f0bbb316f48565c2aa.tar.gz==&gt; Fetching https://mirror.spack.io/_source-cache/archive/f8/f8b85a00849bfb58c9b68e177b369f1e060ed8758253ff8daa57a873eae7b7a5==&gt; Adding package font-util@1.4.0 to mirror==&gt; Fetching https://www.x.org/archive/individual/font/font-util-1.4.0.tar.gz==&gt; Fetching https://mirror.spack.io/_source-cache/archive/55/55861d9cf456bd717a3d30a3193402c02174ed3c0dcee828798165fe307ee324.tar.gz==&gt; Fetching https://mirror.spack.io/_source-cache/archive/63/63087cb61d17bfc9cd6f4f9359f63a3b1dd83300a31a42fd93dca084724c6afb.tar.gz==&gt; Fetching https://mirror.spack.io/_source-cache/archive/72/720b6a513894bfc09a163951ec3dd8311201e08ee40e8891547b6c129ffb5fce.tar.gz==&gt; Fetching https://mirror.spack.io/_source-cache/archive/d5/d5602f1d749ccd31d3bc1bb6f0c5d77400de0e5e3ac5abebd2a867aa2a4081a4.tar.gz==&gt; Fetching https://mirror.spack.io/_source-cache/archive/c4/c4923342f6068c83fd4f5dbcf60d671c28461300db7e2aee930c8634b1e4b74a.tar.gz==&gt; Fetching https://mirror.spack.io/_source-cache/archive/57/57c2db8824865117287d57d47f2c8cf4b2842d036c7475534b5054be69690c73.tar.gz==&gt; Fetching https://mirror.spack.io/_source-cache/archive/54/549c6ba59979da25e85c218a26e5c527c3c24ebab2c76509c1ebc34d94fae227.tar.gz==&gt; Fetching https://mirror.spack.io/_source-cache/archive/81/817703372f080d6508cf109011b17f3572ff31047559fe82d93b487ca4e4e2d9.tar.gz==&gt; Fetching https://mirror.spack.io/_source-cache/archive/45/4509703e9e581061309cf4823bffd4a93f10f48fe192a1d8be1f183fd6ab9711.tar.gz==&gt; Fetching https://mirror.spack.io/_source-cache/archive/49/493965263070a5ee2a301dfdb2e87c1ca3c00c7882bfb3dd99368565ba558ff5.tar.gz==&gt; Fetching https://mirror.spack.io/_source-cache/archive/46/46142c876e176036c61c0c24c0a689079704d5ca5b510d48c025861ee2dbf829.tar.gz==&gt; Fetching https://mirror.spack.io/_source-cache/archive/fc/fcecbfc475dfe5826d137f8edc623ba27d58d32f069165c248a013b3c566bb59.tar.gz==&gt; Fetching https://mirror.spack.io/_source-cache/archive/97/97ee77a9d8ca3e7caf0c78c386eb0b96e8a825ca3642ec035cfb83f5f2cf1475.tar.gz==&gt; Fetching https://mirror.spack.io/_source-cache/archive/61/61eb1fcfec89f7435cb92cd68712fbe4ba412ca562b1f5feec1f6daa1b8544f6.tar.gz==&gt; Fetching https://mirror.spack.io/_source-cache/archive/30/3022b6b124f4cc6aade961f8d1306f67ff42e3b7922fb2244847f287344aefea.tar.gz==&gt; Fetching https://mirror.spack.io/_source-cache/archive/a0/a0b146139363dd0a704c7265ff9cd9150d4ae7c0d248091a9a42093e1618c427.tar.gz==&gt; Fetching https://mirror.spack.io/_source-cache/archive/21/21166546b0490aa3ec73215fa4ea28d91c6027b56178800ba51426bd3d840cc3.tar.gz==&gt; Fetching https://mirror.spack.io/_source-cache/archive/ea/eaddfc6d9b32bf38c9dc87c354be3b646a385bc8d9de6e536269f6e1ca50644e.tar.gz==&gt; Fetching https://mirror.spack.io/_source-cache/archive/97/97d9c1e706938838e4134d74f0836ae9d9ca6705ecb405c9a0ac8fdcbd9c2159.tar.gz==&gt; Fetching https://mirror.spack.io/_source-cache/archive/79/79dfde93d356e41c298c2c1b9c638ec1a144f438d5146d0df6219afb1c2b8818.tar.gz==&gt; Fetching https://mirror.spack.io/_source-cache/archive/d3/d3b93f7f73a526919bf73a38e10ef4643cd541403a682a8068d54bbcdd9c7e27.tar.gz==&gt; Fetching https://mirror.spack.io/_source-cache/archive/02/02b3839ae79ba6a7750525bb3b0c281305664b95bf63b4a0baa230a277b4f928.tar.gz==&gt; Fetching https://mirror.spack.io/_source-cache/archive/c4/c43ae370932eb8a4789a5b1f9801da15228b0d4c803251785c38d82aef024a4b.tar.gz==&gt; Fetching https://mirror.spack.io/_source-cache/archive/33/3399b7586c18be509cdaeceeebf754b861faa1d8799dda1aae01aeb2a7a30f01.tar.gz==&gt; Fetching https://mirror.spack.io/_source-cache/archive/d6/d64b9bfa5fa8dedf084f1695997cc32149485d2a195c810f62a1991ab5cd5519.tar.gz==&gt; Fetching https://mirror.spack.io/_source-cache/archive/dc/dc3b8d5890480943e735e0375f0e0d8333094fcb6d6845ba321b2e39db78d148.tar.gz==&gt; Fetching https://mirror.spack.io/_source-cache/archive/9e/9e82783758e8c67a9aadaf1a7222d13418a87455e4ce0a9974fb1df0278bdf74.tar.gz==&gt; Fetching https://mirror.spack.io/_source-cache/archive/0a/0a8c77c1540dc376fb2bb5a02bd33ee5f3563fbac9fc07c7947cac462c4bb48a.tar.gz==&gt; Fetching https://mirror.spack.io/_source-cache/archive/ae/aeea5f130480a3f05149bde13d240e668d8fb4b32c02b18914fcccd1182abe72.tar.gz==&gt; Fetching https://mirror.spack.io/_source-cache/archive/50/503e70ee66af34f6ec4426c0f4ae708e9d30dafdcd58f671a87c7bf56b1952a3.tar.gz==&gt; Fetching https://mirror.spack.io/_source-cache/archive/25/254be39c09da1c4e77d2a75a2969330ee2db395120a428671c50aef3ab745fc0.tar.gz==&gt; Fetching https://mirror.spack.io/_source-cache/archive/d9/d9e86a8805b0fb78222409169d839a8531a1f5c7284ee117ff2a0af2e5016c3f.tar.gz==&gt; Fetching https://mirror.spack.io/_source-cache/archive/e8/e8c3417d89183b1fc383fb3e0f3948c0d01fabcb9edace8b7ec85eab8cdc18c4.tar.gz==&gt; Fetching https://mirror.spack.io/_source-cache/archive/38/38301bbdb6374494f30c0b44acc7052ed8fc2289e917e648ca566fc591f0a9e0.tar.gz==&gt; Fetching https://mirror.spack.io/_source-cache/archive/5e/5e05a642182ec6a77bd7cacb913d3c86b364429329a5f223b69792d418f90ae9.tar.gz==&gt; Adding package fontconfig@2.14.2 to mirror==&gt; Fetching https://www.freedesktop.org/software/fontconfig/release/fontconfig-2.14.2.tar.gz==&gt; Adding package fontsproto@2.1.3 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/72/72c44e63044b2b66f6fa112921621ecc20c71193982de4f198d9a29cda385c5e.tar.gz==&gt; Adding package freetype@2.11.1 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/f8/f8db94d307e9c54961b39a1cc799a67d46681480696ed72ecf78d4473770f09b.tar.gz==&gt; Adding package fribidi@1.0.12 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/0c/0cd233f97fc8c67bb3ac27ce8440def5d3ffacf516765b91c2cc654498293495.tar.xz==&gt; Adding package gawk@5.2.1 to mirror==&gt; Fetching https://ftpmirror.gnu.org/gawk/gawk-5.2.1.tar.xz==&gt; Adding package gdbm@1.23 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/74/74b1081d21fff13ae4bd7c16e5d6e504a4c26f7cde1dca0d963a484174bbcacd.tar.gz==&gt; Adding package gdk-pixbuf@2.42.10 to mirror==&gt; Fetching https://ftp.acc.umu.se/pub/gnome/sources/gdk-pixbuf/2.42/gdk-pixbuf-2.42.10.tar.xz==&gt; Adding package gettext@0.21.1 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/50/50dbc8f39797950aa2c98e939947c527e5ac9ebd2c1b99dd7b06ba33a6767ae6.tar.xz==&gt; Adding package glib@2.74.6 to mirror==&gt; Fetching https://download.gnome.org/sources/glib/2.74/glib-2.74.6.tar.xz==&gt; Adding package glproto@1.4.17 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/9d/9d8130fec2b98bd032db7730fa092dd9dec39f3de34f4bb03ceb43b9903dbc96.tar.gz==&gt; Adding package glx@1.4 to mirror==&gt; Adding package gmake@4.4.1 to mirror==&gt; Fetching https://ftpmirror.gnu.org/make/make-4.4.1.tar.gz==&gt; Fetching https://mirror.spack.io/_source-cache/archive/fe/fe5b60d091c33f169740df8cb718bf4259f84528b42435194ffe0dd5b79cd125==&gt; Fetching https://mirror.spack.io/_source-cache/archive/ca/ca60bd9c1a1b35bc0dc58b6a4a19d5c2651f7a94a4b22b2c5ea001a1ca7a8a7f==&gt; Adding package gmp@6.2.1 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/ea/eae9326beb4158c386e39a356818031bd28f3124cf915f8c5b1dc4c7a36b4d7c.tar.bz2==&gt; Adding package gobject-introspection@1.72.0 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/02/02fe8e590861d88f83060dd39cda5ccaa60b2da1d21d0f95499301b186beaabc.tar.xz==&gt; Fetching https://mirror.spack.io/_source-cache/archive/77/7700828b638c85255c87fcc317ea7e9572ff443f65c86648796528885e5b4cea==&gt; Adding package gperf@3.1 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/58/588546b945bba4b70b6a3a616e80b4ab466e3f33024a352fc2198112cdbb3ae2.tar.gz==&gt; Adding package gtkplus@3.24.29 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/f5/f57ec4ade8f15cab0c23a80dcaee85b876e70a8823d9105f067ce335a8268caa.tar.xz==&gt; Adding package harfbuzz@5.3.1 to mirror==&gt; Fetching https://github.com/harfbuzz/harfbuzz/releases/download/5.3.1/harfbuzz-5.3.1.tar.xz==&gt; Adding package hwloc@2.9.0 to mirror==&gt; Fetching https://download.open-mpi.org/release/hwloc/v2.9/hwloc-2.9.0.tar.gz==&gt; Adding package icu4c@66.1 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/52/52a3f2209ab95559c1cf0a14f24338001f389615bf00e2585ef3dbc43ecf0a2e.tgz==&gt; Fetching https://mirror.spack.io/_source-cache/archive/6b/6be0b8068b0f5047dad7f4f6f655529304f1abbc551c93223c6f41dafc1e8acc==&gt; Adding package inputproto@2.3.2 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/10/10eaadd531f38f7c92ab59ef0708ca195caf3164a75c4ed99f0c04f2913f6ef3.tar.gz==&gt; Warning: Error while fetching inputproto@2.3.2 sha256 checksum failed for /tmp/centos/spack-stage/spack-stage-inputproto-2.3.2-lchukheykgr7ssdkzqoc6rmu5jj3bb4d/inputproto-2.3.2.tar.gz==&gt; Adding package intltool@0.51.0 to mirror==&gt; Warning: Error while fetching intltool@0.51.0 All fetchers failed for spack-stage-intltool-0.51.0-tqjehgpvexhz6v6ctwifojbppjtcljh7==&gt; Adding package json-glib@1.6.6 to mirror==&gt; Fetching https://download.gnome.org/sources/json-glib/1.6/json-glib-1.6.6.tar.xz==&gt; Adding package kbproto@1.0.7 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/82/828cb275b91268b1a3ea950d5c0c5eb076c678fdf005d517411f89cc8c3bb416.tar.gz==&gt; Adding package libbsd@0.11.7 to mirror==&gt; Fetching https://libbsd.freedesktop.org/releases/libbsd-0.11.7.tar.xz==&gt; Adding package libcroco@0.6.13 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/76/767ec234ae7aa684695b3a735548224888132e063f92db585759b422570621d4.tar.xz==&gt; Adding package libedit@3.1-20210216 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/22/2283f741d2aab935c8c52c04b57bf952d02c2c02e651172f8ac811f77b1fc77a.tar.gz==&gt; Adding package libepoxy@1.4.3 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/0b/0b808a06c9685a62fca34b680abb8bc7fb2fda074478e329b063c1f872b826f6.tar.xz==&gt; Adding package libffi@3.3 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/72/72fba7922703ddfa7a028d513ac15a85c8d54c8d67f55fa5a4802885dc652056.tar.gz==&gt; Adding package libfontenc@1.1.7 to mirror==&gt; Fetching https://www.x.org/archive/individual/lib/libfontenc-1.1.7.tar.gz==&gt; Adding package libgcrypt@1.10.1 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/ef/ef14ae546b0084cd84259f61a55e07a38c3b53afc0f546bffcef2f01baffe9de.tar.bz2==&gt; Adding package libgit2@1.5.0 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/8d/8de872a0f201b33d9522b817c92e14edb4efad18dae95cf156cf240b2efff93e.tar.gz==&gt; Adding package libgpg-error@1.46 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/b7/b7e11a64246bbe5ef37748de43b245abd72cfcd53c9ae5e7fc5ca59f1c81268d.tar.bz2==&gt; Adding package libice@1.0.9 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/78/7812a824a66dd654c830d21982749b3b563d9c2dfe0b88b203cefc14a891edc0.tar.gz==&gt; Adding package libiconv@1.17 to mirror==&gt; Fetching https://ftp.gnu.org/gnu/libiconv/libiconv-1.17.tar.gz==&gt; Adding package libjpeg-turbo@2.1.4 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/a7/a78b05c0d8427a90eb5b4eb08af25309770c8379592bb0b8a863373128e6143f.tar.gz==&gt; Adding package libmd@1.0.4 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/f5/f51c921042e34beddeded4b75557656559cf5b1f2448033b4c1eec11c07e530f.tar.xz==&gt; Adding package libpciaccess@0.17 to mirror==&gt; Fetching https://www.x.org/archive/individual/lib/libpciaccess-0.17.tar.gz==&gt; Adding package libpng@1.6.39 to mirror==&gt; Fetching https://prdownloads.sourceforge.net/libpng/libpng-1.6.39.tar.xz==&gt; Adding package libpthread-stubs@0.4 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/50/50d5686b79019ccea08bcbd7b02fe5a40634abcfd4146b6e75c6420cc170e9d9.tar.gz==&gt; Adding package librsvg@2.51.0 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/89/89d32e38445025e1b1d9af3dd9d3aeb9f6fce527aeecbecf38b369b34c80c038.tar.xz==&gt; Adding package libsigsegv@2.14 to mirror==&gt; Fetching https://ftpmirror.gnu.org/libsigsegv/libsigsegv-2.14.tar.gz==&gt; Fetching https://ftp.gnu.org/gnu/libsigsegv/libsigsegv-2.14.tar.gz==&gt; Adding package libsm@1.2.3 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/1e/1e92408417cb6c6c477a8a6104291001a40b3bb56a4a60608fdd9cd2c5a0f320.tar.gz==&gt; Adding package libssh2@1.10.0 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/2d/2d64e90f3ded394b91d3a2e774ca203a4179f69aebee03003e5a6fa621e41d51.tar.gz==&gt; Adding package libtool@2.4.7 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/04/04e96c2404ea70c590c546eba4202a4e12722c640016c12b9b2f1ce3d481e9a8.tar.gz==&gt; Adding package libunwind@1.6.2 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/4a/4a6aec666991fb45d0889c44aede8ad6eb108071c3554fcdff671f9c94794976.tar.gz==&gt; Adding package libx11@1.8.4 to mirror==&gt; Fetching https://www.x.org/archive/individual/lib/libX11-1.8.4.tar.gz==&gt; Adding package libxau@1.0.8 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/c3/c343b4ef66d66a6b3e0e27aa46b37ad5cab0f11a5c565eafb4a1c7590bc71d7b.tar.gz==&gt; Adding package libxcb@1.14 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/a5/a55ed6db98d43469801262d81dc2572ed124edc3db31059d4e9916eb9f844c34.tar.xz==&gt; Adding package libxcrypt@4.4.33 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/e8/e87acf9c652c573a4713d5582159f98f305d56ed5f754ce64f57d4194d6b3a6f.tar.xz==&gt; Adding package libxdmcp@1.1.4 to mirror==&gt; Fetching https://www.x.org/archive/individual/lib/libXdmcp-1.1.4.tar.gz==&gt; Adding package libxext@1.3.3 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/eb/eb0b88050491fef4716da4b06a4d92b4fc9e76f880d6310b2157df604342cfe5.tar.gz==&gt; Adding package libxfixes@5.0.2 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/ad/ad8df1ecf3324512b80ed12a9ca07556e561b14256d94216e67a68345b23c981.tar.gz==&gt; Adding package libxfont@1.5.4 to mirror==&gt; Fetching https://www.x.org/archive/individual/lib/libXfont-1.5.4.tar.gz==&gt; Adding package libxft@2.3.2 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/26/26cdddcc70b187833cbe9dc54df1864ba4c03a7175b2ca9276de9f05dce74507.tar.gz==&gt; Adding package libxi@1.7.6 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/4e/4e88fa7decd287e58140ea72238f8d54e4791de302938c83695fc0c9ac102b7e.tar.gz==&gt; Adding package libxkbcommon@1.4.0 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/10/106cec5263f9100a7e79b5f7220f889bc78e7d7ffc55d2b6fdb1efefb8024031.tar.xz==&gt; Adding package libxkbfile@1.0.9 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/95/95df50570f38e720fb79976f603761ae6eff761613eb56f258c3cb6bab4fd5e3.tar.gz==&gt; Adding package libxml2@2.10.3 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/5d/5d2cc3d78bec3dbe212a9d7fa629ada25a7da928af432c93060ff5c17ee28a9c.tar.xz==&gt; Fetching https://mirror.spack.io/_source-cache/archive/96/96151685cec997e1f9f3387e3626d61e6284d4d6e66e0e440c209286c03e9cc7.tar.gz==&gt; Fetching https://mirror.spack.io/_source-cache/archive/3e/3e06d42596b105839648070a5921157fe284b932289ffdbfa304ddc3457e5637==&gt; Adding package libxpm@3.5.12 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/25/2523acc780eac01db5163267b36f5b94374bfb0de26fc0b5a7bee76649fd8501.tar.gz==&gt; Adding package libxrandr@1.5.0 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/1b/1b594a149e6b124aab7149446f2fd886461e2935eca8dca43fe83a70cf8ec451.tar.gz==&gt; Adding package libxrender@0.9.10 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/77/770527cce42500790433df84ec3521e8bf095dfe5079454a92236494ab296adf.tar.gz==&gt; Adding package libxslt@1.1.33 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/8e/8e36605144409df979cab43d835002f63988f3dc94d5d3537c12796db90e38c8.tar.gz==&gt; Adding package libxt@1.1.5 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/b5/b59bee38a9935565fa49dc1bfe84cb30173e2e07e1dcdf801430d4b54eb0caa3.tar.gz==&gt; Adding package libxtst@1.2.2 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/22/221838960c7b9058cd6795c1c3ee8e25bae1c68106be314bc3036a4f26be0e6c.tar.gz==&gt; Adding package llvm@7.1.0 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/71/71c93979f20e01f1a1cc839a247945f556fa5e63abf2084e8468b238080fd839.tar.gz==&gt; Fetching https://mirror.spack.io/_source-cache/archive/51/514926d661635de47972c7d403c9c4669235aa51e22e56d44676d2a2709179b6==&gt; Adding package lua@5.4.4 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/16/164c7849653b80ae67bec4b7473b884bf5cc8d2dca05653475ec2ed27b9ebf61.tar.gz==&gt; Fetching https://mirror.spack.io/_source-cache/archive/56/56ab9b90f5acbc42eb7a94cf482e6c058a63e8a1effdf572b8b2a6323a06d923.tar.gz==&gt; Fetching https://mirror.spack.io/_source-cache/archive/20/208316c2564bdd5343fa522f3b230d84bd164058957059838df7df56876cb4ae==&gt; Adding package m4@1.4.19 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/3b/3be4a26d825ffdfda52a56fc43246456989a3630093cced3fbddf4771ee58a70.tar.gz==&gt; Fetching https://mirror.spack.io/_source-cache/archive/fc/fc9b61654a3ba1a8d6cd78ce087e7c96366c290bc8d2c299f09828d793b853c8==&gt; Adding package mesa@22.1.6 to mirror==&gt; Fetching https://archive.mesa3d.org/mesa-22.1.6.tar.xz==&gt; Fetching https://mirror.spack.io/_source-cache/archive/36/36096a178070e40217945e12d542dfe80016cb897284a01114d616656c577d73==&gt; Adding package meson@1.0.1 to mirror==&gt; Fetching https://github.com/mesonbuild/meson/archive/1.0.1.tar.gz==&gt; Adding package mkfontdir@1.0.7 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/bc/bccc5fb7af1b614eabe4a22766758c87bfc36d66191d08c19d2fa97674b7b5b7.tar.gz==&gt; Adding package mkfontscale@1.2.2 to mirror==&gt; Fetching https://www.x.org/archive/individual/app/mkfontscale-1.2.2.tar.gz==&gt; Adding package mpfr@4.2.0 to mirror==&gt; Fetching https://ftpmirror.gnu.org/mpfr/mpfr-4.2.0.tar.bz2==&gt; Fetching https://ftp.gnu.org/gnu/mpfr/mpfr-4.2.0.tar.bz2==&gt; Fetching https://mirror.spack.io/_source-cache/archive/3f/3f80b836948aa96f8d1cb9cc7f3f55973f19285482a96f9a4e1623d460bcccf0==&gt; Fetching https://mirror.spack.io/_source-cache/archive/52/5230aab653fa8675fc05b5bdd3890e071e8df49a92a9d58c4284024affd27739==&gt; Fetching https://mirror.spack.io/_source-cache/archive/7a/7a6dd71bcda4803d6b89612706a17b8816e1acd5dd9bf1bec29cf748f3b60008==&gt; Fetching https://mirror.spack.io/_source-cache/archive/1a/1ae14fb3a54ae8e0faed20801970255b279eee9e5ac624891ab5d29727f0bc04==&gt; Fetching https://mirror.spack.io/_source-cache/archive/11/113705d5333ef0d0ad3eb136a85404ba6bd1cc524dece5ce902c536aa2e29903==&gt; Fetching https://mirror.spack.io/_source-cache/archive/41/4152a780b3cc6e9643283e59093b43460196d0fea9302d8c93b2496f6679f4e4==&gt; Fetching https://mirror.spack.io/_source-cache/archive/1b/1b9fdb515efb09a506a01e1eb307b1464455f5ca63d6c193db3a3da371ab3220==&gt; Adding package nasm@2.15.05 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/91/9182a118244b058651c576baa9d0366ee05983c4d4ae1d9ddd3236a9f2304997.tar.gz==&gt; Fetching https://mirror.spack.io/_source-cache/archive/ac/ac9f315d204afa6b99ceefa1fe46d4eed2b8a23c7315d32d33c0f378d930e950==&gt; Adding package ncurses@6.4 to mirror==&gt; Fetching https://ftp.gnu.org/gnu/ncurses/ncurses-6.4.tar.gz==&gt; Adding package ninja@1.11.1 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/31/31747ae633213f1eda3842686f83c2aa1412e0f5691d1c14dbbcc67fe7400cea.tar.gz==&gt; Adding package openssl@1.1.1t to mirror==&gt; Fetching http://www.openssl.org/source/openssl-1.1.1t.tar.gz==&gt; Fetching https://mirror.spack.io/_source-cache/archive/3f/3fdcf2d1e47c34f3a012f23306322c5a35cad55b180c9b6fb34537b55884645c==&gt; Adding package pango@1.50.13 to mirror==&gt; Fetching http://ftp.gnome.org/pub/GNOME/sources/pango/1.50/pango-1.50.13.tar.xz==&gt; Adding package pcre@8.45 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/4d/4dae6fdcd2bb0bb6c37b5f97c33c2be954da743985369cddac3546e3218bffb8.tar.bz2==&gt; Adding package pcre2@10.42 to mirror==&gt; Fetching https://github.com/PCRE2Project/pcre2/releases/download/pcre2-10.42/pcre2-10.42.tar.bz2==&gt; Adding package perl@5.36.0 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/e2/e26085af8ac396f62add8a533c3a0ea8c8497d836f0689347ac5abd7b7a4e00a.tar.gz==&gt; Fetching https://mirror.spack.io/_source-cache/archive/9d/9da50e155df72bce55cb69f51f1dbb4b62d23740fb99f6178bb27f22ebdf8a46.tar.gz==&gt; Fetching https://mirror.spack.io/_source-cache/archive/8c/8cf4302ca8b480c60ccdcaa29ec53d9d50a71d4baf469ac8c6fca00ca31e58a2==&gt; Fetching https://mirror.spack.io/_source-cache/archive/3b/3bbd7d6f9933d80b9571533867b444c6f8f5a1ba0575bfba1fba4db9d885a71a==&gt; Fetching https://mirror.spack.io/_source-cache/archive/0e/0eac10ed90aeb0459ad8851f88081d439a4e41978e586ec743069e8b059370ac==&gt; Adding package perl-data-dumper@2.173 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/69/697608b39330988e519131be667ff47168aaaaf99f06bd2095d5b46ad05d76fa.tar.gz==&gt; Adding package perl-encode-locale@1.05 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/17/176fa02771f542a4efb1dbc2a4c928e8f4391bf4078473bd6040d8f11adb0ec1.tar.gz==&gt; Adding package perl-extutils-config@0.008 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/ae/ae5104f634650dce8a79b7ed13fb59d67a39c213a6776cfdaa3ee749e62f1a8c.tar.gz==&gt; Adding package perl-extutils-helpers@0.026 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/de/de901b6790a4557cf4ec908149e035783b125bf115eb9640feb1bc1c24c33416.tar.gz==&gt; Adding package perl-extutils-installpaths@0.012 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/84/84735e3037bab1fdffa3c2508567ad412a785c91599db3c12593a50a1dd434ed.tar.gz==&gt; Adding package perl-file-listing@6.04 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/1e/1e0050fcd6789a2179ec0db282bf1e90fb92be35d1171588bd9c47d52d959cf5.tar.gz==&gt; Adding package perl-html-parser@3.72 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/ec/ec28c7e1d9e67c45eca197077f7cdc41ead1bb4c538c7f02a3296a4bb92f608b.tar.gz==&gt; Adding package perl-html-tagset@3.20 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/ad/adb17dac9e36cd011f5243881c9739417fd102fce760f8de4e9be4c7131108e2.tar.gz==&gt; Adding package perl-http-cookies@6.10 to mirror==&gt; Fetching http://search.cpan.org/CPAN/authors/id/O/OA/OALDERS/HTTP-Cookies-6.10.tar.gz==&gt; Adding package perl-http-daemon@6.01 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/43/43fd867742701a3f9fcc7bd59838ab72c6490c0ebaf66901068ec6997514adc2.tar.gz==&gt; Adding package perl-http-date@6.02 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/e8/e8b9941da0f9f0c9c01068401a5e81341f0e3707d1c754f8e11f42a7e629e333.tar.gz==&gt; Adding package perl-http-message@6.44 to mirror==&gt; Fetching http://search.cpan.org/CPAN/authors/id/O/OA/OALDERS/HTTP-Message-6.44.tar.gz==&gt; Adding package perl-http-negotiate@6.01 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/1c/1c729c1ea63100e878405cda7d66f9adfd3ed4f1d6cacaca0ee9152df728e016.tar.gz==&gt; Adding package perl-io-html@1.004 to mirror==&gt; Fetching http://search.cpan.org/CPAN/authors/id/C/CJ/CJM/IO-HTML-1.004.tar.gz==&gt; Adding package perl-libwww-perl@6.68 to mirror==&gt; Fetching http://search.cpan.org/CPAN/authors/id/O/OA/OALDERS/libwww-perl-6.68.tar.gz==&gt; Adding package perl-lwp-mediatypes@6.02 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/18/18790b0cc5f0a51468495c3847b16738f785a2d460403595001e0b932e5db676.tar.gz==&gt; Adding package perl-module-build@0.4232 to mirror==&gt; Fetching http://search.cpan.org/CPAN/authors/id/L/LE/LEONT/Module-Build-0.4232.tar.gz==&gt; Adding package perl-module-build-tiny@0.039 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/7d/7d580ff6ace0cbe555bf36b86dc8ea232581530cbeaaea09bccb57b55797f11c.tar.gz==&gt; Adding package perl-net-http@6.22 to mirror==&gt; Fetching http://search.cpan.org/CPAN/authors/id/O/OA/OALDERS/Net-HTTP-6.22.tar.gz==&gt; Adding package perl-test-needs@0.002010 to mirror==&gt; Fetching https://search.cpan.org/CPAN/authors/id/H/HA/HAARG/Test-Needs-0.002010.tar.gz==&gt; Adding package perl-try-tiny@0.28 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/f1/f1d166be8aa19942c4504c9111dade7aacb981bc5b3a2a5c5f6019646db8c146.tar.gz==&gt; Adding package perl-uri@1.72 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/35/35f14431d4b300de4be1163b0b5332de2d7fbda4f05ff1ed198a8e9330d40a32.tar.gz==&gt; Adding package perl-www-robotrules@6.02 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/46/46b502e7a288d559429891eeb5d979461dd3ecc6a5c491ead85d165b6e03a51e.tar.gz==&gt; Adding package perl-xml-parser@2.44 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/1a/1ae9d07ee9c35326b3d9aad56eae71a6730a73a116b9fe9e8a4758b7cc033216.tar.gz==&gt; Adding package pigz@2.7 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/d2/d2045087dae5e9482158f1f1c0f21c7d3de6f7cdc7cc5848bdabda544e69aa58.tar.gz==&gt; Adding package pixman@0.42.2 to mirror==&gt; Fetching https://cairographics.org/releases/pixman-0.42.2.tar.gz==&gt; Adding package pkgconf@1.8.0 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/ef/ef9c7e61822b7cb8356e6e9e1dca58d9556f3200d78acab35e4347e9d4c2bbaf.tar.xz==&gt; Adding package py-mako@1.2.2 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/37/3724869b363ba630a272a5f89f68c070352137b8fd1757650017b7e06fda163f.tar.gz==&gt; Adding package py-markupsafe@2.1.1 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/7f/7f91197cc9e48f989d12e4e6fbc46495c446636dfc81b9ccf50bb0ec74b91d4b.tar.gz==&gt; Adding package py-pip@23.0 to mirror==&gt; Fetching https://files.pythonhosted.org/packages/py3/p/pip/pip-23.0-py3-none-any.whl==&gt; Adding package py-setuptools@67.6.0 to mirror==&gt; Fetching https://files.pythonhosted.org/packages/py3/s/setuptools/setuptools-67.6.0-py3-none-any.whl==&gt; Adding package py-wheel@0.37.1 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/4b/4bdcd7d840138086126cd09254dc6195fb4fc6f01c050a1d7236f2630db1d22a==&gt; Adding package python@3.10.10 to mirror==&gt; Fetching https://www.python.org/ftp/python/3.10.10/Python-3.10.10.tgz==&gt; Adding package randrproto@1.5.0 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/8f/8f8a716d6daa6ba05df97d513960d35a39e040600bf04b313633f11679006fab.tar.gz==&gt; Adding package re2c@2.2 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/0f/0fc45e4130a8a555d68e230d1795de0216dfe99096b61b28e67c86dfd7d86bda.tar.xz==&gt; Adding package readline@8.2 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/3f/3feb7171f16a84ee82ca18a36d7b9be109a52c04f492a053331d7d1095007c35.tar.gz==&gt; Fetching https://mirror.spack.io/_source-cache/archive/bb/bbf97f1ec40a929edab5aa81998c1e2ef435436c597754916e6a5868f273aff7==&gt; Fetching https://mirror.spack.io/_source-cache/archive/68/682a465a68633650565c43d59f0b8cdf149c13a874682d3c20cb4af6709b9144==&gt; Fetching https://mirror.spack.io/_source-cache/archive/e5/e55be055a68cb0719b0ccb5edc9a74edcc1d1f689e8a501525b3bc5ebad325dc==&gt; Fetching https://mirror.spack.io/_source-cache/archive/d8/d8e5e98933cf5756f862243c0601cb69d3667bb33f2c7b751fe4e40b2c3fd069==&gt; Fetching https://mirror.spack.io/_source-cache/archive/36/36b0febff1e560091ae7476026921f31b6d1dd4c918dcb7b741aa2dad1aec8f7==&gt; Fetching https://mirror.spack.io/_source-cache/archive/94/94ddb2210b71eb5389c7756865d60e343666dfb722c85892f8226b26bb3eeaef==&gt; Fetching https://mirror.spack.io/_source-cache/archive/b1/b1aa3d2a40eee2dea9708229740742e649c32bb8db13535ea78f8ac15377394c==&gt; Fetching https://mirror.spack.io/_source-cache/archive/9a/9ac1b3ac2ec7b1bf0709af047f2d7d2a34ccde353684e57c6b47ebca77d7a376==&gt; Fetching https://mirror.spack.io/_source-cache/archive/87/8747c92c35d5db32eae99af66f17b384abaca961653e185677f9c9a571ed2d58==&gt; Fetching https://mirror.spack.io/_source-cache/archive/9e/9e43aa93378c7e9f7001d8174b1beb948deefa6799b6f581673f465b7d9d4780==&gt; Fetching https://mirror.spack.io/_source-cache/archive/f9/f925683429f20973c552bff6702c74c58c2a38ff6e5cf305a8e847119c5a6b64==&gt; Fetching https://mirror.spack.io/_source-cache/archive/ca/ca159c83706541c6bbe39129a33d63bbd76ac594303f67e4d35678711c51b753==&gt; Fetching https://mirror.spack.io/_source-cache/archive/1a/1a79bbb6eaee750e0d6f7f3d059b30a45fc54e8e388a8e05e9c3ae598590146f==&gt; Fetching https://mirror.spack.io/_source-cache/archive/39/39e304c7a526888f9e112e733848215736fb7b9d540729b9e31f3347b7a1e0a5==&gt; Fetching https://mirror.spack.io/_source-cache/archive/ec/ec41bdd8b00fd884e847708513df41d51b1243cecb680189e31b7173d01ca52f==&gt; Fetching https://mirror.spack.io/_source-cache/archive/45/4547b906fb2570866c21887807de5dee19838a60a1afb66385b272155e4355cc==&gt; Fetching https://mirror.spack.io/_source-cache/archive/87/877788f9228d1a9907a4bcfe3d6dd0439c08d728949458b41208d9bf9060274b==&gt; Warning: Error while fetching readline@8.2 All fetchers failed for spack-stage-d0z8q77a==&gt; Adding package recordproto@1.14.2 to mirror==&gt; Fetching https://mirrors.ircam.fr/pub/x.org/individual/proto/recordproto-1.14.2.tar.gz==&gt; Adding package renderproto@0.11.1 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/a0/a0a4be3cad9381ae28279ba5582e679491fc2bec9aab8a65993108bf8dbce5fe.tar.gz==&gt; Adding package ruby@3.1.0 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/50/50a0504c6edcb4d61ce6b8cfdbddaa95707195fab0ecd7b5e92654b2a9412854.tar.gz==&gt; Fetching https://mirror.spack.io/_source-cache/archive/df/df68841998b7fd098a9517fe971e97890be0fc93bbe1b2a1ef63ebdea3111c80==&gt; Adding package rust@1.65.0 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/58/5828bb67f677eabf8c384020582b0ce7af884e1c84389484f7f8d00dd82c0038.tar.gz==&gt; Fetching https://static.rust-lang.org/dist/rust-1.65.0-x86_64-unknown-linux-gnu.tar.gz==&gt; Adding package shared-mime-info@1.9 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/5c/5c0133ec4e228e41bdf52f726d271a2d821499c2ab97afd3aa3d6cf43efcdc83.tar.xz==&gt; Adding package sqlite@3.40.1 to mirror==&gt; Fetching https://www.sqlite.org/2022/sqlite-autoconf-3400100.tar.gz==&gt; Adding package tar@1.34 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/03/03d908cf5768cfe6b7ad588c921c6ed21acabfb2b79b788d1330453507647aed.tar.gz==&gt; Adding package texinfo@7.0 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/92/9261d4ee11cdf6b61895e213ffcd6b746a61a64fe38b9741a3aaa73125b35170.tar.gz==&gt; Adding package unzip@6.0 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/03/036d96991646d0449ed0aa952e4fbe21b476ce994abc276e49d30e686708bd37.tar.gz==&gt; Adding package util-linux-uuid@2.36.2 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/f5/f5dbe79057e7d68e1a46fc04083fc558b26a49499b1b3f50e4f4893150970463.tar.gz==&gt; Adding package util-macros@1.19.3 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/0f/0f812e6e9d2786ba8f54b960ee563c0663ddbe2434bf24ff193f5feab1f31971.tar.bz2==&gt; Adding package vim@9.0.0045 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/59/594a31e96e3eda07a358db305de939ca749693b4684de9e027bfa70311b1994d.tar.gz==&gt; Adding package xcb-proto@1.14.1 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/f0/f04add9a972ac334ea11d9d7eb4fc7f8883835da3e4859c9afa971efdf57fcc3.tar.xz==&gt; Adding package xextproto@7.3.0 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/1b/1b1bcdf91221e78c6c33738667a57bd9aaa63d5953174ad8ed9929296741c9f5.tar.gz==&gt; Adding package xkbcomp@1.4.4 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/15/159fba6b62ef4a3fb16ef7fc4eb4fc26f3888652471ceb604c495783dda020bc.tar.gz==&gt; Adding package xkbdata@1.0.1 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/5b/5b43ca5219cd4022a158a8d4bfa30308ea5e16c9b5270a64589ebfe7f875f430.tar.gz==&gt; Adding package xmlto@0.0.28 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/2f/2f986b7c9a0e9ac6728147668e776d405465284e13c74d4146c9cbc51fd8aad3.tar.gz==&gt; Adding package xproto@7.0.31 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/6d/6d755eaae27b45c5cc75529a12855fed5de5969b367ed05003944cf901ed43c7.tar.gz==&gt; Adding package xrandr@1.5.0 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/dd/ddfe8e7866149c24ccce8e6aaa0623218ae19130c2859cadcaa4228d8bb4a46d.tar.gz==&gt; Adding package xtrans@1.3.5 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/b7/b7a577c1b6c75030145e53b4793db9c88f9359ac49e7d771d4385d21b3e5945d.tar.gz==&gt; Adding package xz@5.4.1 to mirror==&gt; Fetching https://prdownloads.sourceforge.net/lzmautils/files/xz-5.4.1.tar.bz2==&gt; Adding package zlib@1.2.13 to mirror==&gt; Fetching https://mirror.spack.io/_source-cache/archive/b3/b3a24de97a8fdbc835b9833169501030b8977031bcb54b3b3ac13740f846ab30.tar.gz==&gt; Adding package zstd@1.5.4 to mirror==&gt; Warning: Error while fetching zstd@1.5.4 All fetchers failed for spack-stage-zstd-1.5.4-fcoqzia2hmo7w2ydmmagjiatpskgp7jf==&gt; Summary for mirror in /local/tools/os/spack/pkgs-mirror==&gt; Archive stats: 0 already present 160 added 5 failed to fetch.==&gt; Error: Failed downloads:expat@2.5.0 intltool@0.51.0 zstd@1.5.4 readline@8.2 inputproto@2.3.2提示有失败。可以将传输错误的临时文件删掉，重新执行试试。完成mirror操作之后，将/local/tools/os/spack/pkgs-mirror与/home/centos/.spack(这个目录缓存好了spack bootstrap)目录传到centos7-9-offline机器，配置mirror信息，[centos@centos7-9-offline ~]$ spack mirror add local_filesystem file:///nfs/tools/os/spack/pkgs-mirror[centos@centos7-9-offline ~]$ cat ~/.spack/mirrors.yamlmirrors: local_filesystem: file:///nfs/tools/os/spack/pkgs-mirror这样，spack在离线环境就可以使用mirror过来的目录安装了[centos@centos7-9-offline ~]$ spack install vim %gcc@12.2.0 +gtk +gui +lua +perl +python +ruby +x +cscope验证Spack Mirrors" }, { "title": "限制用户直接访问lsf执行机", "url": "/posts/restrict-user-access-to-remote-lsf-exec-hosts/", "categories": "icenv", "tags": "lsf", "date": "2023-03-22 01:57:58 +0000", "snippet": "需求禁止用户直接访问LSF执行机，以实现LSF执行机的用户进程都来自于LSF的调度，确保使用的公平性，以及方便管理员管理。实现 https://www.ibm.com/docs/en/spectrum-lsf/10.1.0?topic=bsub-about-interactive-jobs //将队列配置为batch-only，以禁止用户提交interactive的job https:...", "content": "需求禁止用户直接访问LSF执行机，以实现LSF执行机的用户进程都来自于LSF的调度，确保使用的公平性，以及方便管理员管理。实现 https://www.ibm.com/docs/en/spectrum-lsf/10.1.0?topic=bsub-about-interactive-jobs //将队列配置为batch-only，以禁止用户提交interactive的job https://www.ibm.com/docs/en/spectrum-lsf/10.1.0?topic=cluster-restrict-user-access-remote-hosts //禁止普通用户执行lsrun, lsgrun与lsmake 每台机器的sshd配置，禁止普通用户登录。三个步骤组合起来，可以满足需求。但interactive往往是必须的，因此可以细化队列的管理，允许个别队列的interactive。" }, { "title": "Python bytes的单个元素与slice", "url": "/posts/python-bytes/", "categories": "icenv", "tags": "python", "date": "2023-03-21 13:59:32 +0000", "snippet": "wanlinwang@MacBook-Pro ~ % python3 Python 3.10.8 (main, Mar 17 2023, 21:21:21) [Clang 14.0.0 (clang-1400.0.29.202)] on darwinType \"help\", \"copyright\", \"credits\" or \"license\" for more information.&g...", "content": "wanlinwang@MacBook-Pro ~ % python3 Python 3.10.8 (main, Mar 17 2023, 21:21:21) [Clang 14.0.0 (clang-1400.0.29.202)] on darwinType \"help\", \"copyright\", \"credits\" or \"license\" for more information.&gt;&gt;&gt; cafe = bytes('café', encoding='utf_8')&gt;&gt;&gt; cafeb'caf\\xc3\\xa9'&gt;&gt;&gt; cafe[0]99&gt;&gt;&gt; cafe[:1]b'c'&gt;&gt;&gt; type(cafe[0])&lt;class 'int'&gt;&gt;&gt;&gt; type(cafe[:1])&lt;class 'bytes'&gt;&gt;&gt;&gt; Python bytes的单个元素与slice，不是同一种类型。bytes的单个元素，是一个范围是0到255的整数；而bytes的slice同样是bytes，即使slice的长度是1。" }, { "title": "displaying beautiful tables with Bootstrap Tables", "url": "/posts/tables/", "categories": "sample-posts", "tags": "formatting, tables", "date": "2023-03-20 18:37:00 +0000", "snippet": "Using markdown to display tables is easy. Just use the following syntax:| Left aligned | Center aligned | Right aligned || :----------- | :------------: | ------------: || Left 1 | center 1 ...", "content": "Using markdown to display tables is easy. Just use the following syntax:| Left aligned | Center aligned | Right aligned || :----------- | :------------: | ------------: || Left 1 | center 1 | right 1 || Left 2 | center 2 | right 2 || Left 3 | center 3 | right 3 |That will generate: Left aligned Center aligned Right aligned Left 1 center 1 right 1 Left 2 center 2 right 2 Left 3 center 3 right 3 It is also possible to use HTML to display tables. For example, the following HTML code will display a table with Bootstrap Table, loaded from a JSON file:&lt;table id=\"table\" data-toggle=\"table\" data-url=\"{{ '/assets/json/table_data.json' | relative_url }}\"&gt; &lt;thead&gt; &lt;tr&gt; &lt;th data-field=\"id\"&gt;ID&lt;/th&gt; &lt;th data-field=\"name\"&gt;Item Name&lt;/th&gt; &lt;th data-field=\"price\"&gt;Item Price&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt;&lt;/table&gt; ID Item Name Item Price By using Bootstrap Table it is possible to create pretty complex tables, with pagination, search, and more. For example, the following HTML code will display a table, loaded from a JSON file, with pagination, search, checkboxes, and header/content alignment. For more information, check the documentation.&lt;table data-click-to-select=\"true\" data-height=\"460\" data-pagination=\"true\" data-search=\"true\" data-toggle=\"table\" data-url=\"{{ '/assets/json/table_data.json' | relative_url }}\"&gt; &lt;thead&gt; &lt;tr&gt; &lt;th data-checkbox=\"true\"&gt;&lt;/th&gt; &lt;th data-field=\"id\" data-halign=\"left\" data-align=\"center\" data-sortable=\"true\"&gt;ID&lt;/th&gt; &lt;th data-field=\"name\" data-halign=\"center\" data-align=\"right\" data-sortable=\"true\"&gt;Item Name&lt;/th&gt; &lt;th data-field=\"price\" data-halign=\"right\" data-align=\"left\" data-sortable=\"true\"&gt;Item Price&lt;/th&gt; &lt;/tr&gt; &lt;/thead&gt;&lt;/table&gt; ID Item Name Item Price " }, { "title": "a post with table of contents", "url": "/posts/table-of-contents/", "categories": "sample-posts", "tags": "formatting, toc", "date": "2023-03-20 15:59:00 +0000", "snippet": "This post shows how to add a table of contents in the beginning of the post.Adding a Table of ContentsTo add a table of contents to a post, simply addtoc: beginning: trueto the front matter of the...", "content": "This post shows how to add a table of contents in the beginning of the post.Adding a Table of ContentsTo add a table of contents to a post, simply addtoc: beginning: trueto the front matter of the post. The table of contents will be automatically generated from the headings in the post.Example of Sub-Heading 1Jean shorts raw denim Vice normcore, art party High Life PBR skateboard stumptown vinyl kitsch. Four loko meh 8-bit, tousled banh mi tilde forage Schlitz dreamcatcher twee 3 wolf moon. Chambray asymmetrical paleo salvia, sartorial umami four loko master cleanse drinking vinegar brunch. Pinterest DIY authentic Schlitz, hoodie Intelligentsia butcher trust fund brunch shabby chic Kickstarter forage flexitarian. Direct trade cold-pressed meggings stumptown plaid, pop-up taxidermy. Hoodie XOXO fingerstache scenester Echo Park. Plaid ugh Wes Anderson, freegan pug selvage fanny pack leggings pickled food truck DIY irony Banksy.Example of another Sub-Heading 1Jean shorts raw denim Vice normcore, art party High Life PBR skateboard stumptown vinyl kitsch. Four loko meh 8-bit, tousled banh mi tilde forage Schlitz dreamcatcher twee 3 wolf moon. Chambray asymmetrical paleo salvia, sartorial umami four loko master cleanse drinking vinegar brunch. Pinterest DIY authentic Schlitz, hoodie Intelligentsia butcher trust fund brunch shabby chic Kickstarter forage flexitarian. Direct trade cold-pressed meggings stumptown plaid, pop-up taxidermy. Hoodie XOXO fingerstache scenester Echo Park. Plaid ugh Wes Anderson, freegan pug selvage fanny pack leggings pickled food truck DIY irony Banksy.Table of Contents OptionsIf you want to learn more about how to customize the table of contents, you can check the jekyll-toc repository.Example of Sub-Heading 2Jean shorts raw denim Vice normcore, art party High Life PBR skateboard stumptown vinyl kitsch. Four loko meh 8-bit, tousled banh mi tilde forage Schlitz dreamcatcher twee 3 wolf moon. Chambray asymmetrical paleo salvia, sartorial umami four loko master cleanse drinking vinegar brunch. Pinterest DIY authentic Schlitz, hoodie Intelligentsia butcher trust fund brunch shabby chic Kickstarter forage flexitarian. Direct trade cold-pressed meggings stumptown plaid, pop-up taxidermy. Hoodie XOXO fingerstache scenester Echo Park. Plaid ugh Wes Anderson, freegan pug selvage fanny pack leggings pickled food truck DIY irony Banksy.Example of another Sub-Heading 2Jean shorts raw denim Vice normcore, art party High Life PBR skateboard stumptown vinyl kitsch. Four loko meh 8-bit, tousled banh mi tilde forage Schlitz dreamcatcher twee 3 wolf moon. Chambray asymmetrical paleo salvia, sartorial umami four loko master cleanse drinking vinegar brunch. Pinterest DIY authentic Schlitz, hoodie Intelligentsia butcher trust fund brunch shabby chic Kickstarter forage flexitarian. Direct trade cold-pressed meggings stumptown plaid, pop-up taxidermy. Hoodie XOXO fingerstache scenester Echo Park. Plaid ugh Wes Anderson, freegan pug selvage fanny pack leggings pickled food truck DIY irony Banksy." }, { "title": "lsf运行问题", "url": "/posts/lsf-problems/", "categories": "icenv", "tags": "lsf", "date": "2023-03-20 12:08:15 +0000", "snippet": "问题1：sinit: ls_getmastername() failed. Server host LIM configuration is not ready yet.res/get_hostInfo: ls_gethostinfo() failed. Slave LIM configuration is not ready yet.master到执行机的udp端口不通导致问题（在执行机的...", "content": "问题1：sinit: ls_getmastername() failed. Server host LIM configuration is not ready yet.res/get_hostInfo: ls_gethostinfo() failed. Slave LIM configuration is not ready yet.master到执行机的udp端口不通导致问题（在执行机的input方向，开了来自于master的tcp连接，但没开udp连接）。从执行机到master通信失败导致的问题（在执行机的output方向，禁止掉了去往master的连接）。参考资料： https://www.ibm.com/support/pages/configure-firewall-ports-lsf-management-node-platform-rtm-monitoring ，其中LSF_LIM_PORT要允许访问UDP协议。" }, { "title": "LSF如何将job分散到集群运行", "url": "/posts/lsf-job-dispatching/", "categories": "icenv", "tags": "lsf", "date": "2023-03-19 14:06:56 +0000", "snippet": "需求研发想将job尽可能地均匀分散在集群中的执行机上，将负载均匀地分散到集群中，而不是默认的往一台调度，这台满了再往下一台调度。如图，是默认的调度情况，连续提交的job都调度到了同一台机器，解决方案方案一：基于执行机接收时间间隔经查看手册1， JOB_ACCEPT_INTERVAL=integer[ S   s   M  ...", "content": "需求研发想将job尽可能地均匀分散在集群中的执行机上，将负载均匀地分散到集群中，而不是默认的往一台调度，这台满了再往下一台调度。如图，是默认的调度情况，连续提交的job都调度到了同一台机器，解决方案方案一：基于执行机接收时间间隔经查看手册1， JOB_ACCEPT_INTERVAL=integer[ S   s   M   m ] where S | s indicates that the value is in seconds and M | m indicates that the value is in minutes.If you set a unit (seconds or minutes), the value that you specify determines how long to wait after dispatching a job to a host before dispatching a second job to the same host. If you do not set a unit, the value you specify is multiplied by the value of lsb.params MBD_SLEEP_TIME (60 seconds by default). The result of the calculation is the number of seconds to wait after dispatching a job to a host, before dispatching a second job to the same host. If 0 (zero), a host may accept more than one job. By default, there is no limit to the total number of jobs that can run on a host, so if this parameter is set to 0, a very large number of jobs might be dispatched to a host all at once. This can overload your system to the point that it will be unable to create any more processes. It is not recommended to set this parameter to 0. JOB_ACCEPT_INTERVAL set at the queue level (lsb.queues) overrides JOB_ACCEPT_INTERVAL set at the cluster level (lsb.params).可以通过调整同一台执行机接收job的时间间隔，来达到将job分散到集群中的执行机的需求。设置[lsfadmin@lsf-server-01 lsf]$ grep JOB_ACCEPT_INTERVAL /nfs/home/lsfadmin/lsf/lsf/conf/lsbatch/myCluster01/configdir/lsb.params#JOB_ACCEPT_INTERVAL = 0 # Interval for any host to accept a job JOB_ACCEPT_INTERVAL = 1 # 语法：JOB_ACCEPT_INTERVAL=integer[ S | s | M | m ]。 如果未指定单位，则该时间等于该数值乘以MBD_SLEEP_TIME，而MBD_SLEEP_TIME缺省值是60秒，在安装时会被设定为10秒。[lsfadmin@lsf-server-01 lsf]$ badmin reconfigChecking configuration files ...No errors found.Reconfiguration initiated[lsfadmin@lsf-server-01 ~]$ bparams -l| grep MBD_SLEEP_TIME MBD_SLEEP_TIME = 10 (seconds) JOB_ACCEPT_INTERVAL = 1 (* MBD_SLEEP_TIME)在10秒内，连续提交三个job，可以看到它们分散在了三台执行机器。方案二：基于主机指标经查看手册2，RES_REQ的order string介绍如下， The order string allows the selected hosts to be sorted according to the values of resources. The values of r15s, r1m, and r15m used for sorting are the normalized load indices that are returned by lsload -N. The order string is used for host sorting and selection. The ordering begins with the rightmost index in the order string and proceeds from right to left. The hosts are sorted into order based on each load index, and if more hosts are available than were requested, the LIM drops the least desirable hosts according to that index. The remaining hosts are then sorted by the next index. After the hosts are sorted by the leftmost index in the order string, the final phase of sorting orders the hosts according to their status, with hosts that are currently not available for load sharing (that is, not in the ok state) listed at the end. Because the hosts are sorted again for each load index, only the host status and the leftmost index in the order string actually affect the order in which hosts are listed. The other indices are only used to drop undesirable hosts from the list. When sorting is done on each index, the direction in which the hosts are sorted (increasing versus decreasing values) is determined by the default order returned by lsinfo for that index. This direction is chosen such that after sorting, by default, the hosts are ordered from best to worst on that index. When used with a cu string, the preferred compute unit order takes precedence. Within each compute unit hosts are ordered according to the order string requirements.如果order string里有多个指标，则从右到左依次处理，上一个指标排序后的输出成为下一个指标排序的输入，直到最左的指标排序完成，选出合适的执行机进行调度。LSF的RES_REQ order string默认是r15s:pg，如下图所示，在pg指标排序完之后，再r15s排序，最优的胜出。回到本文的需求，想将job调度到slot可用数量多的，可以这样设置[lsfadmin@lsf-server-01 lsf]$ grep DEFAULT_RESREQ_ORDER ./conf/lsbatch/myCluster01/configdir/lsb.paramsDEFAULT_RESREQ_ORDER = slots[lsfadmin@lsf-server-01 lsf]$ badmin reconfigChecking configuration files ...No errors found.Reconfiguration initiated连续提交三个job上去，看下效果， https://www.ibm.com/docs/en/spectrum-lsf/10.1.0?topic=lsbparams-job-accept-interval &#8617;&#xfe0e; https://www.ibm.com/docs/en/spectrum-lsf/10.1.0?topic=strings-order-string &#8617;&#xfe0e; " }, { "title": "cursor IDE使用", "url": "/posts/cursor-ide/", "categories": "icenv", "tags": "ide", "date": "2023-03-17 13:47:45 +0000", "snippet": "下载略。安装略。", "content": "下载略。安装略。" }, { "title": "sequence图设置消息的id", "url": "/posts/how-to-apply-numbering-for-message-in-sequence-diagram/", "categories": "icenv", "tags": "uml", "date": "2023-03-17 06:55:37 +0000", "snippet": "Diagram-based NumberingSingle Level在UML时序图的背景处，右键选择Sequence Number -&gt; Single Level。只要在同一个图中，编号就是连续的。Nested Level在UML时序图的背景处，右键选择Sequence Number -&gt; Nested Level。效果如下，Frame-based NumberingSingl...", "content": "Diagram-based NumberingSingle Level在UML时序图的背景处，右键选择Sequence Number -&gt; Single Level。只要在同一个图中，编号就是连续的。Nested Level在UML时序图的背景处，右键选择Sequence Number -&gt; Nested Level。效果如下，Frame-based NumberingSingle Level在UML时序图的背景处，右键选择Sequence Number -&gt; Frame-based Single Level。效果如下，Nested Level在UML时序图的背景处，右键选择Sequence Number -&gt; Frame-based Nested Level。效果如下，参考文献How to Apply Numbering for Messages in Sequence Diagram? (visual-paradigm.com)" }, { "title": "Welcome to the UML", "url": "/posts/welcome-to-the-uml/", "categories": "icenv", "tags": "uml", "date": "2023-03-17 01:05:26 +0000", "snippet": "UML历史", "content": "UML历史" }, { "title": "Linux的网卡bonding模式", "url": "/posts/Bonding-Modes-in-Linux/", "categories": "icenv", "tags": "network", "date": "2023-03-15 13:39:18 +0000", "snippet": "不同的Bonding Mode区别网卡Bonding是一项在操作系统层面上实现的网络冗余技术。设置网卡Bonding后，内核会将多条物理链路组成一条逻辑虚拟链路，在网络层上实现高可用。mode 0(balance-rr)Round-robin policy。从组内的第一个Slave接口开始，以轮询的方式将数据按顺序依次发放。该模式提供load balancing以及fault toleran...", "content": "不同的Bonding Mode区别网卡Bonding是一项在操作系统层面上实现的网络冗余技术。设置网卡Bonding后，内核会将多条物理链路组成一条逻辑虚拟链路，在网络层上实现高可用。mode 0(balance-rr)Round-robin policy。从组内的第一个Slave接口开始，以轮询的方式将数据按顺序依次发放。该模式提供load balancing以及fault tolerance。mode 1(active-backup)Active-backup policy。只有一个slave是active的。当且仅当active slave失效了，另一个slave就会变成active。bond的MAC地址只在一个端口上对外可见，避免了交换机混淆。该模式提供fault tolerance。mode 2(balance-xor)基于选择的transmit hash policy传输。policy可以通过xmit_hash_policy更改。该模式提供load balancing以及fault tolerance。mode 3(broadcast)在所有slave接口上都传输。该模式提供fault tolerance。mode 4(802.3ad)IEEE 802.3ad Dynamic link aggregation policy。创建聚合组，共享相同的速率与工作模式。根据802.3ad规范，充分利用active aggregator里的所有slave。对于outgoing流量的slave接口选举，是通过transmit hash policy来完成的。policy可以通过xmit_hash_policy更改。xmit_hash_policy的值1 0 or layer2 默认配置。它使用两个MAC地址做异或，再取模，获得hash。 (source_MAC_address XOR destination_MAC) MODULO slave_count 1 or layer3+4 使用第3层与第4层地址分别做异或运算，再取模，获得hash。 ((source_port XOR dest_port) XOR ((source_IP XOR dest_IP) AND 0xffff) MODULO slave_count 2 or layer2+3 使用第2层与第3层地址分别做异或运算，再取模，获得hash。 (((source_IP XOR dest_IP) AND 0xffff) XOR ( source_MAC XOR destination_MAC )) MODULO slave_count 该模式对硬件的要求 ethtool支持基础驱动，取回每个slave的速率与单双工工作模式。 交换机虚支持IEEE 802.3ad Dynamic link aggregation。列子：mode 5(balance-tlb)发送负载均衡。不需要交换机的任何特殊支持。outgoing的流量会分布到各个slave，incoming的流量会被当前的slave接收。如果当前slave失效了，其他的slave会接管它的MAC地址。mode 6(balance-alb)它包括IPv4的发送负载均衡以及接收负载均衡。不需要交换机的任何特殊支持。接收负载均衡，是通过ARP协商实现。bonding驱动拦截本机发出的ARP reply，重写source MAC地址为bond中的其中一个slave的MAC地址。如此一来，不同的对端与本机不同的MAC地址进行通信，达到接收负载均衡的效果。更多信息请访问Linux内核官网2。不同的Bonding Mode对交换机的配置要求 Bonding Mode Configuration on the Switch 0 - balance-rr Requires static Etherchannel enabled(not LACP-negotiated) 1 - active-backup Requires autonomous ports 2 - balance-xor Requires static Etherchannel enabled(not LACP-negotiated) 3 - broadcast Requires static Etherchannel enabled(not LACP-negotiated) 4 - 802.3ad Requires LACP-negotiated Etherchannel enabled 5 - balance-tlb Requires autonomous ports 6 - balance-alb Requires autonomous ports xmit_hash_policy常用的三个值，引用自 https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/7/html/networking_guide/sec-using_channel_bonding?ssp=1&amp;darkschemeovr=0&amp;setlang=en-US&amp;safesearch=moderate &#8617;&#xfe0e; Linux内核官网 https://www.kernel.org/doc/Documentation/networking/bonding.txt &#8617;&#xfe0e; " }, { "title": "使用spack安装gcc 4.6.4失败", "url": "/posts/gcc-4.6.4-failed-installed-with-spack/", "categories": "icenv", "tags": "gcc", "date": "2023-03-15 09:55:09 +0000", "snippet": "问题因定位问题，供应商建议xrun尝试一下gcc 4.6版本。我用spack info gcc查到gcc 4.6.4。安装时报错，上述报错与texinfo有关，查看了 https://github.com/esden/summon-arm-toolchain/issues/60https://github.com/esden/summon-arm-toolchain/issues/60#is...", "content": "问题因定位问题，供应商建议xrun尝试一下gcc 4.6版本。我用spack info gcc查到gcc 4.6.4。安装时报错，上述报错与texinfo有关，查看了 https://github.com/esden/summon-arm-toolchain/issues/60https://github.com/esden/summon-arm-toolchain/issues/60#issuecomment-55583716与texinfo的bug有关，将texinfo包降级即可解决问题。解决spack info texinfo查看到有5.0版本，于是使用它spack install gcc@4.6.4 ^texinfo@5.0问题解决。" }, { "title": "使用patchelf修改rpath", "url": "/posts/patchelf-modify-rpath/", "categories": "linux", "tags": "elf", "date": "2023-03-15 03:30:48 +0000", "snippet": "自动解决共享库链接问题当从软件包获取一个程序时，经常需要手动设置 LD_LIBRARY_PATH 环境变量，以确保程序能够正确加载共享库并正常运行。为了避免每次都进行繁琐的配置，可以通过为程序设置 RPATH 来实现自动查找共享库，从而简化操作。问题背景例如，当你从 SourceForge 下载并解压 srecord RPM 包后，你会发现其目录结构如下：[wanlinwang@comput...", "content": "自动解决共享库链接问题当从软件包获取一个程序时，经常需要手动设置 LD_LIBRARY_PATH 环境变量，以确保程序能够正确加载共享库并正常运行。为了避免每次都进行繁琐的配置，可以通过为程序设置 RPATH 来实现自动查找共享库，从而简化操作。问题背景例如，当你从 SourceForge 下载并解压 srecord RPM 包后，你会发现其目录结构如下：[wanlinwang@computing-server-01 usr]$ ls *bin:srec_cat srec_cmp srec_infoinclude:srecordlib:ld-linux-x86-64.so.2 libgcc_s.so.1 libgcrypt.so.20.3.4 libgpg-error.so.0.32.1 libm.so.6 libstdc++.so.6.0.30libc.so.6 libgcrypt.so.20 libgpg-error.so.0 liblib_srecord.a libstdc++.so.6share:doc man直接运行 srec_cat 等命令时，可能会提示共享库未找到。解决方案为了让程序能够自动找到其依赖的共享库，而无需用户每次手动设置环境变量，可以通过设置 ELF 文件的 RPATH，使得动态链接器在指定目录（如 lib 目录）中查找共享库。1. 设置 RPATH使用 patchelf 工具可以轻松修改 ELF 文件的 RPATH。RPATH 告诉动态链接器去哪里查找共享库，$ORIGIN 代表程序所在目录，因此设置 RPATH 为 $ORIGIN/../lib，表示程序将从其上级目录的 lib 文件夹中查找共享库。[wanlinwang@computing-server-01 bin]$ patchelf --set-rpath '$ORIGIN/../lib' --force-rpath *2. 验证 RPATH 设置修改 RPATH 后，可以通过 readelf 查看每个二进制文件的 RPATH 设置，确保其正确：[wanlinwang@computing-server-01 bin]$ readelf -d * | grep -i rpath 0x000000000000000f (RPATH) Library rpath: [$ORIGIN/../lib] 0x000000000000000f (RPATH) Library rpath: [$ORIGIN/../lib] 0x000000000000000f (RPATH) Library rpath: [$ORIGIN/../lib]3. 验证共享库加载情况通过 ldd 命令检查共享库是否正确加载，确保程序能够从预期目录加载共享库：[wanlinwang@computing-server-01 bin]$ ldd *srec_cat:\tlinux-vdso.so.1 =&gt; (0x00007fff02d8d000)\tlibgcrypt.so.20 =&gt; /nfs/home/wanlinwang/usr/bin/./../lib/libgcrypt.so.20 (0x00007f9b740a0000)\tlibstdc++.so.6 =&gt; /nfs/home/wanlinwang/usr/bin/./../lib/libstdc++.so.6 (0x00007f9b73e76000)\tlibgcc_s.so.1 =&gt; /nfs/home/wanlinwang/usr/bin/./../lib/libgcc_s.so.1 (0x00007f9b742d3000)\tlibc.so.6 =&gt; /nfs/home/wanlinwang/usr/bin/./../lib/libc.so.6 (0x00007f9b73c4e000)\tlibgpg-error.so.0 =&gt; /nfs/home/wanlinwang/usr/bin/./../lib/libgpg-error.so.0 (0x00007f9b742ac000)\tlibm.so.6 =&gt; /nfs/home/wanlinwang/usr/bin/./../lib/libm.so.6 (0x00007f9b73b67000)\t/lib64/ld-linux-x86-64.so.2 (0x00007f9b741de000)srec_cmp:\tlinux-vdso.so.1 =&gt; (0x00007fffa639e000)\tlibgcrypt.so.20 =&gt; /nfs/home/wanlinwang/usr/bin/./../lib/libgcrypt.so.20 (0x00007f5fd42ca000)\tlibstdc++.so.6 =&gt; /nfs/home/wanlinwang/usr/bin/./../lib/libstdc++.so.6 (0x00007f5fd4067000)\tlibgcc_s.so.1 =&gt; /nfs/home/wanlinwang/usr/bin/./../lib/libgcc_s.so.1 (0x00007f5fd4047000)\tlibc.so.6 =&gt; /nfs/home/wanlinwang/usr/bin/./../lib/libc.so.6 (0x00007f5fd3e1f000)\tlibgpg-error.so.0 =&gt; /nfs/home/wanlinwang/usr/bin/./../lib/libgpg-error.so.0 (0x00007f5fd3df9000)\tlibm.so.6 =&gt; /nfs/home/wanlinwang/usr/bin/./../lib/libm.so.6 (0x00007f5fd3d12000)\t/lib64/ld-linux-x86-64.so.2 (0x00007f5fd4291000)srec_info:\tlinux-vdso.so.1 =&gt; (0x00007ffe78da2000)\tlibgcrypt.so.20 =&gt; /nfs/home/wanlinwang/usr/bin/./../lib/libgcrypt.so.20 (0x00007f97be3fc000)\tlibstdc++.so.6 =&gt; /nfs/home/wanlinwang/usr/bin/./../lib/libstdc++.so.6 (0x00007f97be19c000)\tlibgcc_s.so.1 =&gt; /nfs/home/wanlinwang/usr/bin/./../lib/libgcc_s.so.1 (0x00007f97be17c000)\tlibc.so.6 =&gt; /nfs/home/wanlinwang/usr/bin/./../lib/libc.so.6 (0x00007f97bdf54000)\tlibgpg-error.so.0 =&gt; /nfs/home/wanlinwang/usr/bin/./../lib/libgpg-error.so.0 (0x00007f97bdf2e000)\tlibm.so.6 =&gt; /nfs/home/wanlinwang/usr/bin/./../lib/libm.so.6 (0x00007f97bde47000)\t/lib64/ld-linux-x86-64.so.2 (0x00007f97be3c6000)此时，所有的共享库都已成功加载，且程序会自动从解压目录下的 lib 文件夹中查找所需的共享库。共享库查找顺序当动态链接器查找共享库时，会按照以下顺序进行： RPATH：如果可执行文件的 RPATH 存在且不为空，链接器将首先检查这些路径。 LD_LIBRARY_PATH：如果设置了环境变量 LD_LIBRARY_PATH，链接器将依次检查其中列出的目录。 RUNPATH：如果可执行文件包含 RUNPATH，链接器将使用这些路径。 缓存：检查 /etc/ld.so.cache 是否包含所需的库。 系统默认路径：如果以上都没有找到，链接器将检查 /lib 和 /usr/lib 目录。总结通过为程序设置 RPATH，可以避免手动设置 LD_LIBRARY_PATH，并确保共享库能够自动找到。这样做的好处是用户无需额外配置，软件运行时自动加载必要的库，提高了用户体验和软件的可移植性。参考资料共享库查找顺序，来自The Linux Programming When resolving library dependencies, the dynamic linker first inspects each dependency string to see if it contains a slash (/), which can occur if we specified an explicit library pathname when linking the executable. If a slash is found, then the dependency string is interpreted as a pathname (either absolute or relative), and the library is loaded using that pathname. Otherwise, the dynamic linker searches for the shared library using the following rules: If the executable has any directories listed in its DT_RPATH run-time library path list (rpath) and the executable does not contain a DT_RUNPATH list, then these directories are searched (in the order that they were supplied when linking the program). If the LD_LIBRARY_PATH environment variable is defined, then each of the colon-separated directories listed in its value is searched in turn. If the executable is a set-user-ID or set-group-ID program, then LD_LIBRARY_PATH is ignored. This is a security measure to prevent users from tricking the dynamic linker into loading a private version of a library with the same name as a library required by the executable. If the executable has any directories listed in its DT_RUNPATH run-time library path list, then these directories are searched (in the order that they were supplied when linking the program). The file /etc/ld.so.cache is checked to see if it contains an entry for the library. The directories /lib and /usr/lib are searched (in that order). " }, { "title": "GPT4来了", "url": "/posts/gpt4-arrived/", "categories": "it", "tags": "gpt, ai", "date": "2023-03-15 01:39:12 +0000", "snippet": "借助DeepL Translator 翻译的GPT-4博文：GPT-4我们已经创建了GPT-4，这是OpenAI在扩大深度学习方面的最新里程碑。GPT-4是一个大型的多模态模型（接受图像和文本输入，发出文本输出），虽然在许多现实世界的场景中能力不如人类，但在各种专业和学术基准上表现出人类水平的表现。例如，它通过了模拟的律师考试，分数在应试者的前10%左右；相比之下，GPT-3.5的分数则在后...", "content": "借助DeepL Translator 翻译的GPT-4博文：GPT-4我们已经创建了GPT-4，这是OpenAI在扩大深度学习方面的最新里程碑。GPT-4是一个大型的多模态模型（接受图像和文本输入，发出文本输出），虽然在许多现实世界的场景中能力不如人类，但在各种专业和学术基准上表现出人类水平的表现。例如，它通过了模拟的律师考试，分数在应试者的前10%左右；相比之下，GPT-3.5的分数则在后10%左右。我们花了6个月的时间，利用我们的对抗性测试项目以及ChatGPT的经验，反复调整GPT-4，从而在事实性、可引导性和拒绝超出护栏方面取得了我们有史以来最好的结果（尽管远非完美）。在过去的两年里，我们重建了整个深度学习堆栈，并与Azure一起，为我们的工作负荷从头开始共同设计了一台超级计算机。一年前，我们训练了GPT-3.5，作为该系统的第一次 “试运行”。我们发现并修复了一些错误，并改进了我们的理论基础。因此，我们的GPT-4训练运行（至少对我们来说是如此！）空前稳定，成为我们第一个训练性能能够提前准确预测的大型模型。随着我们继续专注于可靠的扩展，我们的目标是磨练我们的方法，以帮助我们越来越提前地预测和准备未来的能力–我们认为这对安全至关重要。我们正在通过ChatGPT和API发布GPT-4的文本输入功能（有一个等待名单）。为了准备更广泛地提供图像输入功能，我们正在与一个合作伙伴紧密合作，以开始。我们也正在开源OpenAI Evals，这是我们自动评估人工智能模型性能的框架，允许任何人报告我们模型中的缺点，以帮助指导进一步的改进。Capabilities 能力在闲聊中，GPT-3.5和GPT-4之间的区别可能是微妙的。当任务的复杂性达到足够的阈值时，差异就会显现出来–GPT-4比GPT-3.5更可靠，更有创造性，能够处理更细微的指令。为了了解这两种模型之间的差异，我们在各种基准上进行了测试，包括模拟最初为人类设计的考试。我们通过使用最新的公开测试（就奥数和AP自由回答问题而言）或购买2022-2023年版的练习考试来进行。我们没有为这些考试做专门的培训。考试中的少数问题是模型在训练中看到的，但我们认为结果是有代表性的–详情请见我们的技术报告。我们还在为机器学习模型设计的传统基准上评估了GPT-4。GPT-4的性能大大超过了现有的大型语言模型，与大多数最先进的（SOTA）模型并驾齐驱，这些模型可能包括针对基准的制作或额外的训练协议。许多现有的ML基准是用英语写的。为了初步了解其他语言的能力，我们使用Azure Translate（见附录）将MMLU基准–一套涵盖57个主题的14000个多选题–翻译成了各种语言。在测试的26种语言中的24种语言中，GPT-4的表现优于GPT-3.5和其他LLM（Chinchilla，PaLM）的英语表现，包括低资源语言，如拉脱维亚语、威尔士语和斯瓦希里语。我们也一直在内部使用GPT-4，对支持、销售、内容审核和编程等功能有很大影响。我们也正在使用它来协助人类评估人工智能的产出，开始了我们调整战略的第二阶段。GPT-4可以接受文本和图像的提示，这与纯文本设置平行，让用户指定任何视觉或语言任务。具体来说，它可以生成文本输出（自然语言、代码等），给定的输入包括穿插的文本和图像。在一系列的领域中，包括带有文字和照片的文件、图表或屏幕截图，GPT-4表现出与纯文本输入类似的能力。此外，它还可以使用为纯文本语言模型开发的测试时间技术，包括少数几个镜头和思维链提示。图像输入仍然是一个研究预览，没有公开提供。我们通过对一套狭窄的标准学术视觉基准进行评估来预览GPT-4的性能。然而，这些数字并不完全代表它的能力范围，因为我们正在不断发现该模型能够处理的新的和令人兴奋的任务。我们计划很快发布进一步的分析和评估数字，以及对测试时间技术效果的彻底调查。操纵性我们一直在努力实现我们关于定义人工智能行为的帖子中概述的计划的各个方面，包括可引导性。与经典的ChatGPT个性的固定言语、语气和风格不同，开发者（以及很快ChatGPT用户）现在可以通过在 “系统 “消息中描述这些方向来规定他们的AI的风格和任务。系统消息允许API用户在一定范围内大幅定制他们的用户体验。我们将继续在这里进行改进（特别是知道系统消息是 “越狱 “当前模式的最简单方法，也就是说，对界限的遵守并不完美），但我们鼓励你尝试并让我们知道你的想法。限制条件尽管有这样的能力，GPT-4也有与早期GPT模型类似的局限性。最重要的是，它仍然不是完全可靠的（它对事实产生 “幻觉”，并出现推理错误）。在使用语言模型的输出时，特别是在高风险的情况下，应该非常小心，准确的协议（如人类审查，用额外的背景接地，或完全避免高风险的使用）与特定的使用案例的需求相匹配。虽然仍然是一个真实的问题，但GPT-4相对于以前的模型（这些模型本身在每次迭代中都有改进），大大减少了幻觉。在我们的内部对抗性事实性评估中，GPT-4的得分比我们最新的GPT-3.5高40%。我们在TruthfulQA等外部基准上取得了进展，该基准测试了模型从对抗性选择的不正确陈述中分离事实的能力。这些问题与在统计学上具有吸引力的事实错误的答案相搭配。GPT-4基础模型在这一任务上只比GPT-3.5略胜一筹；然而，在经过RLHF后期训练后（应用我们在GPT-3.5上使用的相同过程），却有很大差距。检查下面的一些例子，GPT-4抵制选择普通的说法（你不能教一只老狗新的技巧），然而它仍然可能错过微妙的细节（猫王不是一个演员的儿子）。该模型在其输出中可能会有各种偏见–我们在这些方面已经取得了进展，但仍有更多工作要做。根据我们最近的博文，我们的目标是使我们建立的人工智能系统具有合理的默认行为，以反映广泛的用户价值观，允许这些系统在广泛的范围内被定制，并获得公众对这些范围的意见。GPT-4通常缺乏对其绝大部分数据截止后（2021年9月）发生的事件的了解，也不会从其经验中学习。它有时会犯一些简单的推理错误，这似乎与它在这么多领域的能力不相符，或者过于轻信用户的明显虚假陈述。有时它也会像人类一样在困难的问题上失败，比如在它产生的代码中引入安全漏洞。GPT-4在预测时也会自信地出错，在有可能出错的时候不注意反复检查工作。有趣的是，基础的预训练模型是高度校准的（它对一个答案的预测信心一般与正确的概率相匹配）。然而，通过我们目前的后训练过程，校准程度降低了。风险和缓解措施我们一直在对GPT-4进行迭代，以使其从培训开始就更加安全和一致，所做的努力包括预培训数据的选择和过滤、评估和专家参与、模型安全改进以及监测和执行。GPT-4与以前的模型有类似的风险，如产生有害的建议、错误的代码或不准确的信息。然而，GPT-4的额外能力导致了新的风险面。为了了解这些风险的程度，我们聘请了50多位来自人工智能对接风险、网络安全、生物风险、信任和安全以及国际安全等领域的专家对该模型进行对抗性测试。他们的发现特别使我们能够测试模型在高风险领域的行为，这些领域需要专业知识来评估。来自这些专家的反馈和数据为我们缓解和改进模型提供了依据；例如，我们已经收集了额外的数据，以提高GPT-4拒绝关于如何合成危险化学品请求的能力。GPT-4在RLHF训练中加入了一个额外的安全奖励信号，通过训练模型来拒绝对此类内容的请求，从而减少有害的输出（根据我们的使用指南定义）。奖励是由GPT-4的零点分类器提供的，它判断安全边界和安全相关提示的完成方式。为了防止模型拒绝有效的请求，我们从不同的来源（例如，标记的生产数据、人类红队、模型生成的提示）收集不同的数据集，并在允许和不允许的类别上应用安全奖励信号（有一个正值或负值）。与GPT-3.5相比，我们的缓解措施大大改善了GPT-4的许多安全性能。与GPT-3.5相比，我们将该模型对不允许内容的请求的响应倾向降低了82%，而GPT-4对敏感请求（如医疗建议和自我伤害）的响应符合我们的政策的频率提高了29%。总的来说，我们的模型级干预措施增加了诱发不良行为的难度，但这样做仍然是可能的。此外，仍然存在 “越狱 “的情况，以产生违反我们使用指南的内容。随着人工智能系统的 “每个令牌的风险 “的增加，在这些干预措施中实现极高的可靠性将变得至关重要；目前，重要的是用部署时间的安全技术来补充这些限制，如监测滥用。GPT-4和后续模型有可能以有益和有害的方式大大影响社会。我们正在与外部研究人员合作，以改善我们理解和评估潜在影响的方式，以及建立对未来系统可能出现的危险能力的评估。我们将很快分享我们对GPT-4和其他人工智能系统的潜在社会和经济影响的更多思考。培训过程像以前的GPT模型一样，GPT-4基础模型被训练为预测文档中的下一个词，并使用公开的数据（如互联网数据）以及我们授权的数据进行训练。这些数据是一个网络规模的语料库，包括数学问题的正确和错误的解决方案，薄弱和强大的推理，自相矛盾和一致的声明，以及大量不同的意识形态和想法。因此，当被提示有一个问题时，基础模型可以以各种各样的方式做出反应，而这些反应可能与用户的意图相去甚远。为了使其与用户的意图保持一致，我们使用人类反馈的强化学习（RLHF）对模型的行为进行微调。请注意，模型的能力似乎主要来自于预训练过程–RLHF并不能提高考试成绩（如果不积极努力，它实际上会降低成绩）。但是对模型的引导来自于训练后的过程–基础模型需要及时的工程，甚至知道它应该回答问题。可预测的缩放比例GPT-4项目的一大重点是建立一个可预测扩展的深度学习栈。主要原因是，对于像GPT-4这样的大型训练运行，进行广泛的特定模型调整是不可行的。我们开发了基础设施和优化，在多种规模下都有非常可预测的行为。为了验证这种可扩展性，我们提前准确地预测了GPT-4在我们内部代码库（不属于训练集）上的最终损失，方法是通过使用相同的方法训练的模型进行推断，但使用的计算量要少10000倍。现在，我们可以准确地预测我们在训练过程中优化的指标（损失），我们开始开发方法来预测更多可解释的指标。例如，我们成功地预测了HumanEval数据集的一个子集的通过率，从计算量少1000倍的模型中推断出来。有些能力仍然难以预测。例如，逆向缩放奖是一项竞赛，目的是找到一个随着模型计算量的增加而变得更糟的指标，而事后忽略是获胜者之一。就像最近的另一个结果，GPT-4扭转了这一趋势。我们相信，准确预测未来的机器学习能力是安全的一个重要部分，但相对于其潜在的影响，它并没有得到足够的重视（尽管我们已经被一些机构的努力所鼓舞）。我们正在扩大我们的努力，开发一些方法，为社会提供更好的指导，让人们了解对未来系统的期望，我们希望这成为该领域的一个共同目标。我们正在开源OpenAI Evals，这是我们的软件框架，用于创建和运行评估GPT-4等模型的基准，同时逐个样本检查其性能。我们使用Evals来指导我们的模型的开发（包括识别缺点和防止倒退），我们的用户可以应用它来跟踪各个模型版本（现在将定期推出）和不断发展的产品集成的性能。例如，Stripe使用Evals来补充他们的人工评估，以衡量其GPT驱动的文档工具的准确性。由于代码都是开源的，Evals支持编写新的类来实现自定义评估逻辑。然而，根据我们自己的经验，许多基准遵循一些 “模板 “中的一个，所以我们也包括了内部最有用的模板（包括一个 “模型分级评估 “的模板–我们发现GPT-4令人惊讶地能够检查自己的工作）。一般来说，建立一个新的评估的最有效方法是将这些模板中的一个实例化，并提供数据。我们很高兴看到其他人能用这些模板和Evals更普遍地建立什么。我们希望Evals成为一个分享和众包基准的工具，最大限度地代表广泛的故障模式和困难任务。作为后续的例子，我们已经创建了一个逻辑谜题评估，其中包含GPT-4失败的十个提示。Evals也与实现现有的基准兼容；我们已经包括了几个实现学术基准的笔记本和一些整合CoQA（小的子集）的变化作为例子。我们邀请大家使用Evals来测试我们的模型，并提交最有趣的例子。我们相信Evals将成为使用和建立在我们的模型之上的过程的一个组成部分，我们欢迎直接的贡献、问题和反馈。" }, { "title": "Python tuple += 的谜题", "url": "/posts/tuple-addition-assignment-puzzler/", "categories": "icenv", "tags": "python", "date": "2023-03-13 14:08:53 +0000", "snippet": "Python的tuple是一个不可修改的数据类型。&gt;&gt;&gt; a = (1,2,3)&gt;&gt;&gt; a[0]1&gt;&gt;&gt; a[0] = 11Traceback (most recent call last): File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;TypeError: 'tuple' object...", "content": "Python的tuple是一个不可修改的数据类型。&gt;&gt;&gt; a = (1,2,3)&gt;&gt;&gt; a[0]1&gt;&gt;&gt; a[0] = 11Traceback (most recent call last): File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;TypeError: 'tuple' object does not support item assignment那么tuple里放一个list，对这个tuple里的list做扩展，是什么结果？&gt;&gt;&gt; t = (1, 2, [30, 40])&gt;&gt;&gt; t[2] += [50, 60] t变成(1, 2, [30, 40, 50, 60]) 像上面那样抛出TypeError: ‘tuple’ object does not support item assignment 1与2都不是 1与2都是答案如下，是不是出乎意料？&gt;&gt;&gt; t = (1, 2, [30, 40])&gt;&gt;&gt; t[2] += [50, 60]Traceback (most recent call last): File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;TypeError: 'tuple' object does not support item assignment&gt;&gt;&gt; t(1, 2, [30, 40, 50, 60])通过https://pythontutor.com/visualize.html#mode=display图形化查看代码执行使用dis模块查看s[a] += b的字节码&gt;&gt;&gt; import dis&gt;&gt;&gt; dis.dis('s[a] += b') 1 0 LOAD_NAME 0 (s) 2 LOAD_NAME 1 (a) 4 DUP_TOP_TWO 6 BINARY_SUBSCR 8 LOAD_NAME 2 (b) 10 INPLACE_ADD 12 ROT_THREE 14 STORE_SUBSCR 16 LOAD_CONST 0 (None) 18 RETURN_VALUE DUP_TOP_TWO: 将栈顶的两个引用复制，保持顺序BINARY_SUBSCR: TOS = TOS1[TOS]的实现ROT_THREE：将栈顶的第二、第三个元素提升一个位置，将最顶的放到第三位置。ROT_TWO: 将栈顶的两个元素对调参考资料https://docs.python.org/3/library/dis.htmlhttps://learning.oreilly.com/library/view/fluent-python-2nd/9781492056348/ch02.html#tuple_puzzlerhttps://www.synopsys.com/blogs/software-security/understanding-python-bytecode/" }, { "title": "Python的双端队列", "url": "/posts/double-queue-in-python/", "categories": "icenv", "tags": "python", "date": "2023-03-13 10:20:56 +0000", "snippet": "介绍双端队列允许两端进行元素的增加或删除操作。Python collections.deque是一个线程安全的双端队列。当队列满了，从一端插入元素，另一端的最后一个元素会被丢弃。实验[wanlinwang@computing-server-01 ~]$ python3Python 3.10.8 (main, Mar 12 2023, 22:29:09) [GCC 4.8.5 20150623...", "content": "介绍双端队列允许两端进行元素的增加或删除操作。Python collections.deque是一个线程安全的双端队列。当队列满了，从一端插入元素，另一端的最后一个元素会被丢弃。实验[wanlinwang@computing-server-01 ~]$ python3Python 3.10.8 (main, Mar 12 2023, 22:29:09) [GCC 4.8.5 20150623 (Red Hat 4.8.5-44)] on linuxType \"help\", \"copyright\", \"credits\" or \"license\" for more information.&gt;&gt;&gt; from collections import deque&gt;&gt;&gt; dq = deque(range(10), maxlen=10) #创建最大长度为10的双端队列&gt;&gt;&gt; dqdeque([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], maxlen=10)&gt;&gt;&gt; dq.rotate(3) #向右滚动3个元素，最右端的会依次放到最左端。&gt;&gt;&gt; dqdeque([7, 8, 9, 0, 1, 2, 3, 4, 5, 6], maxlen=10)&gt;&gt;&gt; dq.rotate(-4) #向左移动4个元素，最左端的会依次放到最右端。&gt;&gt;&gt; dqdeque([1, 2, 3, 4, 5, 6, 7, 8, 9, 0], maxlen=10)&gt;&gt;&gt; dq.appendleft(-1) #在左端，增加一个元素-1，可以看到最右端的元素被丢弃了。&gt;&gt;&gt; dqdeque([-1, 1, 2, 3, 4, 5, 6, 7, 8, 9], maxlen=10)&gt;&gt;&gt; dq.extend([11,22,33]) #在右端扩展3个元素，可以看到最左的3个元素被丢弃了。&gt;&gt;&gt; dqdeque([3, 4, 5, 6, 7, 8, 9, 11, 22, 33], maxlen=10)&gt;&gt;&gt; dq.extendleft([10,20,30,40]) #在左端扩展4个元素，可以看到最右的4个元素被丢弃了。&gt;&gt;&gt; dqdeque([40, 30, 20, 10, 3, 4, 5, 6, 7, 8], maxlen=10)" }, { "title": "OpenVPN连上去就断开，然后重连，如此反复", "url": "/posts/openvpn-disconnect-every-other-3-seconds/", "categories": "icenv", "tags": "openvpn", "date": "2023-03-13 05:10:39 +0000", "snippet": "问题OpenVPN连上去3秒就断开，然后重连，如此反复。原因OpenVPN仅支持单客户端连接。当多客户端连接时，会互相挤下线。解决将不使用的终端下线。", "content": "问题OpenVPN连上去3秒就断开，然后重连，如此反复。原因OpenVPN仅支持单客户端连接。当多客户端连接时，会互相挤下线。解决将不使用的终端下线。" }, { "title": "Python Memoryview", "url": "/posts/python-memoryview/", "categories": "icenv", "tags": "python", "date": "2023-03-13 02:36:42 +0000", "snippet": "memoryview根据 MemoryView objects 介绍，memoryview对象暴露了C层次的buffer interface作为Python对象，可以被传递到任何其它对象。实验实验一透过本实验，可以看到memoryview.cast()方法可以不修改位来改变读取与写入的单位，它返回另一个memoryview对象，但与原memoryview是共享内存的。[wanlinwang@...", "content": "memoryview根据 MemoryView objects 介绍，memoryview对象暴露了C层次的buffer interface作为Python对象，可以被传递到任何其它对象。实验实验一透过本实验，可以看到memoryview.cast()方法可以不修改位来改变读取与写入的单位，它返回另一个memoryview对象，但与原memoryview是共享内存的。[wanlinwang@computing-server-01 ~]$ python3Python 3.10.8 (main, Mar 12 2023, 22:29:09) [GCC 4.8.5 20150623 (Red Hat 4.8.5-44)] on linuxType \"help\", \"copyright\", \"credits\" or \"license\" for more information.&gt;&gt;&gt; from array import array&gt;&gt;&gt; octets = array('B', range(6))&gt;&gt;&gt; octetsarray('B', [0, 1, 2, 3, 4, 5])&gt;&gt;&gt; m1 = memoryview(octets)&gt;&gt;&gt; mlTraceback (most recent call last): File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;NameError: name 'ml' is not defined. Did you mean: 'm1'?&gt;&gt;&gt; m1&lt;memory at 0x7f2af10db880&gt;&gt;&gt;&gt; m1.tolist()[0, 1, 2, 3, 4, 5]&gt;&gt;&gt; m2 = m1.cast('B', [2,3])&gt;&gt;&gt; m2.tolist()[[0, 1, 2], [3, 4, 5]]&gt;&gt;&gt; m3 = m1.cast('B', [3,2])&gt;&gt;&gt; m3.tolist()[[0, 1], [2, 3], [4, 5]]&gt;&gt;&gt; octetsarray('B', [0, 1, 2, 3, 4, 5])&gt;&gt;&gt; m2[1,1] = 22&gt;&gt;&gt; m2.tolist()[[0, 1, 2], [3, 22, 5]]&gt;&gt;&gt; m3[1,1] = 33&gt;&gt;&gt; m3.tolist()[[0, 1], [2, 33], [22, 5]]&gt;&gt;&gt; octetsarray('B', [0, 1, 2, 33, 22, 5])&gt;&gt;&gt;实验二[wanlinwang@computing-server-01 ~]$ python3Python 3.10.8 (main, Mar 12 2023, 22:29:09) [GCC 4.8.5 20150623 (Red Hat 4.8.5-44)] on linuxType \"help\", \"copyright\", \"credits\" or \"license\" for more information.&gt;&gt;&gt; import array&gt;&gt;&gt; numbers = array.array('h', [-2,-1,0,1,2])&gt;&gt;&gt; memv = memoryview(numbers)&gt;&gt;&gt; len(memv)5&gt;&gt;&gt; memv[0]-2&gt;&gt;&gt; memv_oct = memv.cast('B')&gt;&gt;&gt; memv_oct.tolist()[254, 255, 255, 255, 0, 0, 1, 0, 2, 0]&gt;&gt;&gt; memv_oct[5] = 4&gt;&gt;&gt; numbersarray('h', [-2, -1, 1024, 1, 2])&gt;&gt;&gt; 参考资料https://www.fluentpython.com/extra/parsing-binary-struct/#ex_metro_struct_chttps://learning.oreilly.com/library/view/fluent-python-2nd/9781492056348/ch02.html#numpy_sec" }, { "title": "在Linux下编辑图", "url": "/posts/picture-viewing-and-editing-on-linux/", "categories": "icenv", "tags": "linux", "date": "2023-03-12 10:38:18 +0000", "snippet": "需求在Linux研发桌面下画图。本文介绍两个常用的画图工具，第一个是满足与Windows下”画图“工具的简单需求；第二个则是满足流程图的功能需求，类似于visio。方案gimp它是GNU图片操作程序，信息如下所示安装bash-4.2# yum install -y gimp运行draw.io简介它是一款免费的支持多平台的流程图工具，许可证为Apache 2.0。下载运行赋予执行权限，如是ro...", "content": "需求在Linux研发桌面下画图。本文介绍两个常用的画图工具，第一个是满足与Windows下”画图“工具的简单需求；第二个则是满足流程图的功能需求，类似于visio。方案gimp它是GNU图片操作程序，信息如下所示安装bash-4.2# yum install -y gimp运行draw.io简介它是一款免费的支持多平台的流程图工具，许可证为Apache 2.0。下载运行赋予执行权限，如是root账户则加上–no-sandbox选项" }, { "title": "虚拟补丁：一种有效的数据库安全防护方式", "url": "/posts/virtual-patching/", "categories": "icenv-posts", "tags": "linux, security", "date": "2023-03-08 04:50:00 +0000", "snippet": "Verizon曾经就“核心数据是如何丢失的”做过一次全面的市场调查，结果发现，75%的数据丢失情况是由于数据库漏洞造成。CVE数据安全漏洞统计显示，Oracle、SQL Server、MySQL等主流数据库的漏洞逐年上升。Skybox Security最新发布的2020年漏洞和威胁趋势报告则指出，2020年漏洞数量有可能突破新的记录——超过20000个。软件系统因技术性缺陷，总是不可避免的存...", "content": "Verizon曾经就“核心数据是如何丢失的”做过一次全面的市场调查，结果发现，75%的数据丢失情况是由于数据库漏洞造成。CVE数据安全漏洞统计显示，Oracle、SQL Server、MySQL等主流数据库的漏洞逐年上升。Skybox Security最新发布的2020年漏洞和威胁趋势报告则指出，2020年漏洞数量有可能突破新的记录——超过20000个。软件系统因技术性缺陷，总是不可避免的存在各种漏洞，而根据Gartner的数据， 其中99%的漏洞均为已知的漏洞，系统持续“裸奔”，这无疑给攻击者大开方便之门。尤其是数据库，这一信息系统的核心，一旦漏洞被利用，将造成巨大隐患。通过获取软件开发商所提供的补丁程序，完成系统升级，这是普遍的漏洞修复方式，这种补丁修复流程会历经多个阶段，如下图所示：但是，这种直接打补丁的方案却存在风险、成本、时效、老旧系统等诸多问题：补丁修复操作繁琐，修复过程存在兼容性隐患；漏洞问题层出不穷，频繁打补丁工作成本加大；零日漏洞加速出现，厂商提供补丁更新包却滞后；老旧系统无补丁更新，即便有用户也不敢去升级。在漏洞爆发式增长的今天，“打补丁”已经越来越不能应对新的安全态势，漏洞之困，何以解忧？这需要一种既可以快速解决系统漏洞风险，又具有可操作性的漏洞修补方案。虚拟补丁作为一种轻量级且无损现有生产环境，同时又是非常行之有效的漏洞修补方案应运而生。☆虚拟补丁虚拟补丁概念最早由安全厂商McAfee提出。虚拟补丁方案假设：漏洞不可能避免，永远都有漏洞。漏洞修复总是需要一定的时间作为代价。新形势下，对于漏洞的“修复”有着更高的要求。避免触碰业务系统，尽可能短的时间内进行修复。如果一个系统有很多漏洞，只要不去引爆，那么这些漏洞的存在也将没有意义。也就达到了“漏洞修复”的目的。对此，虚拟补丁承认系统漏洞存在，在受保护的资源外部建立一个策略实施点，以便在漏洞到达目标之前识别和拦截利用这些漏洞的行为。这样就不需要直接修改被保护的资源，从而让漏洞在非法攻击中隐形。如下图所示：目前市面上，虚拟补丁方案在形式上基本一致，但实现逻辑却有所差异，各厂商都有各自的方案特点，如：完全基于对网络流量的分析并提供系统使用签名、正则表达式和模式匹配来识别恶意活动并阻止相应的请求；基于相同的原理，但提供一种使用规则语言和状态管理等更为健壮的方式来阻止指定请求。在数据库安全领域历经十余年的研究和实践，美创科技提出更轻量级、更加健壮的数据库虚拟补丁方案，可以快速响应漏洞、智能修复，在此，我们深入了解该方案如何实现有效保护。☆虚拟补丁架构美创科技虚拟补丁架构主要由虚拟补丁策略、策略决策点（PDP）和策略执行点（PEP）构成。实现的逻辑架构如下图所示：策略执行点（PEP）数据平面拦截数据流，通过数据流的协议解析获取请求/响应的应用层内容。把内容送往PDP(策略决策点)进行策略评估。根据PDP的返回做出响应，阻断或者放行等。流量可通过旁路模式实现。旁路模式实时阻断较弱，但可实现告警，追溯等能力。流量串接模式则能够进行实时阻断，甚至是内容级别的阻断。策略决策点（PDP）根据策略对PEP送过来的请求进行评估，识别请求是否合法。策略可以采取多种形式：正则匹配：触发漏洞的语句往往具有一定的特征，可以根据这些特征编写正则表达式。语义解析：通过语义解析判断当前请求是否是攻击行为。白名单形式：通过建立起正常的行为模式基线识别攻击。偏离固有的行为模式，判定存在风险。访问上下文：通过检测访问上下文的各种属性，判断当前请求是否合法。策略决策点的关键在于持续的评估请求合法性。根据灵活的策略库、风险库识别当前请求是否合法，对不合法的请求阻断，将攻击扼杀在路上，从而避免被保护的资源受到攻击，受保护资源本身的漏洞也就不存在威胁。流程实施虚拟补丁，关键点在于请求的路径上设置检测点，阻断非法请求。让受保护资源本身的漏洞隐形，不会发作，从而达到“漏洞修复”的目的。☆虚拟补丁的优点美创科技数据库虚拟补丁作为一种轻量级的漏洞修复方案，有诸多优点：快速响应漏洞：无需等待开发厂商的补丁包，只需及时调整策略即可。快速修复：无需重启系统，无须停机窗口，策略一旦调整完毕实时起效。非侵入式：通过虚拟补丁方式修复数据库漏洞，无需更改数据库环境，无额外成本，大大减轻测试和部署补丁的工作。智能修复：可根据虚拟补丁策略的优先级、等级、严重性等进行智能编排，快速选择启停策略，响应方式等，自由灵活。更具合规性：帮助用户，用最少的成本保持数据库始终符合合规要求。更多可能性：可以在访问控制的基础上，实现授权操作等功能。根据不同身份执行不同策略。根据身份、行为、资产的属性做出不同的评估。最大程度达成业务和安全的平衡：① 减少对“紧急”补丁或者解决方案的依赖；② 在网络中的选定点，而不是在每个系统上应用补丁；③ 使企业能够灵活地按计划时间表进行修补；④ 有助于减少关键系统、数据库和应用程序的计划外停机带来的高机会成本；⑤ 扩展的策略授权执行。美创科技虚拟补丁解决方案更加适合针对数据库等复杂系统的保护，轻量级的保护手段让“漏洞修复”更加安全、快速、灵活。此虚拟补丁方案已集成到美创数据库防火墙内，作为内嵌功能，以非侵入式帮助用户实现保护数据库安全的目的。美创数据防火墙虚拟补丁功能基于上述架构通过控制对数据库的输入和输出，检测其会话信息和语句信息对漏洞的尝试利用，阻止或消除漏洞攻击行为。截止目前，数据库防火墙的漏洞规则库已识别并内置20多类数据库漏洞类型虚拟补丁，实现对1600+多个漏洞防御保护，同时也仍在持续不断地更新。美创数据库防火墙的虚拟补丁功能完全避免进行代码级的改造，加长数据库系统被保护的时间，避免数据库长时间处在高风险的阴影下。☆案例SQL SERVER 2008提权漏洞当使用SQL SERVER数据库的业务系统存在SQL注入，或者SQL SERVER数据库存在弱口令的情况下，攻击者获得SQL SERVER数据库管理员权限后，即可以利用SQL SERVER数据库的存储过程执行命令进行提权，从而获得SQL SERVER数据库所在系统的控制权限。开启之后就可以执行，获得一些信息后，然后进一步破坏。针对这个漏洞，美创数据防火墙虚拟补丁可以通过多种方式进行拦截：根据语句特征，编写正则表达式，放入策略库，进行阻断；根据强制白名单阻断；根据语义解析，分析行为；如果一些情况需要执行这些语句，可进行授权操作；整个过程快速实施，轻量级处理风险。强制白名单机制可防御0-day漏洞。即便需要更新策略库，过程也比传统打补丁修复方式更加快速。ORACLE TNS Listener远程注册投毒漏洞ORACLE TNS Listener远程注册投毒漏洞（CVE-2012-1675）是Oracle 2012年发布的告警，CVE-2012-1675漏洞是Oracle允许攻击者在不提供用户名/密码的情况下，向远程“TNS Listener”组件处理的数据投毒的漏洞。如：攻击者可以在不需要用户名密码的情况下利用网络中传送的数据消息(包括加密或者非加密的数据)，如果结合（CVE-2012-3137漏洞进行密码破解）从而进一步影响甚至控制局域网内的任何一台数据库。攻击者利用该漏洞时，首先会利用攻击载荷攻击TNS网络组件，使其返回错误信息，错误信息中包含攻击者所需的信息，如下：可以看到，返回的信息是有其固定的格式的。美创数据防火墙虚拟补丁通过精准匹配数据库漏洞发生时输出的信息，对返回的数据库信息进行混淆处理或者拦截，使攻击者无法得到有效信息，有效抵御入侵攻击行为。本文作者：杭州美创科技原文链接：https://www.freebuf.com/articles/network/254518.html" }, { "title": "REALVNC如何增加或删除分辨率配置？", "url": "/posts/realvnc-add-or-rm-resolution/", "categories": "icenv-posts", "tags": "linux, vnc", "date": "2023-03-08 04:50:00 +0000", "snippet": "问题用户设置1920x1080的分辨率，屏幕崩溃，画面乱了。解决去掉有问题的配置。查看到两个1920x1080的配置使用xrandr试着删掉其中一个，提示无法删除经google，说的是xrandr无法删除由X managed的mode。从XREALVNC手册侧删除，/etc/X11/vncserver-virtual-dummy.conf，如果是较早的版本则是/etc/X11/vncserv...", "content": "问题用户设置1920x1080的分辨率，屏幕崩溃，画面乱了。解决去掉有问题的配置。查看到两个1920x1080的配置使用xrandr试着删掉其中一个，提示无法删除经google，说的是xrandr无法删除由X managed的mode。从XREALVNC手册侧删除，/etc/X11/vncserver-virtual-dummy.conf，如果是较早的版本则是/etc/X11/vncserver-virtual.conf文件。尝试将其一从这个文件里移除，问题即解决。" }, { "title": "GitHub bashrc 初始化文件样例", "url": "/posts/github-bash-.bashrc/", "categories": "icenv-posts", "tags": "linux", "date": "2023-03-02 03:18:00 +0000", "snippet": "@wanlinwang ➜ ~ $ cat .bashrc# ~/.bashrc: executed by bash(1) for non-login shells.# see /usr/share/doc/bash/examples/startup-files (in the package bash-doc)# for examples# If not running interacti...", "content": "@wanlinwang ➜ ~ $ cat .bashrc# ~/.bashrc: executed by bash(1) for non-login shells.# see /usr/share/doc/bash/examples/startup-files (in the package bash-doc)# for examples# If not running interactively, don't do anythingcase $- in *i*) ;; *) return;;esac# don't put duplicate lines or lines starting with space in the history.# See bash(1) for more optionsHISTCONTROL=ignoreboth# append to the history file, don't overwrite itshopt -s histappend# for setting history length see HISTSIZE and HISTFILESIZE in bash(1)HISTSIZE=1000HISTFILESIZE=2000# check the window size after each command and, if necessary,# update the values of LINES and COLUMNS.shopt -s checkwinsize# If set, the pattern \"**\" used in a pathname expansion context will# match all files and zero or more directories and subdirectories.#shopt -s globstar# make less more friendly for non-text input files, see lesspipe(1)[ -x /usr/bin/lesspipe ] &amp;&amp; eval \"$(SHELL=/bin/sh lesspipe)\"# set variable identifying the chroot you work in (used in the prompt below)if [ -z \"${debian_chroot:-}\" ] &amp;&amp; [ -r /etc/debian_chroot ]; then debian_chroot=$(cat /etc/debian_chroot)fi# set a fancy prompt (non-color, unless we know we \"want\" color)case \"$TERM\" in xterm-color|*-256color) color_prompt=yes;;esac# uncomment for a colored prompt, if the terminal has the capability; turned# off by default to not distract the user: the focus in a terminal window# should be on the output of commands, not on the prompt#force_color_prompt=yesif [ -n \"$force_color_prompt\" ]; then if [ -x /usr/bin/tput ] &amp;&amp; tput setaf 1 &gt;&amp;/dev/null; then # We have color support; assume it's compliant with Ecma-48 # (ISO/IEC-6429). (Lack of such support is extremely rare, and such # a case would tend to support setf rather than setaf.) color_prompt=yes else color_prompt= fifiif [ \"$color_prompt\" = yes ]; then PS1='${debian_chroot:+($debian_chroot)}\\[\\033[01;32m\\]\\u@\\h\\[\\033[00m\\]:\\[\\033[01;34m\\]\\w\\[\\033[00m\\]\\$ 'else PS1='${debian_chroot:+($debian_chroot)}\\u@\\h:\\w\\$ 'fiunset color_prompt force_color_prompt# If this is an xterm set the title to user@host:dircase \"$TERM\" inxterm*|rxvt*) PS1=\"\\[\\e]0;${debian_chroot:+($debian_chroot)}\\u@\\h: \\w\\a\\]$PS1\" ;;*) ;;esac# enable color support of ls and also add handy aliasesif [ -x /usr/bin/dircolors ]; then test -r ~/.dircolors &amp;&amp; eval \"$(dircolors -b ~/.dircolors)\" || eval \"$(dircolors -b)\" alias ls='ls --color=auto' #alias dir='dir --color=auto' #alias vdir='vdir --color=auto' alias grep='grep --color=auto' alias fgrep='fgrep --color=auto' alias egrep='egrep --color=auto'fi# colored GCC warnings and errors#export GCC_COLORS='error=01;31:warning=01;35:note=01;36:caret=01;32:locus=01:quote=01'# some more ls aliasesalias ll='ls -alF'alias la='ls -A'alias l='ls -CF'# Add an \"alert\" alias for long running commands. Use like so:# sleep 10; alertalias alert='notify-send --urgency=low -i \"$([ $? = 0 ] &amp;&amp; echo terminal || echo error)\" \"$(history|tail -n1|sed -e '\\''s/^\\s*[0-9]\\+\\s*//;s/[;&amp;|]\\s*alert$//'\\'')\"'# Alias definitions.# You may want to put all your additions into a separate file like# ~/.bash_aliases, instead of adding them here directly.# See /usr/share/doc/bash-doc/examples in the bash-doc package.if [ -f ~/.bash_aliases ]; then . ~/.bash_aliasesfi# enable programmable completion features (you don't need to enable# this, if it's already enabled in /etc/bash.bashrc and /etc/profile# sources /etc/bash.bashrc).if ! shopt -oq posix; then if [ -f /usr/share/bash-completion/bash_completion ]; then . /usr/share/bash-completion/bash_completion elif [ -f /etc/bash_completion ]; then . /etc/bash_completion fifi# bash theme - partly inspired by https://github.com/ohmyzsh/ohmyzsh/blob/master/themes/robbyrussell.zsh-theme__bash_prompt() { local userpart='`export XIT=$? \\ &amp;&amp; [ ! -z \"${GITHUB_USER}\" ] &amp;&amp; echo -n \"\\[\\033[0;32m\\]@${GITHUB_USER} \" || echo -n \"\\[\\033[0;32m\\]\\u \" \\ &amp;&amp; [ \"$XIT\" -ne \"0\" ] &amp;&amp; echo -n \"\\[\\033[1;31m\\]➜\" || echo -n \"\\[\\033[0m\\]➜\"`' local gitbranch='`\\ if [ \"$(git config --get devcontainers-theme.hide-status 2&gt;/dev/null)\" != 1 ] &amp;&amp; [ \"$(git config --get codespaces-theme.hide-status 2&gt;/dev/null)\" != 1 ]; then \\ export BRANCH=$(git --no-optional-locks symbolic-ref --short HEAD 2&gt;/dev/null || git --no-optional-locks rev-parse --short HEAD 2&gt;/dev/null); \\ if [ \"${BRANCH}\" != \"\" ]; then \\ echo -n \"\\[\\033[0;36m\\](\\[\\033[1;31m\\]${BRANCH}\" \\ &amp;&amp; if [ \"$(git config --get devcontainers-theme.show-dirty 2&gt;/dev/null)\" = 1 ] &amp;&amp; \\ git --no-optional-locks ls-files --error-unmatch -m --directory --no-empty-directory -o --exclude-standard \":/*\" &gt; /dev/null 2&gt;&amp;1; then \\ echo -n \" \\[\\033[1;33m\\]✗\"; \\ fi \\ &amp;&amp; echo -n \"\\[\\033[0;36m\\]) \"; \\ fi; \\ fi`' local lightblue='\\[\\033[1;34m\\]' local removecolor='\\[\\033[0m\\]' PS1=\"${userpart} ${lightblue}\\w ${gitbranch}${removecolor}\\$ \" unset -f __bash_prompt}__bash_promptexport PROMPT_DIRTRIM=4" }, { "title": "Cadence workshop 20230302", "url": "/posts/Cadence-workshop/", "categories": "icenv-posts", "tags": "workshop", "date": "2023-03-02 01:55:00 +0000", "snippet": "一、提升仿真速度业界仿真工具的功能类似，拼性能。5X Xcelium MC App这个成熟吗？加速门级DFT仿真。Test suite latency受制于最长的那个case。通过MC将它切分到多核运行。追求效率与资源的平衡。ARM-Based or X86-based将没有依赖性的拆分，会引入一些overhead。在SingleCore时加选项，可以生成profile，来评估哪些可以加速。...", "content": "一、提升仿真速度业界仿真工具的功能类似，拼性能。5X Xcelium MC App这个成熟吗？加速门级DFT仿真。Test suite latency受制于最长的那个case。通过MC将它切分到多核运行。追求效率与资源的平衡。ARM-Based or X86-based将没有依赖性的拆分，会引入一些overhead。在SingleCore时加选项，可以生成profile，来评估哪些可以加速。DFT可以考虑用MC做加速。5X Xcelium ML App通过机器学习来提升回归吞吐。模型是自己训练还是厂家提供？需要安装额外的ML安装包，依赖于vmanager做集成。正在做无vmnanager的集成，下半年推出。达到同样的效果，会做精简。降低回归时间。很多case是冗余的，随机种子很多是伪随机。随机空间更加优化。以收敛率，生成更好的随机空间，随机变量。节省资源，释放更多的资源。Bug Hunting。通过随机的。如果是定向的则没有意义。5X Advanced Build Tech并行编译、增量编译（改动不大的，做成snapshot）。很多IP是固定的，没有必要每次都编译。 增量编译。编testcase，再花两分钟将它链到固定的部分。语法检查，并行编译，所有的编译好的文件，做一个elaboration。10X Save/Restore and dynamic Test Load所有人都从那个点开始，用UVM的动态重载功能。在run的时候可以override。base testcase，跑完save snapshot（非常大、复杂的状态集）。开始case的时候对base testcase考量，这样初始化只需要跑一些。如果case已经建好，再去拆就比较麻烦了，因为每个case都例化了一个UVM environment了。Full Power Solution略" }, { "title": "除了ping，还有什么可以做主机探活？", "url": "/posts/ping-alternativies/", "categories": "icenv-posts", "tags": "formatting, links", "date": "2023-03-01 11:00:00 +0000", "snippet": "背景日常工作中，经常需要对主机进行探活操作，用的最多的属ping工具。ARP PingARP Ping是一种使用ARP（Address Resolution Protocol）协议的网络测试工具。它与ICMP Ping类似，但是它不依赖于ICMP协议，而是发送ARP请求包到目标主机的MAC地址来判断主机是否存活。TCP PingTCP Ping是一种基于TCP协议的网络测试工具，它通过发送一...", "content": "背景日常工作中，经常需要对主机进行探活操作，用的最多的属ping工具。ARP PingARP Ping是一种使用ARP（Address Resolution Protocol）协议的网络测试工具。它与ICMP Ping类似，但是它不依赖于ICMP协议，而是发送ARP请求包到目标主机的MAC地址来判断主机是否存活。TCP PingTCP Ping是一种基于TCP协议的网络测试工具，它通过发送一个TCP SYN包到目标主机的端口来判断主机是否存活。如果目标主机响应了一个TCP SYN+ACK包，则表示主机存活。UDP PingUDP Ping是一种基于UDP协议的网络测试工具，它通过发送一个UDP数据包到目标主机的端口来判断主机是否存活。如果目标主机响应了一个UDP数据包，则表示主机存活。TracerouteTraceroute是一种网络测试工具，它可以用来确定数据包从源主机到目标主机的路径。通过Traceroute，可以检测到中间任何一个网络节点的响应情况，从而判断主机是否存活。需要注意的是，这些测试工具也有其局限性，有时可能会出现误判或漏判的情况，因此在实际应用中，需要根据具体情况选择合适的测试工具并结合其他方法来进行综合判断。" }, { "title": "LSF初级在线培训", "url": "/posts/LSF-101-live-training/", "categories": "icenv-posts", "tags": "formatting, links", "date": "2023-02-28 10:30:00 +0000", "snippet": "1. 简介今天下午，IBM举办的LSF初级在线培训。Agenda Basic of LSF and architecture Overview of LSF Family products LSF and LSF Suite installation LSF License Scheduler Use PAC to submit and manager jobs Use RTM ...", "content": "1. 简介今天下午，IBM举办的LSF初级在线培训。Agenda Basic of LSF and architecture Overview of LSF Family products LSF and LSF Suite installation LSF License Scheduler Use PAC to submit and manager jobs Use RTM to monitor LSF cluster Q&amp;A2. 内容2.1 IBM Spectrum LSF支持各种工作负载的调度 传统的HPC/HTC（batch&amp;Interactive）作业 容器化作业 大数据作业 机器学习作业2.2 IBM Spectrum LSF对（云上云下）各种共享（异构）资源的管理 Power x86 Linux on z SPARC Arm containers 存储（Flash，Disk，and Tape）2.3 LSF术语 角色 数量 说明 Client 一个或多个 作为提交机，可以是Linux，或者是Windows master host 一个master host，一个或多个master candidate host 可以作为提交机与执行机。也可以CLOSED使得它不作为提交机、执行机，专机专用，避免工作负载影响了LSF master的调度 server host 一个或多个 可以作为提交机与执行机。它也可以是一个master cadidate host job   提交：从提交机提交到master host放到Queue并PEND调度：被调度器调度到执行机，通常占用1个slot执行：执行机接收到job后开始执行 2.4 LSF架构Master与Host的各种服务之间的联系。 所有机器有LIM进程 host上的LIM进程会收集当前node的负载、资源使用情况，有哪些资源，比如CPU型号、OS版本等，定期发送给master的LIM。这样master就知道所有这些主机的情况。用户也可以通过elim（plugin module）来自定义监控，如温度等等。 所有机器有SBD进程 当作业提交到master时，会在MBD、MBSCHD里排队。MBD是集群里最重要的核心组件，它会把master LIM里收集到host的信息拿到，并且知道集群里排队作业的情况，进行作业与资源的匹配、派遣到执行机。host的SBD会根据用户指定的命令行，将作业运行起来，直到作业结束。 守护进程异常处理 当host的守护进程宕掉之后，master就无法收集host的信息，此时host将会被标为unavail的状态。在最新的RHEL里，有一个lsf的patch，它使用systemd来管理lsf的守护进程，当lsf守护进程宕掉后，systemd自动将它重启起来。 job LSF对job没有特殊要求，只要它能够在单机上运行，那么它就可以在LSF集群里执行，不需要做过多的集成。假设master与host没有共享文件系统的话，可以设置将job的输出拷贝回提交机。 2.5 IBM Spectrum LSF Family有很多add-on，如 Application Center web页面 Process Manager License Scheduler EDA License是非常昂贵的，基于FlexLM或RLM的，结合License调度，达到License的最大化使用。 Data Manager 在on-premise LSF资源不够时，将job弹到云上，此时借助Data Manager来决定哪些数据是需要传上去给job使用的。 Resource Connector 多集群时使用。在on-premise LSF资源不够时，到客户指定的云上去动态申请机器并将其加到现有的LSF集群，用来跑作业。当作业跑完后释放资源。 Explorer 监控集群的使用情况。定期产生报表，是否要扩缩容。 2.6 Editions2.6.1 IBM Spectrum LSF Community Edition Community Edition可扩展到10个节点，最大job数2,500个；2.6.2 IBM Spectrum LSF Suite Editions商业有三个版本，功能越来越强大： Workgroup可扩展到 128 个节点，最大job数25,000个； HPC可扩展至 1,024 个节点，最大job数250,000个； Enterprise的节点与job数量没有限制。2.6.3 版本号介绍 10.1.0.13 的10.1.0为major release，13为fix pack（每0.5~1年一次）。2.7 安装与配置2.7.1 标准版安装与使用 确定用于安装LSF的服务器是什么CPU架构，什么操作系统； 在IBM passport advantage上面下载对应的安装包 lsf10.1_lsfinstall.tar.Z(Passport Advantage) lsf10.1_OS-Spec.tar.Z(Passport Advantage) lsf10.1_OS-Spec-build-number.tar.Z(Fix Central) platform_lsf_std_entitlement.dat #许可证，如果无许可证，安装完之后是社区版。 解压 修改配置文件install.config 安装，建议在共享文件系统（如Spectrum Scale，即原来的GPFS，可被深度集成的，如每作业占用文件系统大小；或NFS）下安装，命令如下$ ./lsfinstall -f install.config$ $LSF_ENVDIR/../10.1/install/patchinstall &lt;/path/to/fp&gt; 安装最新的fix pack -（截止至发稿，是FP13。于2022年中旬发布）。请注意，最新的fix pack已经包含当前major release的所有fix pack了，不需要将FP1…FP12都补上，直接打FP13即可。 启动LSF 启动本机daemon # lsadmin limstartup# lsadmin resstartup# badmin hstartup 启动其他机器的daemon # lsadmin limstartup host1 [host2 ... hostn]# lsadmin resstartup host1 [host2 ... hostn]# badmin hstartup host1 [host2 ... hostn] 启动所有在lsf.cluster定义的主机的daemon # lsadmin limstartup all# lsadmin resstartup all# badmin hstartup all# lsfstartup #或者一条命令 新增机器编辑/conf/lsf.cluster.文件，将新增的机器加进来，然后执行`lsadmin reconfig; badmin mbdrestart`以及`lsadmin limstartup host1 [host2 ... hostn]; lsadmin resstartup host1 [host2 ... hostn]; badmin hstartup host1 [host2 ... hostn]`。 LSF启动的服务以及默认端口 LSF Master LSF Server Port Desc lim lim 7869 Load Information Manager pim pim   Process information Manager res res 6878 Remote Execution Server sbatchd sbatchd 6882 Slave Batch Daemon mbatchd   6881 Master Batch Daemon mbschd     Master Batch Scheduler 初始化source /path/to/lsf/conf/cshrc.lsf #for csh. /path/to/lsf/conf/profile.lsf # for bash初始化完了之后，执行which bsub可以验证是否初始化成功。 常用命令 CLI Desc bsub 提交作业。多个bsub并行跑 bjobs 查看作业，从内存里找 bhist 查看作业的历史信息，从lsf events文件里找 bbot/btop 将pending job移到最后/最前 bkill 杀掉作业，加上jobid杀掉指定job，或者加0kill掉当前用户的全部作业 bmod 修改作业的提交选项 bpeek 将未完成作业的stdout与stderr显示 bstop/bresume 挂起/恢复作业 bswitch 将未完成的作业，更换一个队列 注意： LSF安装后不支持cluster name修改。 使用IBM certified的GPFS来安装LSF。也支持NFS，但性能稍差。也可以安装在local文件系统，但为了支持failover，建议Master安装在共享文件系统。 Master支持在物理机或者虚拟机安装，以满足客户对混合云的部署需求。 标准版的cli安装，Suit版的Ansible安装 Suit版以.bin结尾，不需先安装基础包再安装fix pack包。而标准版则两步骤分开。 Entitlement File，标准版里需手动下载指定，而Suit版本已内置。 最大Node数量：标准版里技术上不限制，通过合同限制。而Suit版技术上就限制了最大Node数量。2.7.2 LSF Suite安装与使用LSF Suite安装与标准版安装不一样，它是累积型的，一个bin包就包含了之前所有的fix pack以及entitlement文件。10.2.0.9以及之前是包含了ElasticSearch的，之后是不包含了，允许用户自己指定ElasticSearch。 确定用于安装LSF的服务器是什么CPU架构，什么操作系统； 下载安装包：lsfswg10.2.0.13-x86_64.bin 执行自解压：./lsfswg10.2.0.13-x86_64.bin 切换目录到/opt/ibm/lsf_installer/playbook 编辑主机列表文件lsf-inventory，将作为master、server、client、GUI_Host、DB_Host的机器加进来。 编辑配置文件lsf-config.yml，设置集群名称、共享目录、JDBC连接串以及其他的一些设置。默认当前机器是GUI节点、数据库节点。 测试配置文件以及主机的连通性： ansible-playbook -i lsf-inventory lsf-config-test.ymlansible-playbook -i lsf-inventory lsf-predeploy-test.yml 上一步测试没问题时，则执行安装命令： ansible-playbook -i lsf-inventory lsf-deploy.yml 2.7.3 队列队列划分，根据不同的运行时间、交互类型等来划分队列。2.8 高级特性 从_？_版本开始，支持带lockid的badmin hclose，方便管理员做不同原因的hclose操作。 有Workload Template功能，便于用户根据不同业务类型，快速上手LSF的使用。 提供用户各种终端交互，包括cli，web，mobile以及api等。 process manager支持flow的定制2.9 周边组件支持 RTM（Report, Track, and Monitor）支持对两种License管理器使用情况的收集展示：FlexLM与RLM。 一个RTM支持对多个LSF集群监控。 License Scheduler支持对两种License管理器——FlexLM与RLM的bsub rusage条件使用。 支持Docker作业。另，K8S在调度方面能力弱，LSF支持作为K8S的调度组件使用。 LSF RTM Server是开源的，卖服务。而RTM Poller（RTM Data Collectors）是闭源的商业产品，采集存储的数据结构相对稳定，字段一般只增不减，方便客户基于该数据源做定制化聚合与展示。 Application Center的权限模型是RBAC的。 LSF管理数据存放在MeraiDB，作业日志存放在ElasticSearch里。2.10 如何试用？ 自行安装社区版 与代理商或者原厂联系，申请私有化部署测试环境 在https://techzone.ibm.com/collection/ibm-spectrum-lsf-suite申请suite版本测试，自带少量Node，需注册。3. Q&amp;A lsadmin与admin的区别是？ The lsadmin command controls the operation of the lim and res daemons.（base部分，一般是修改了ls、lsf开头的配置文件后使用。）The badmin command controls the operation of the mbatchd and sbatchd daemons.（batch部分，一般是修改了lsb开头的配置文件后使用。） 机器可以跑多少任务，如何确定？ 默认是多少个core，就可以跑多少个任务，通过bhosts查看的MAX字段。但也可以修改/conf/lsbatch//configdir/lsb.hosts文件来修改。参考(MXJ settings in lsb.hosts file)[https://www.ibm.com/docs/en/spectrum-lsf/10.1.0?topic=files-lsbhosts] 如果将LSF宕掉了，作业还能恢复吗？ /work目录，存放作业的状态信息。当集群从异常恢复正常时，LSF会从这个目录读取信息，恢复作业的状态。 如果需要绑定core，如何操作？ 设置LSF CPU affinity，利用control group将作业的所有进程绑定到某一个core上。这样不会被别的作业使用。 4. 致谢感谢主办方以及IBM的分享。5. 参考资料 https://www.ibm.com/docs/en/spectrum-lsf/10.1.0?topic=linux-preparing-your-systems-installation for Integrating LDAP with LSF. https://www.ibm.com/docs/en/spectrum-lsf-rtm/10.1.0?topic=alerts-setting-up-email-server-notifications for settings up email server notifications for RTM. https://www.ibm.com/docs/en/spectrum-lsf/10.1.0?topic=limits-specify-resource-usage for specifying resource usage limits. https://www.ibm.com/docs/en/spectrum-lsf/10.1.0?topic=resources-define-ncpusprocessors-cores-threads for ncpus definition. https://www.ibm.com/docs/en/spectrum-lsf/10.1.0?topic=migrate-upgrade for migrating or upgrading LSF. https://www.ibm.com/docs/en/slsfh/10.2.0?topic=updating-installation-scenarios 7." }, { "title": "ChatGPT机器人", "url": "/posts/ai-chatbot/", "categories": "ai-posts", "tags": "formatting, links", "date": "2023-02-28 01:28:16 +0000", "snippet": "背景聊天生成型预训练变换模型（英文：Chat Generative Pre-trained Transformer）简称ChatGPT，是由OpenAI开发的一个人工智能聊天机器人程序，于2022年11月推出。该程序使用基于GPT-3.5架构的大型语言模型并通过强化学习进行训练。 ChatGPT目前仍以文字方式交互，而除了可以通过人类自然对话方式进行交互，还可以用于相对复杂的语言工作，包括自...", "content": "背景聊天生成型预训练变换模型（英文：Chat Generative Pre-trained Transformer）简称ChatGPT，是由OpenAI开发的一个人工智能聊天机器人程序，于2022年11月推出。该程序使用基于GPT-3.5架构的大型语言模型并通过强化学习进行训练。 ChatGPT目前仍以文字方式交互，而除了可以通过人类自然对话方式进行交互，还可以用于相对复杂的语言工作，包括自动文本生成、自动问答、自动摘要等在内的多种任务。如：在自动文本生成方面，ChatGPT可以根据输入的文本自动生成类似的文本（剧本、歌曲、企划等），在自动问答方面，ChatGPT可以根据输入的问题自动生成答案。还具有编写和调试计算机程序的能力。在推广期间，所有人可以免费注册，并在登录后免费使用ChatGPT实现与AI机器人对话。由于一些原因，大陆尚未能够访问这个有趣且强大的对话机器人。有人敏锐地识别到了商机，做起了微信聊天机器人，并做了商业化变现，据说部分粉丝多的号，成功变现超百万元。ChatGPT机器人有哪些依托于微信生态的： 微信订阅号（公众号） 微信服务号（公众号） 微信小程序依托于公司企业微信的： 企业微信机器人，服务于公司内部用户依托于开源生态： 如做成VSCode插件，做自动coding、代码检查、bug修复等功能。散兵游勇： 自建web，通过不同渠道引流如何做ChatGPT机器人 无法直接访问chat.openai.com的现成客户端，如微信：在一台能够访问chat.openai.com的服务器，租用云虚拟机或者云函数平台，运行一个机器人，这个机器人接受来自微信的请求，随后将请求forward到chat.openai.com，随后将从chat.openai.com返回的结果发回给微信。 自建的web：在一台能够访问chat.openai.com的服务器，租用云虚拟机。搭建web系统，后台为chat.openai.com api，前台自行定制。 总结总之，ChatGPT这阵风，很多商业大佬都开始惊慌了，纷纷all in。" }, { "title": "AI对话-额度提升", "url": "/posts/ai-quota/", "categories": "ai-posts", "tags": "formatting, links", "date": "2023-02-26 06:44:16 +0000", "snippet": "说明额度提升说明一、转账前，请在“AI拯救世界”公众号发送 id 查看id号二、转账时，请备注id号AI对话说明一、因openai服务器经常满载，问的问题可能处理时间很久导致超时，可能需要重新提问。二、如遇到问题，请在本帖回复，技术小哥会抽空复现并着手解决。三、本公众号关注人数较多，技术小哥在努力思考如何提升用户并发数量，敬请期待。入门套餐30次特惠体验卡：原价14.9元，活动价9.99元。...", "content": "说明额度提升说明一、转账前，请在“AI拯救世界”公众号发送 id 查看id号二、转账时，请备注id号AI对话说明一、因openai服务器经常满载，问的问题可能处理时间很久导致超时，可能需要重新提问。二、如遇到问题，请在本帖回复，技术小哥会抽空复现并着手解决。三、本公众号关注人数较多，技术小哥在努力思考如何提升用户并发数量，敬请期待。入门套餐30次特惠体验卡：原价14.9元，活动价9.99元。经济套餐128次特惠体验卡：原价49.9元，活动价19.99元。豪华套餐298次特惠体验卡：原价69.9元，活动价49.99元。" }, { "title": "a new test post", "url": "/posts/a-more-new-test-post/", "categories": "sample-posts", "tags": "formatting, links", "date": "2023-02-26 06:40:16 +0000", "snippet": "这是又一篇新的测试博客文章。", "content": "这是又一篇新的测试博客文章。" }, { "title": "a new test post", "url": "/posts/a-new-test-post/", "categories": "sample-posts", "tags": "formatting, links", "date": "2023-02-26 06:28:16 +0000", "snippet": "这是一篇新的测试博客文章。", "content": "这是一篇新的测试博客文章。" }, { "title": "a post with giscus comments", "url": "/posts/giscus-comments/", "categories": "sample-posts, external-services", "tags": "", "date": "2022-12-10 15:59:00 +0000", "snippet": "This post shows how to add GISCUS comments.", "content": "This post shows how to add GISCUS comments." }, { "title": "Spack教程（基础）", "url": "/posts/spack-tutorial-basics/", "categories": "icenv", "tags": "spack", "date": "2022-11-07 02:42:00 +0000", "snippet": "准备注：本教程均在Ubuntu:20.04镜像下演示。获取镜像并运行，[wanlinwang@VM-119-18-tencentos ~]$ docker pull ubuntu:22.0422.04: Pulling from library/ubuntuaece8493d397: Pull complete Digest: sha256:2b7412e6465c3c7fc5bb21d3e...", "content": "准备注：本教程均在Ubuntu:20.04镜像下演示。获取镜像并运行，[wanlinwang@VM-119-18-tencentos ~]$ docker pull ubuntu:22.0422.04: Pulling from library/ubuntuaece8493d397: Pull complete Digest: sha256:2b7412e6465c3c7fc5bb21d3e6f1917c167358449fecac8176c6e496e5c1f05fStatus: Downloaded newer image for ubuntu:22.04docker.io/library/ubuntu:22.04[wanlinwang@VM-119-18-tencentos ~]$ docker run -ti ubuntu:22.04root@284b243a39ec:/# cdroot@284b243a39ec:~#安装相关依赖包（其中git用来与git仓库交互，python3用作spack的解析器，gcc gfortran fort77 g++ clang用作spack构建工具时的编译器，make构建），root@284b243a39ec:~# apt updateroot@284b243a39ec:~# apt install git python3root@284b243a39ec:~# apt install gcc gfortran fort77 g++ clangroot@284b243a39ec:~# apt install make下载spack，root@284b243a39ec:~# git clone --depth=100 --branch=releases/v0.20 https://github.com/spack/spack.git ~/spackCloning into '/root/spack'...remote: Enumerating objects: 19032, done.remote: Counting objects: 100% (19032/19032), done.remote: Compressing objects: 100% (10494/10494), done.remote: Total 19032 (delta 2022), reused 12091 (delta 1506), pack-reused 0Receiving objects: 100% (19032/19032), 12.33 MiB | 15.21 MiB/s, done.Resolving deltas: 100% (2022/2022), done.root@284b243a39ec:~# cd ~/spack初始化，root@284b243a39ec:~/spack# . share/spack/setup-env.shroot@284b243a39ec:~/spack# spack compiler find上手spack list查看所有可用的包，root@284b243a39ec:~/spack# spack listspack list支持查询语句root@284b243a39ec:~/spack# spack list pytho* #前缀匹配查询python==&gt; 1 packagesroot@284b243a39ec:~/spack# spack list pytho #模糊匹配查询py-antlr4-python3-runtime py-ipython py-mysql-connector-python py-python-constraint py-python-engineio py-python-jose py-python-louvain py-python-memcached py-python-socketio py-python3-openid py-systemd-pythonpy-avro-python3 py-ipython-cluster-helper py-openslide-python py-python-crfsuite py-python-fmask py-python-json-logger py-python-lsp-jsonrpc py-python-multipart py-python-sotools py-python3-xlib py-types-python-dateutilpy-biopython py-ipython-genutils py-psij-python py-python-daemon py-python-fsutil py-python-keystoneclient py-python-lsp-server py-python-oauth2 py-python-subunit py-pythonqwt py-wxpythonpy-bx-python py-kb-python py-python-benedict py-python-dateutil py-python-gitlab py-python-ldap py-python-lzo py-python-picard py-python-swiftclient py-pythonsollya pythonpy-dnspython py-meson-python py-python-bioformats py-python-docs-theme py-python-igraph py-python-levenshtein py-python-magic py-python-ptrace py-python-utils py-saga-python r-findpythonpy-gitpython py-mkdocstrings-python py-python-box py-python-dotenv py-python-javabridge py-python-libsbml py-python-mapnik py-python-rapidjson py-python-xlib py-scientificpython xtensor-pythonpy-google-api-python-client py-mmtf-python py-python-certifi-win32 py-python-editor py-python-jenkins py-python-logstash py-python-markdown-math py-python-slugify py-python-xmp-toolkit py-spython==&gt; 76 packages安装一个包，命名spack install &lt;package_name&gt;root@284b243a39ec:~/spack# spack install zlib==&gt; Installing zlib-1.2.13-ivmy4r5hq6uijii4yspbffl2dutqdxgb==&gt; No binary for zlib-1.2.13-ivmy4r5hq6uijii4yspbffl2dutqdxgb found: installing from source==&gt; Using cached archive: /root/spack/var/spack/cache/_source-cache/archive/b3/b3a24de97a8fdbc835b9833169501030b8977031bcb54b3b3ac13740f846ab30.tar.gz==&gt; No patches needed for zlib==&gt; zlib: Executing phase: 'edit'==&gt; zlib: Executing phase: 'build'==&gt; zlib: Executing phase: 'install'==&gt; zlib: Successfully installed zlib-1.2.13-ivmy4r5hq6uijii4yspbffl2dutqdxgb Stage: 0.04s. Edit: 0.38s. Build: 0.61s. Install: 0.05s. Post-install: 0.02s. Total: 1.12s[+] /root/spack/opt/spack/linux-ubuntu22.04-cascadelake/gcc-11.4.0/zlib-1.2.13-ivmy4r5hq6uijii4yspbffl2dutqdxgbSpack安装包时，支持从源码安装，或者从二进制缓存安装。二进制缓存的安全，由GPG签名保证。root@284b243a39ec:~/spack# spack mirror add tutorial /mirrorroot@284b243a39ec:~/spack# spack buildcache keys --install --trust==&gt; Fetching file:///mirror/build_cache/_pgp/0ACDCFDA91DB974A68C3DDC2F85815B32355CB19.pubgpg: key F85815B32355CB19: public key \"e4s-uo-spack-01\" importedgpg: Total number processed: 1gpg:\t\t imported: 1gpg: inserting ownertrust of 6==&gt; Fetching file:///mirror/build_cache/_pgp/2C8DD3224EF3573A42BD221FA8E0CA3C1C2ADA2F.pubgpg: key A8E0CA3C1C2ADA2F: 5 signatures not checked due to missing keysgpg: key A8E0CA3C1C2ADA2F: public key \"Spack Project Official Binaries &lt;maintainers@spack.io&gt;\" importedgpg: Total number processed: 1gpg:\t\t imported: 1gpg: marginals needed: 3 completes needed: 1 trust model: pgpgpg: depth: 0 valid:\t1 signed: 0\ttrust: 0-, 0q, 0n, 0m, 0f, 1ugpg: inserting ownertrust of 6==&gt; Fetching file:///mirror/build_cache/_pgp/78F3726939CA1B94893B66E8BC86F6FB94429164.pubgpg: key A8E0CA3C1C2ADA2F: 7 signatures not checked due to missing keysgpg: key A8E0CA3C1C2ADA2F: \"Spack Project Official Binaries &lt;maintainers@spack.io&gt;\" 3 new signaturesgpg: key A8E0CA3C1C2ADA2F: \"Spack Project Official Binaries &lt;maintainers@spack.io&gt;\" 1 new subkeygpg: Total number processed: 1gpg:\t\tnew subkeys: 1gpg:\t new signatures: 3gpg: marginals needed: 3 completes needed: 1 trust model: pgpgpg: depth: 0 valid:\t2 signed: 0\ttrust: 0-, 0q, 0n, 0m, 0f, 2uspack install zlib %clang==&gt; Installing zlib-1.2.13-gephbceg3rl2e77o46xyzlk5e4kd3gt3==&gt; Fetching file:///mirror/build_cache/linux-ubuntu22.04-x86_64_v3-clang-14.0.0-zlib-1.2.13-gephbceg3rl2e77o46xyzlk5e4kd3gt3.spec.json.sig==&gt; Fetching file:///mirror/build_cache/linux-ubuntu22.04-x86_64_v3/clang-14.0.0/zlib-1.2.13/linux-ubuntu22.04-x86_64_v3-clang-14.0.0-zlib-1.2.13-gephbceg3rl2e77o46xyzlk5e4kd3gt3.spack==&gt; Extracting zlib-1.2.13-gephbceg3rl2e77o46xyzlk5e4kd3gt3 from binary cache==&gt; zlib: Successfully installed zlib-1.2.13-gephbceg3rl2e77o46xyzlk5e4kd3gt3 Search: 0.00s. Fetch: 0.11s. Install: 0.02s. Total: 0.13s[+] /root/spack/opt/spack/linux-ubuntu22.04-x86_64_v3/clang-14.0.0/zlib-1.2.13-gephbceg3rl2e77o46xyzlk5e4kd3gt3在运行安装命令前，可以先查看有哪些版本，root@284b243a39ec:~/spack# spack versions zlib==&gt; Safe versions (already checksummed): 1.2.13 1.2.12 1.2.11 1.2.8 1.2.3==&gt; Remote versions (not yet checksummed): 1.3 1.2.9 1.2.7.2 1.2.7 1.2.6 1.2.5.2 1.2.5 1.2.4.4 1.2.4.2 1.2.4 1.2.3.8 1.2.3.6 1.2.3.4 1.2.3.2 1.2.2.4 1.2.2.2 1.2.2 1.2.1.1 1.2.0.8 1.2.0.6 1.2.0.4 1.2.0.2 1.2.0 1.1.3 1.1.1 1.0.9 1.0.7 1.0.5 1.0.2 1.0-pre 0.95 0.93 0.91 0.71 0.8 1.2.10 1.2.7.3 1.2.7.1 1.2.6.1 1.2.5.3 1.2.5.1 1.2.4.5 1.2.4.3 1.2.4.1 1.2.3.9 1.2.3.7 1.2.3.5 1.2.3.3 1.2.3.1 1.2.2.3 1.2.2.1 1.2.1.2 1.2.1 1.2.0.7 1.2.0.5 1.2.0.3 1.2.0.1 1.1.4 1.1.2 1.1.0 1.0.8 1.0.6 1.0.4 1.0.1 0.99 0.94 0.92 0.79 0.9安装时，可以传编译器flags，如cppflags, cflags, cxxflags, fflags, ldflags, 与 ldlibs 参数。root@284b243a39ec:~/spack# spack install zlib@1.2.8 cflags=-O3==&gt; Warning: using \"zlib@1.2.8\" which is a deprecated version==&gt; Installing zlib-1.2.8-5o535gi4wwtrfcb3jcilmuelp57hnyxq==&gt; No binary for zlib-1.2.8-5o535gi4wwtrfcb3jcilmuelp57hnyxq found: installing from source==&gt; Warning: zlib@1.2.8 is deprecated and may be removed in a future Spack release.==&gt; Fetch anyway? [y/N] y==&gt; Fetching https://mirror.spack.io/_source-cache/archive/36/36658cb768a54c1d4dec43c3116c27ed893e88b02ecfcb44f2166f9c0b7f2a0d.tar.gz==&gt; No patches needed for zlib==&gt; zlib: Executing phase: 'edit'==&gt; zlib: Executing phase: 'build'==&gt; zlib: Executing phase: 'install'==&gt; zlib: Successfully installed zlib-1.2.8-5o535gi4wwtrfcb3jcilmuelp57hnyxq Stage: 44.96s. Edit: 0.38s. Build: 0.56s. Install: 0.07s. Post-install: 0.02s. Total: 46.01s[+] /root/spack/opt/spack/linux-ubuntu22.04-cascadelake/gcc-11.4.0/zlib-1.2.8-5o535gi4wwtrfcb3jcilmuelp57hnyxqspack find查看已安装的包，root@284b243a39ec:~/spack# spack find-- linux-ubuntu22.04-cascadelake / clang@14.0.0 -----------------zlib@1.2.12 zlib@1.2.13-- linux-ubuntu22.04-cascadelake / gcc@11.4.0 -------------------zlib@1.2.8 zlib@1.2.13==&gt; 4 installed packagesroot@284b243a39ec:~/spack# spack find -lf-- linux-ubuntu22.04-cascadelake / clang@14.0.0 -----------------phqllhi zlib@1.2.12%clang r5taitb zlib@1.2.13%clang -- linux-ubuntu22.04-cascadelake / gcc@11.4.0 -------------------5o535gi zlib@1.2.8%gcc cflags=\"-O3\" ivmy4r5 zlib@1.2.13%gcc ==&gt; 4 installed packagesSpack为每个spec都生成一个hash，任何不同版本组合都生成唯一的hash。root@284b243a39ec:~/spack# spack install tcl[+] /root/spack/opt/spack/linux-ubuntu22.04-cascadelake/gcc-11.4.0/zlib-1.2.13-ivmy4r5hq6uijii4yspbffl2dutqdxgb==&gt; Installing tcl-8.6.12-m2wnkqeddps4xf5oyrxqd6i3lrvokfwp==&gt; No binary for tcl-8.6.12-m2wnkqeddps4xf5oyrxqd6i3lrvokfwp found: installing from source==&gt; Fetching https://mirror.spack.io/_source-cache/archive/26/26c995dd0f167e48b11961d891ee555f680c175f7173ff8cb829f4ebcde4c1a6.tar.gz==&gt; No patches needed for tcl==&gt; tcl: Executing phase: 'autoreconf'==&gt; tcl: Executing phase: 'configure'==&gt; tcl: Executing phase: 'build'==&gt; tcl: Executing phase: 'install'==&gt; tcl: Successfully installed tcl-8.6.12-m2wnkqeddps4xf5oyrxqd6i3lrvokfwp Stage: 14.43s. Autoreconf: 0.00s. Configure: 5.85s. Build: 1m 2.43s. Install: 3.53s. Post-install: 0.59s. Total: 1m 26.86s[+] /root/spack/opt/spack/linux-ubuntu22.04-cascadelake/gcc-11.4.0/tcl-8.6.12-m2wnkqeddps4xf5oyrxqd6i3lrvokfwp使用^指定依赖root@284b243a39ec:~/spack# spack install tcl ^zlib@1.2.13 %clang[+] /root/spack/opt/spack/linux-ubuntu22.04-cascadelake/clang-14.0.0/zlib-1.2.13-r5taitbmvh5nzn2jqjo2f2mignhvrabe==&gt; Installing tcl-8.6.12-lgob6rq7jo5q3dyd2qfhyrs3nk6ggpqe==&gt; No binary for tcl-8.6.12-lgob6rq7jo5q3dyd2qfhyrs3nk6ggpqe found: installing from source==&gt; Using cached archive: /root/spack/var/spack/cache/_source-cache/archive/26/26c995dd0f167e48b11961d891ee555f680c175f7173ff8cb829f4ebcde4c1a6.tar.gz==&gt; No patches needed for tcl==&gt; tcl: Executing phase: 'autoreconf'==&gt; tcl: Executing phase: 'configure'==&gt; tcl: Executing phase: 'build'==&gt; tcl: Executing phase: 'install'==&gt; tcl: Successfully installed tcl-8.6.12-lgob6rq7jo5q3dyd2qfhyrs3nk6ggpqe Stage: 0.36s. Autoreconf: 0.00s. Configure: 10.13s. Build: 1m 13.37s. Install: 3.34s. Post-install: 0.58s. Total: 1m 27.82s[+] /root/spack/opt/spack/linux-ubuntu22.04-cascadelake/clang-14.0.0/tcl-8.6.12-lgob6rq7jo5q3dyd2qfhyrs3nk6ggpqe使用^/5o5指定依赖的hash。如上所示，其中5o5是zlib@1.2.8%gcc的hash。root@284b243a39ec:~/spack# spack install tcl ^/5o5[+] /root/spack/opt/spack/linux-ubuntu22.04-cascadelake/gcc-11.4.0/zlib-1.2.8-5o535gi4wwtrfcb3jcilmuelp57hnyxq==&gt; Installing tcl-8.6.12-o6wvao34ytjgbpy2kpf63x4c34wn45ub==&gt; No binary for tcl-8.6.12-o6wvao34ytjgbpy2kpf63x4c34wn45ub found: installing from source==&gt; Using cached archive: /root/spack/var/spack/cache/_source-cache/archive/26/26c995dd0f167e48b11961d891ee555f680c175f7173ff8cb829f4ebcde4c1a6.tar.gz==&gt; No patches needed for tcl==&gt; tcl: Executing phase: 'autoreconf'==&gt; tcl: Executing phase: 'configure'==&gt; tcl: Executing phase: 'build'==&gt; tcl: Executing phase: 'install'==&gt; tcl: Successfully installed tcl-8.6.12-o6wvao34ytjgbpy2kpf63x4c34wn45ub Stage: 0.35s. Autoreconf: 0.00s. Configure: 6.08s. Build: 1m 1.70s. Install: 3.45s. Post-install: 0.59s. Total: 1m 12.21s[+] /root/spack/opt/spack/linux-ubuntu22.04-cascadelake/gcc-11.4.0/tcl-8.6.12-o6wvao34ytjgbpy2kpf63x4c34wn45ubspack find还支持-d，用来显示依赖关系。root@284b243a39ec:~/spack# spack find -ldf-- linux-ubuntu22.04-cascadelake / clang@14.0.0 -----------------lgob6rq tcl@8.6.12%clang r5taitb zlib@1.2.13%clang phqllhi zlib@1.2.12%clang r5taitb zlib@1.2.13%clang -- linux-ubuntu22.04-cascadelake / gcc@11.4.0 -------------------o6wvao3 tcl@8.6.12%gcc 5o535gi zlib@1.2.8%gcc cflags=\"-O3\" m2wnkqe tcl@8.6.12%gcc ivmy4r5 zlib@1.2.13%gcc 5o535gi zlib@1.2.8%gcc cflags=\"-O3\" ivmy4r5 zlib@1.2.13%gcc ==&gt; 7 installed packages我们来安装一个更复杂的包——HDF5，默认情况下，会将MPI依赖也装上。root@284b243a39ec:~/spack# spack install hdf5[+] /root/spack/opt/spack/linux-ubuntu22.04-cascadelake/gcc-11.4.0/libpciaccess-0.17-pykx2euy2awtgyou2nnsjl2s6hi4n646[+] /root/spack/opt/spack/linux-ubuntu22.04-cascadelake/gcc-11.4.0/libiconv-1.17-yodoqmhmvqbqvjzl3s6snnatz6trv7iy[+] /root/spack/opt/spack/linux-ubuntu22.04-cascadelake/gcc-11.4.0/xz-5.4.1-dzgxjank6ou2hybibf5ub262lgc2lorn[+] /root/spack/opt/spack/linux-ubuntu22.04-cascadelake/gcc-11.4.0/zlib-1.2.13-ivmy4r5hq6uijii4yspbffl2dutqdxgb[+] /root/spack/opt/spack/linux-ubuntu22.04-cascadelake/gcc-11.4.0/ncurses-6.4-ujngusmjurwe2fa7l3b6kvt73gabtuor[+] /root/spack/opt/spack/linux-ubuntu22.04-cascadelake/gcc-11.4.0/numactl-2.0.14-r22sabf66foyohnzrm2vhslqhyvzaodc[+] /root/spack/opt/spack/linux-ubuntu22.04-cascadelake/gcc-11.4.0/bzip2-1.0.8-ddoyjf47vjlyagfc22epabwym5pymdr7[+] /root/spack/opt/spack/linux-ubuntu22.04-cascadelake/gcc-11.4.0/zstd-1.5.5-5e3alsszldfqzfm4bln3x2bxo63lgc5h[+] /root/spack/opt/spack/linux-ubuntu22.04-cascadelake/gcc-11.4.0/libxcrypt-4.4.33-gei6nykcbdwqnwkbtaapysokbdy5hsa5[+] /root/spack/opt/spack/linux-ubuntu22.04-cascadelake/gcc-11.4.0/pkgconf-1.9.5-sxbb6ve36mznc2trrpk4llouoi47yqlm[+] /root/spack/opt/spack/linux-ubuntu22.04-cascadelake/gcc-11.4.0/pigz-2.7-5gemoganu6n6ps7aca4llw5txrxgwcm7[+] /root/spack/opt/spack/linux-ubuntu22.04-cascadelake/gcc-11.4.0/openssl-1.1.1t-vmachqinwttmfsngz56nzjlsdxpvp7ki[+] /root/spack/opt/spack/linux-ubuntu22.04-cascadelake/gcc-11.4.0/libedit-3.1-20210216-d7fgamjkvusfpwqhdevl5u3ld2ajwelz[+] /root/spack/opt/spack/linux-ubuntu22.04-cascadelake/gcc-11.4.0/libxml2-2.10.3-5mmkszwox2ca75c274cebzp7yizhvant[+] /root/spack/opt/spack/linux-ubuntu22.04-cascadelake/gcc-11.4.0/tar-1.34-tfgqkhebvyigwree5sh4jxtt2r6ebkhn[+] /root/spack/opt/spack/linux-ubuntu22.04-cascadelake/gcc-11.4.0/libevent-2.1.12-zt3qad4mu4mlsfmedkakxw7ue4ekrudc[+] /root/spack/opt/spack/linux-ubuntu22.04-cascadelake/gcc-11.4.0/hwloc-2.9.1-fcfzcph73hlkt23vthevpninsi7jbfdp[+] /root/spack/opt/spack/linux-ubuntu22.04-cascadelake/gcc-11.4.0/gettext-0.21.1-y3smi3ultsqlwsrwzcykwzl52h4eekhg[+] /root/spack/opt/spack/linux-ubuntu22.04-cascadelake/gcc-11.4.0/pmix-4.2.3-h55tf5zun6v6kxuszej6imea7sfb7lku[+] /root/spack/opt/spack/linux-ubuntu22.04-cascadelake/gcc-11.4.0/krb5-1.20.1-imoj7v4sveupl2komhnb655d3jjxeyez[+] /root/spack/opt/spack/linux-ubuntu22.04-cascadelake/gcc-11.4.0/openssh-9.3p1-pi6fj3d4bnbsvdzjygatwmeppme2e57o[+] /root/spack/opt/spack/linux-ubuntu22.04-cascadelake/gcc-11.4.0/openmpi-4.1.5-z2lpbjfjf72tikfaxfuq7keby327rang==&gt; Installing hdf5-1.14.1-2-gqyhwfo3iyea3sdekxcolo5qrnnuzlqn==&gt; No binary for hdf5-1.14.1-2-gqyhwfo3iyea3sdekxcolo5qrnnuzlqn found: installing from source==&gt; Fetching https://mirror.spack.io/_source-cache/archive/cb/cbe93f275d5231df28ced9549253793e40cd2b555e3d288df09d7b89a9967b07.tar.gz==&gt; Ran patch() for hdf5==&gt; hdf5: Executing phase: 'cmake'==&gt; hdf5: Executing phase: 'build'==&gt; hdf5: Executing phase: 'install'==&gt; hdf5: Successfully installed hdf5-1.14.1-2-gqyhwfo3iyea3sdekxcolo5qrnnuzlqn Stage: 31.03s. Cmake: 11.47s. Build: 30.78s. Install: 0.90s. Post-install: 0.20s. Total: 1m 14.55s[+] /root/spack/opt/spack/linux-ubuntu22.04-cascadelake/gcc-11.4.0/hdf5-1.14.1-2-gqyhwfo3iyea3sdekxcolo5qrnnuzlqnSpack包也有build选项，通过+或~/-root@284b243a39ec:~/spack# spack install hdf5~mpi[+] /root/spack/opt/spack/linux-ubuntu22.04-cascadelake/gcc-11.4.0/ncurses-6.4-ujngusmjurwe2fa7l3b6kvt73gabtuor[+] /root/spack/opt/spack/linux-ubuntu22.04-cascadelake/gcc-11.4.0/zlib-1.2.13-ivmy4r5hq6uijii4yspbffl2dutqdxgb[+] /root/spack/opt/spack/linux-ubuntu22.04-cascadelake/gcc-11.4.0/gmake-4.4.1-264topq36ww6abmwthbd7pouu65v7nwm[+] /root/spack/opt/spack/linux-ubuntu22.04-cascadelake/gcc-11.4.0/pkgconf-1.9.5-sxbb6ve36mznc2trrpk4llouoi47yqlm[+] /root/spack/opt/spack/linux-ubuntu22.04-cascadelake/gcc-11.4.0/openssl-1.1.1t-vmachqinwttmfsngz56nzjlsdxpvp7ki[+] /root/spack/opt/spack/linux-ubuntu22.04-cascadelake/gcc-11.4.0/cmake-3.26.3-ttvpnusqvmowfgfwiwil7dgkmkjaiqp5==&gt; Installing hdf5-1.14.1-2-thweeqbqmd7uqugx6iswe56zarcgg554==&gt; No binary for hdf5-1.14.1-2-thweeqbqmd7uqugx6iswe56zarcgg554 found: installing from source==&gt; Using cached archive: /root/spack/var/spack/cache/_source-cache/archive/cb/cbe93f275d5231df28ced9549253793e40cd2b555e3d288df09d7b89a9967b07.tar.gz==&gt; Ran patch() for hdf5==&gt; hdf5: Executing phase: 'cmake'==&gt; hdf5: Executing phase: 'build'==&gt; hdf5: Executing phase: 'install'==&gt; hdf5: Successfully installed hdf5-1.14.1-2-thweeqbqmd7uqugx6iswe56zarcgg554 Stage: 0.83s. Cmake: 10.69s. Build: 27.12s. Install: 0.88s. Post-install: 0.18s. Total: 39.84s[+] /root/spack/opt/spack/linux-ubuntu22.04-cascadelake/gcc-11.4.0/hdf5-1.14.1-2-thweeqbqmd7uqugx6iswe56zarcgg554Spack还可以通过^来指定依赖root@284b243a39ec:~/spack# spack install hdf5+hl+mpi ^mpichSpack可以打印依赖的单向无环图(DAG)spack graph hdf5+hl+mpi ^mpich再安装一个更复杂的，spack install trilinos这个直接依赖有23个，依赖又有自己的依赖。经验丰富的用户可能也需要花几天、几周来完成，而spack一条命令几秒钟搞定。DAG输出到PDF文件，spack graph --dot trilinos | dot -Tpdf &gt; trilinos_graph.pdfuninstall包spack uninstallspack find也支持高级查询，包括spack find ^mpich #查询依赖mpich的包spack find cflags=-O3 #查询带这个编译选项的将spack安装的gcc加入spack编译器列表里，spack compiler add \"$(spack location -i gcc@12)\"将gcc编译器移出spack编译器列表，spack compiler remove gcc@12" }, { "title": "会议有感", "url": "/posts/meetings/", "categories": "career", "tags": "post", "date": "2022-09-13 23:15:00 +0000", "snippet": "会议有感领导是帮助大家将事情做成的人，千万不要将领导看成是高人一等的角色，而是看成是可以求助的伙伴，要资源，要帮助，就说服领导，把事情做成。我们做的事情很有意义，放长远来看，对社会、对公司、对个人都是很有意义的。当前的待遇都是临时的。大家可以将现在做的事，想成是为下一份工作简历，努力做好，充实简历。当然了，留在公司一直做下去也是最好的。我们技术人要保持单纯，就事论事，会议上给大家提了很多批评...", "content": "会议有感领导是帮助大家将事情做成的人，千万不要将领导看成是高人一等的角色，而是看成是可以求助的伙伴，要资源，要帮助，就说服领导，把事情做成。我们做的事情很有意义，放长远来看，对社会、对公司、对个人都是很有意义的。当前的待遇都是临时的。大家可以将现在做的事，想成是为下一份工作简历，努力做好，充实简历。当然了，留在公司一直做下去也是最好的。我们技术人要保持单纯，就事论事，会议上给大家提了很多批评与建议，希望大家不要太介意。有问题，有建议就提出来，千万不要藏着掖着。有大家齐心协力才能完成这么重要的工作，任何一个单人都无法完成这种事业。大家一起继续努力。监控中，大部分正常的数据，都是没有价值的。我们如何识别并留存有效的数据，是需要特别关注的。" }, { "title": "软件采购的一些总结", "url": "/posts/it-purcurment-guide/", "categories": "it", "tags": "post", "date": "2022-09-11 02:37:14 +0000", "snippet": "软件采购大小公司在年末时会收集来年的各种预算，其中IT的无形资产，如软件也包括在内。那么软件采购，需要注意哪些点呢?以采购MATLAB为例子: 需求厘清业务反馈的需求，需要与软件供应商仔细核对，确保需求与供应匹配，如购买MATLAB，它涉及到的有MATLAB RUNTIME， MATLAB以及100多个Toolbox。如果是合作伙伴将写好的MATLAB程序编译好，提供给你使用，这时...", "content": "软件采购大小公司在年末时会收集来年的各种预算，其中IT的无形资产，如软件也包括在内。那么软件采购，需要注意哪些点呢?以采购MATLAB为例子: 需求厘清业务反馈的需求，需要与软件供应商仔细核对，确保需求与供应匹配，如购买MATLAB，它涉及到的有MATLAB RUNTIME， MATLAB以及100多个Toolbox。如果是合作伙伴将写好的MATLAB程序编译好，提供给你使用，这时可以确认下是否仅需使用到MATLAB RUNTIME，如果是则不需要购买;此外，由于业务反馈如仅需要使用Computer Vision Toolbox的Toolbox，但与厂商支持人员确认它会依赖于另两个包MATLAB与Image Processing Toolbox。 许可与维保 按年/月付费租用，到期续费，不续费则终止使用。 一次性买断，首年赠送技术支持与软件升级。次年开始支付原价10%作为维保，获得技术支持与软件升级。维保过期后隔一段时间再想购买维保，则需补足未缴维保，并重启费用方可续保。价格约为前者的2.5倍。 价格税率调研时，需向销售了解清楚，报价是否含税。否则申请预算时审批下来后，发现未含税，再要去申请审批就为难领导了。 许可方式固定版: 固定版，被授权的license只能绑定在某个员工或某台机器上。如有变动，则需要请厂商协助。维保期内一年最多四次。 管理员授权版:管理员手动指定使用的人。Floating版:动态占用与释放前两种价格相似，最后一种最方便，价格约前两种的4倍。" }, { "title": "strace与perf trace", "url": "/posts/tracing-dd-commnd/", "categories": "linux", "tags": "post", "date": "2022-09-05 22:15:00 +0000", "snippet": "Stracestrace是众所周知的系统调用追踪工具。由于它依赖于ptrace暂停应用来获取系统调用的相关信息，这导致在使用strace过程中非常差的性能。在strace过程中，每个系统调用会暂停两次：一次是进入系统调用、一次是离开系统调用。perf traceperf trace使用trace points来收集系统调用信息，在tracing过程中，应用无需被暂停。此外，perf trac...", "content": "Stracestrace是众所周知的系统调用追踪工具。由于它依赖于ptrace暂停应用来获取系统调用的相关信息，这导致在使用strace过程中非常差的性能。在strace过程中，每个系统调用会暂停两次：一次是进入系统调用、一次是离开系统调用。perf traceperf trace使用trace points来收集系统调用信息，在tracing过程中，应用无需被暂停。此外，perf trace还扩展到使用eBPF程序来做syscall参数追踪。案例" }, { "title": "如何安装GCC？", "url": "/posts/how-to-install-gcc/", "categories": "linux, spack", "tags": "post", "date": "2022-09-02 22:15:00 +0000", "snippet": "安装GCC./configure --prefix=/path/to/gccmakemake install相信大家在Linux下安装GCC都是一个难忘的回忆。笔者也经历过缺依赖，编好几个小时才发现错误。重读文档文档中描述，安装GCC是有几个必要依赖的，它们是GMP, MPFR and MPC。 If it provides sufficiently recent versions, us...", "content": "安装GCC./configure --prefix=/path/to/gccmakemake install相信大家在Linux下安装GCC都是一个难忘的回忆。笔者也经历过缺依赖，编好几个小时才发现错误。重读文档文档中描述，安装GCC是有几个必要依赖的，它们是GMP, MPFR and MPC。 If it provides sufficiently recent versions, use your OS package management system to install the support libraries in standard system locations. For Debian-based systems, including Ubuntu, you should install the packages libgmp-dev, libmpfr-dev and libmpc-dev. For RPM-based systems, including Fedora and SUSE, you should install gmp-devel, mpfr-devel and libmpc-devel (or mpc-devel on SUSE) packages. The packages will install the libraries and headers in standard system directories so they can be found automatically when building GCC. Alternatively, after extracting the GCC source archive, simply run the ./contrib/download_prerequisites script in the GCC source directory. That will download the support libraries and create symlinks, causing them to be built automatically as part of the GCC build process. Set GRAPHITE_LOOP_OPT=no in the script if you want to build GCC without ISL, which is only needed for the optional Graphite loop optimizations. The difficult way, which is not recommended, is to download the sources for GMP, MPFR and MPC, then configure and install each of them in non-standard locations, then configure GCC with –with-gmp=/some/silly/path/gmp –with-mpfr=/some/silly/path/mpfr –with-mpc=/some/silly/path/mpc, then be forced to set LD_LIBRARY_PATH=/some/silly/path/gmp/lib:/some/silly/path/mpfr/lib:/some/silly/path/mpc/lib in your environment forever. This is silly and causes major problems for anyone who doesn’t understand how dynamic linkers find libraries at runtime. Do not do this. If building GCC fails when using any of the –with-gmp or –with-mpfr or –with-mpc options then you probably shouldn’t be using them.如上面摘抄的所示，有三种方式可以将依赖准备好。 第一种是使用系统自带的包管理器，将依赖安装，这时这些依赖都将安装到系统默认的目录下； 第二种是执行GCC目录下的./contrib/download_prerequisites 脚本，将依赖的源码包下载下来，随GCC一起编译安装； 第三种，不推荐的方式，分别安装好，然后以--with-gmp=/some/silly/path/gmp --with-mpfr=/some/silly/path/mpfr --with-mpc=/some/silly/path/mpc 的这种方式指定。其他自动化方法 系统的包管理器安装GCC发行版的系统，均提供了自己的包管理器。CentOS提供了yum，Ubuntu提供了apt等等。使用操作系统自带的包管理器，可以很方便地将GCC安装上。缺点是，它只能安装包管理器仓库里提供的版本，不能随心所欲。 使用spack包管理器spack包管理器是一个强大的包管理器。安装开源库是一个NP问题，靠人工解决依赖很麻烦，像spack这种提前定义好依赖关系，自动生成单向无环图，可以一键完成人工要画几小时、几天甚至无法完成的依赖关系安装。 easybuild包管理器同spack一样，easybuild也是类似功能的包管理器。 其他案例左工的案例 https://mp.weixin.qq.com/s/vNfM571Gxw1UUIGgehZ1hQ" }, { "title": "如何禁止普通用户关闭lmgrd?", "url": "/posts/how-to-avoid-flexlm-license-server-being-shutdown-by-normal-users/", "categories": "license", "tags": "post", "date": "2022-08-30 22:47:00 +0000", "snippet": "问题License管理员以lmgrd启动的license进程，普通用户从本地或远程，能通过lmutil lmdown命令将其关闭掉。不仅如此，普通用户还有权限运行lmutil的子命令lmreread与lmremove命令。真是头大，普通用户权限咋这么大？解决通过查资料可以看到，有两种选项能够使得lmgrd的运行更安全。 方法一启动lmgrd时，加上-local选项，限制lmdown与lmr...", "content": "问题License管理员以lmgrd启动的license进程，普通用户从本地或远程，能通过lmutil lmdown命令将其关闭掉。不仅如此，普通用户还有权限运行lmutil的子命令lmreread与lmremove命令。真是头大，普通用户权限咋这么大？解决通过查资料可以看到，有两种选项能够使得lmgrd的运行更安全。 方法一启动lmgrd时，加上-local选项，限制lmdown与lmreread命令只能从运行lmgrd的这台机器上发起。由于限制了使用机器，如果license机器是专用机器，则这样就很安全了。如果license机器不是专用机器，则方法一也不够安全，则继续看方法二。 方法二启动lmgrd时，加上-2 -p选项，限制默认为root用户的 FLEXlm 管理员使用 lmdown、lmreread 和 lmremove。如果存在一个名为“lmadmin”的 Unix 组，则限制该组的成员使用。如果超级用户不是该组的成员，则该帐户无法使用上述任何实用程序。“-p”选项可以在 FLEXlm v2.4 以及更高版本中使用。由于方法二是赋予操作权限给指定用户或组，它没有限制机器，因此在保证安全的前提下，又给与了管理员足够的灵活性——不必专门登录到License机器来执行这三个命令。" }, { "title": "使用Python自动化运维ipset与iptables", "url": "/posts/operate-ipset-and-iptables-with-python/", "categories": "python", "tags": "post", "date": "2022-08-30 22:15:00 +0000", "snippet": "配置文件host-rules:- name: normal_computing conf: # 正式员工使用的研发运算机规则 type: ip need_create_ipset: true need_create_iptables: true hosts: # 主机列表 - 192.168.1.2 - 192.168.1.4 - 1...", "content": "配置文件host-rules:- name: normal_computing conf: # 正式员工使用的研发运算机规则 type: ip need_create_ipset: true need_create_iptables: true hosts: # 主机列表 - 192.168.1.2 - 192.168.1.4 - 172.31.86.213 - 192.168.1.5 input: # INPUT方向规则 - dport: 22,5600 peer: # INPUT方向规则的来源 - type: ipset value: normal_computing - type: ipset value: win_jump_server - type: ip value: 8.8.8.8 output: # OUTPUT方向规则 - peer: - type: ipset value: network_monitor_subnet - peer: - type: ipset value: domain_names - peer: - type: ipset value: normal_computing - peer: - type: ipset value: outsourcing_computing - peer: - type: ipset value: cfs - dport: 22 peer: - type: ipset value: normal_computing- name: network_monitor_subnet conf: type: ip,port need_create_ipset: true need_create_iptables: false hosts: - name: 192.168.100.1 port: tcp:8888 - name: outsourcing_computing conf: # 外包员工使用的研发运算机规则 type: ip need_create_ipset: true need_create_iptables: true hosts: # 主机列表 - 192.168.1.11 input: # INPUT方向规则 - dport: 22,5600 peer: # INPUT方向规则的来源 - type: ipset value: normal_computing - type: ipset value: win_jump_server- name: cadence_lic_hosts conf: # c家lic type: ip need_create_ipset: false need_create_iptables: true hosts: - 172.31.86.213 input: # INPUT方向规则 - dport: 3000,5280 peer: # INPUT方向规则的来源 - type: ipset value: normal_computing - type: ipset value: outsourcing_computing - type: ipset value: n_gate_subnets- name: svn_hosts conf: type: ip need_create_ipset: false need_create_iptables: true hosts: - 192.168.1.2 input: # INPUT方向规则 - dport: 1690:1697,1699 peer: # INPUT方向规则的来源 - type: ipset value: normal_computing - dport: 1698 peer: # INPUT方向规则的来源 - type: ipset value: outsourcing_computing- name: n_gate_subnets conf: type: net need_create_ipset: true need_create_iptables: false hosts: - 172.16.0.1/24 - 172.16.1.1/24- name: win_jump_server conf: type: ip need_create_ipset: true need_create_iptables: false hosts: - 1.1.1.1 - 1.1.1.2- name: jump_server conf: type: net need_create_ipset: true need_create_iptables: false hosts: - 2.2.2.0/24 - 2.2.3.0/24- name: cfs conf: type: ip,port need_create_ipset: true need_create_iptables: false hosts: - name: 1.2.3.4 port: tcp:111 - name: 1.2.3.4 port: tcp:2049- name: domain_names conf: type: dns,port need_create_ipset: true need_create_iptables: false hosts: - name: mirrors.tencent.com port: tcp:80 - name: mirrors.tecentyun.com port: tcp:443生成脚本\"\"\"Author: wanlinwangDate: 24-Aug-2022 19:00-23:00Description: 自动化维护iptables与ipset\"\"\"import yamlimport tempfilefrom netifaces import interfaces, ifaddresses, AF_INETimport subprocessimport reimport filecmpdef ip4_addresses(): ip_list = [] for interface in interfaces(): # 有些接口没有IP，使用try跳过它。 try: for link in ifaddresses(interface)[AF_INET]: ip=link['addr'] #去掉本地地址，去掉192.开头的私有地址。 if ip.startswith('192.') or ip == '127.0.0.1': continue ip_list.append(ip) except: pass return ip_listdef dig_domainname_to_ips(domain_name): entries = subprocess.run(['dig', '+short', domain_name], stdout=subprocess.PIPE) return entries.stdout.decode('utf-8')def check_if_ip(ip_str): if re.match(r\"^(\\d{1,3})\\.(\\d{1,3})\\.(\\d{1,3})\\.(\\d{1,3})$\", ip_str): return True else: return Falsedef create_ipset(set_name, entry_list, set_type, write_file): \"\"\" 生成ipset配置文件，应用命令如下： ipset restore -f ./ipset.conf --exist \"\"\" # print('entry_list', entry_list) if set_type == 'dns,port': set_type = 'ip,port' rst_list = [] for entry in entry_list: ip_list = dig_domainname_to_ips(entry['name']).split('\\n') ip_list.sort() for item in ip_list: # 只添加是ip的条目 if check_if_ip(item): rst_list.append(item + \",\" + entry['port']) entry_list = rst_list elif set_type == 'ip,port': rst_list = [] for entry in entry_list: rst_list.append(entry['name'] + \",\" + entry['port']) entry_list = rst_list set_tmp_name = set_name + \"_tmp\" print(f\"\"\"####################################################create {set_name} hash:{set_type} family inet hashsize 1024 maxelem 65536create {set_tmp_name} hash:{set_type} family inet hashsize 1024 maxelem 65536destroy {set_tmp_name}create {set_tmp_name} hash:{set_type} family inet hashsize 1024 maxelem 65536\\ \"\"\", file=write_file) for entry in entry_list: print(f\"add {set_tmp_name} {entry}\", file=write_file) print(f\"\"\"\\swap {set_tmp_name} {set_name}destroy {set_tmp_name}#################################################### \"\"\", file=write_file)def generate_iptables_entry(direction, ip_type, ips, ipset_dict, ports=None): entry = ['-A'] match_set_arg = '' if direction == 'input': entry.append('INPUT') if ip_type.startswith('ipset'): match_set_arg = 'src' elif direction == 'output': entry.append('OUTPUT') if ip_type.startswith('ipset'): match_set_arg = 'dst' if ipset_dict[ips] == 'ip,port': match_set_arg = 'dst,dst' else: print(f\"Error with {direction}\") entry.append(f'-p tcp') if ip_type == 'ip': entry.append(f'-s {ips}') elif ip_type.startswith('ipset'): entry.append(f'-m set --match-set {ips} {match_set_arg}') else: print(f'Error with ip_type {ip_type}') # if ip_type == 'ip': # entry.append(f'-s {ips}') # elif ip_type.startswith('ipset'): # ip_type = ip_type.replace('ipset,') # if ip_type == 'ip': # entry.append(f'-m set --match-set {ips} {match_set_arg}') # elif ip_type == 'ip,port': # entry.append(f'-m set --match-set {ips} dst,dst') # else: # print(f'Error with ip_type {ip_type}') if ports: if ip_type == 'ipset,ip,port': raise 'Conflict with ipset' entry.append(f'--dport {ports}') entry.append(f'-j ACCEPT') return ' '.join(entry)if __name__ == \"__main__\": ipset_conf_tmp = tempfile.NamedTemporaryFile(mode='w+', prefix='ipset.conf_', dir='./', delete=False) iptables_conf_tmp = tempfile.NamedTemporaryFile(mode='w+', prefix='iptables_', dir='./', delete=False) current_host_ips = ip4_addresses() print(\"current host ip\", current_host_ips) # 将默认开通的iptables条目先写上。 with open(\"./config.yml\", 'r') as yml: conf = yaml.safe_load(yml) # print(json.dumps(conf,indent=2)) # print(conf['host-rules']) ipset_type_dict = dict() for host_rule in conf['host-rules']: # print(json.dumps(host_rule, indent=2)) host_rule_name = host_rule['name'] host_rule_conf = host_rule['conf'] host_rule_conf_type = host_rule_conf['type'] # 步骤一：首先完成ipset的创建。Done if 'need_create_ipset' in host_rule_conf and host_rule_conf['need_create_ipset']: create_ipset(host_rule_name, host_rule_conf['hosts'], host_rule_conf_type, ipset_conf_tmp) if host_rule_conf_type == 'dns,port': host_rule_conf_type = 'ip,port' ipset_type_dict[host_rule_name] = host_rule_conf_type for host_rule in conf['host-rules']: host_rule_name = host_rule['name'] host_rule_conf = host_rule['conf'] # 步骤二：然后判断本机属于哪个rule下面，将对应的rule都生成一遍。TODO if 'need_create_iptables' in host_rule_conf and host_rule_conf['need_create_iptables']: for current_ip in current_host_ips: # print(host_rule_conf) # print(host_rule_conf['hosts']) if 'hosts' not in host_rule_conf: print(f'hosts not in {host_rule_name}, please check.') continue if current_ip in host_rule_conf['hosts']: # 分析文件条目 # 分析input的 for direction in ['input', 'output']: if direction not in host_rule_conf: print(f'{direction} not in {host_rule_name}, please check.') else: for d in host_rule_conf[direction]: # print('direction', d) dports = None if 'dport' in d: dports = d['dport'] if 'peer' not in d: print(f'{direction} peer not in {host_rule_name}, please check.') continue else: for item in d['peer']: ip_type = item['type'] value = item['value'] # 生成iptables INPUT条目 # print(\"=============\") print(generate_iptables_entry(direction, ip_type, value, ipset_type_dict, dports), file=iptables_conf_tmp) # 步骤三：最后再将default的DROP规则写上。TODO # 步骤四：生成好ipset.conf与iptables两个文件，与生产环境的文件做对比， # 如有变则应用它，并将日志写到日志文件里。TODO ipset_conf_tmp.close() iptables_conf_tmp.close() if not filecmp.cmp(ipset_conf_tmp.name, 'ipset.conf'): # ipset.conf有更新，执行更新操作 pass if not filecmp.cmp(iptables_conf_tmp.name, 'iptables'): # iptables文件有更新，执行更新操作 pass" }, { "title": "Get permanent MAC Address", "url": "/posts/get-permanent-mac-on-linux/", "categories": "linux", "tags": "post", "date": "2022-08-23 21:52:00 +0000", "snippet": "如何查看永久Mac地址", "content": "如何查看永久Mac地址" }, { "title": "Obsidian Learning", "url": "/posts/Obsidian-learning/", "categories": "obsidian", "tags": "post", "date": "2022-08-20 12:00:00 +0000", "snippet": "Obsidian是什么? Obsidian is a powerful knowledge base that works on top of a local folder of plain text Markdown files.Obsidian的学习资源Johnny学OB （每个热爱学习的人，电脑上都应该装一个Obsidian）Obsidian 雙向鏈結型筆記工具研究與應用，打造屬於個...", "content": "Obsidian是什么? Obsidian is a powerful knowledge base that works on top of a local folder of plain text Markdown files.Obsidian的学习资源Johnny学OB （每个热爱学习的人，电脑上都应该装一个Obsidian）Obsidian 雙向鏈結型筆記工具研究與應用，打造屬於個人的專業知識圖譜系列" }, { "title": "为什么文件被vim、sed命令修改后，其inode也变了？", "url": "/posts/file-inode-chang/", "categories": "linux", "tags": "post", "date": "2022-08-18 16:00:00 +0000", "snippet": "问题为什么文件被vim、sed命令修改后，其inode也变了？思路inode变化了，那我们可以看下inode的变化情况。本文以vim为例子。分析 安装inotifywait工具 监控将要操作的文件的父目录 本例子，我要使用vim修改~/.bashrc的内容，因此我用以下命令监控~/目录 ubuntu@ip-172-31-85-138:~$ inotifywait -m...", "content": "问题为什么文件被vim、sed命令修改后，其inode也变了？思路inode变化了，那我们可以看下inode的变化情况。本文以vim为例子。分析 安装inotifywait工具 监控将要操作的文件的父目录 本例子，我要使用vim修改~/.bashrc的内容，因此我用以下命令监控~/目录 ubuntu@ip-172-31-85-138:~$ inotifywait -mr ~/ 在另外一个terminal里，运行vim修改~/.bashrc 查看步骤2的terminal的变化 /home/ubuntu/ MOVED_FROM .bashrc/home/ubuntu/ MOVED_TO .bashrc~/home/ubuntu/ CREATE .bashrc/home/ubuntu/ OPEN .bashrc/home/ubuntu/ MODIFY .bashrc/home/ubuntu/ MODIFY .bashrc/home/ubuntu/ ATTRIB .bashrc/home/ubuntu/ CLOSE_WRITE,CLOSE .bashrc/home/ubuntu/ ATTRIB .bashrc/home/ubuntu/ MODIFY .bashrc.swp/home/ubuntu/ DELETE .bashrc~/home/ubuntu/ CLOSE_WRITE,CLOSE .bashrc.swp/home/ubuntu/ DELETE .bashrc.swp^C 从监控可以看到，vim修改文件时，原文件会被重命名为.bashrc~，创建一个新的.bashrc进行修改。修改完毕后.bashrc~还会被删掉。由此可见，.bashrc文件已经不是当初那个文件了，而是新建的文件。怪不得inode号都改变了。延伸sed也是类似的原理，编辑时会生成一个中间文件，操作完毕后会将中间文件rename成被操作的那个文件名" }, { "title": "How to modify the environment of a running process in a desktop or server environment", "url": "/posts/modify-the-env-of-a-running-process/", "categories": "icenv", "tags": "process", "date": "2021-01-17 00:00:00 +0000", "snippet": "在实际操作中，如果一个进程的环境变量配置错误，尤其是在没有像 shell 这样的界面供你直接修改时，你可以利用 GDB 来动态修复进程的环境。这里是一个模拟案例，展示如何使用 GDB 修改一个正在运行的进程的 PATH 环境变量。场景设定假设我们有一个名为 myapp 的程序，它的启动脚本如下：#!/bin/bash# 启动应用程序并显示其当前的 PATH 环境变量echo \"Current...", "content": "在实际操作中，如果一个进程的环境变量配置错误，尤其是在没有像 shell 这样的界面供你直接修改时，你可以利用 GDB 来动态修复进程的环境。这里是一个模拟案例，展示如何使用 GDB 修改一个正在运行的进程的 PATH 环境变量。场景设定假设我们有一个名为 myapp 的程序，它的启动脚本如下：#!/bin/bash# 启动应用程序并显示其当前的 PATH 环境变量echo \"Current PATH: $PATH\"./myapp假设 myapp 在执行时遇到环境问题，例如，它的 PATH 没有包含某些必要的目录，导致它无法找到需要的执行文件。为了解决这个问题，我们将使用 GDB 来修改 myapp 进程的环境。步骤 1: 启动程序首先，通过脚本启动 myapp：$ ./start_myapp.shCurrent PATH: /usr/bin:/bin此时，myapp 进程启动，并打印了当前的 PATH 环境变量，但你发现它没有包含某些目录，可能导致后续的程序调用失败。步骤 2: 查找 myapp 进程的 PID打开一个新的终端，使用 ps 或 top 命令找到正在运行的 myapp 进程的 PID。例如：$ ps aux | grep myappuser 12345 0.5 0.1 123456 2345 ? S 12:34 0:01 ./myapp假设 myapp 进程的 PID 是 12345。步骤 3: 使用 GDB 附加到 myapp 进程接下来，我们使用 GDB 附加到正在运行的进程上，修改它的环境变量。首先，启动 GDB：$ gdb -p 12345这会将 GDB 附加到 myapp 进程。GDB 启动后，会显示类似下面的提示：Attaching to process 12345Reading symbols from /path/to/myapp...done.步骤 4: 修改 PATH 环境变量现在，我们可以使用 GDB 的 set 命令来修改进程的环境变量。在 GDB 提示符下，输入以下命令：(gdb) set environment PATH=/usr/bin:/bin:/custom/bin:/opt/bin这将修改 myapp 进程的 PATH 环境变量，加入了一个新的路径 /custom/bin 和 /opt/bin。步骤 5: 继续执行进程修改了环境变量后，我们需要让 myapp 进程继续执行。输入以下命令：(gdb) continue这将使进程继续运行，同时新的环境变量设置生效。步骤 6: 验证修改是否生效返回到启动 myapp 的终端，查看新的 PATH 变量是否生效。你可以在 myapp 程序内打印新的 PATH 变量，或者直接在 myapp 的输出中验证：$ ./start_myapp.shCurrent PATH: /usr/bin:/bin:/custom/bin:/opt/bin如上所示，PATH 环境变量已经成功更新，包含了 /custom/bin 和 /opt/bin。总结通过 GDB，我们成功地修改了正在运行的 myapp 进程的环境变量，修复了环境配置错误的问题。这种方法适用于没有直接界面的进程，尤其是对于在系统中运行的长时间进程。" }, { "title": "为一个90后，关于年轻工程师如何加深对技术的理解，获得更快的个人成长，你有什么建议吗？", "url": "/posts/how-young-engineers-can-deepen-technical-understanding/", "categories": "life", "tags": "", "date": "2019-02-02 00:00:00 +0000", "snippet": "为一个90后，关于年轻工程师如何加深对技术的理解，获得更快的个人成长，你有什么建议吗？这里想对年轻的工程师提一些个人建议。 第一，一定要多读代码。尤其是语言的标准库代码，知名的开源项目代码，或者其它超高使用频率的代码，提高自己的代码品味。 第二，一定要多写代码。尤其是写可读性高、可维护性好的代码，尽量寻找有经验的工程师帮助自己 Review 代码，提高自己的代码能力和质量。 第三，一定...", "content": "为一个90后，关于年轻工程师如何加深对技术的理解，获得更快的个人成长，你有什么建议吗？这里想对年轻的工程师提一些个人建议。 第一，一定要多读代码。尤其是语言的标准库代码，知名的开源项目代码，或者其它超高使用频率的代码，提高自己的代码品味。 第二，一定要多写代码。尤其是写可读性高、可维护性好的代码，尽量寻找有经验的工程师帮助自己 Review 代码，提高自己的代码能力和质量。 第三，一定要多看、多想，看经典的系统设计，思考自己项目的架构和演进路线，找到志同道合的朋友一起探讨和研究，提高自己的设计、架构能力。 最后，一定要多学，学习前沿的技术，为未来做好技术储备；学习领域内的顶会的论文，能够对未来有所预判；学习一些领域外的知识，比如市场、经济等，更多的了解通用事物的发展规律。每个人都有最适合自己的成长路线，对于年轻工程师来讲，最重要的还是能够专注在自己热爱的领域上，以最大的热情投入每天的工作，每天都能进步一点点。" }, { "title": "墨菲定律（设计系统）和康威定律（系统划分）", "url": "/posts/murphy-s-law/", "categories": "life", "tags": "", "date": "2019-01-15 00:00:00 +0000", "snippet": "在设计系统时，多考虑墨菲定律：任何事情都没有表面看起来那么简单；所有的事情都会比你预计的时间长；可能出错的事总会出错；如果你担心某种情况发生，那么他就更有可能发生。在划分系统时，应该多考虑康威定律：系统架构是公司组织架构的反应；应该按照业务闭环进行系统拆分/组织架构划分，实现闭环/高内聚/低耦合，减少沟通成本；如果沟通出现问题，那么应该考虑进行系统和组织架构的调整；在合适的时机进行系统拆分，...", "content": "在设计系统时，多考虑墨菲定律：任何事情都没有表面看起来那么简单；所有的事情都会比你预计的时间长；可能出错的事总会出错；如果你担心某种情况发生，那么他就更有可能发生。在划分系统时，应该多考虑康威定律：系统架构是公司组织架构的反应；应该按照业务闭环进行系统拆分/组织架构划分，实现闭环/高内聚/低耦合，减少沟通成本；如果沟通出现问题，那么应该考虑进行系统和组织架构的调整；在合适的时机进行系统拆分，不要一开始就把系统/服务拆的非常细，虽然闭环，但是每个人维护的系统非常多，成本高。摘抄自csdn的《墨菲定律（设计系统）和康威定律（系统划分）》" }, { "title": "多和资深的同仁交流，就会发现惊人的效率提升", "url": "/posts/efficiency-boost-through-experienced-collaboration/", "categories": "icenv", "tags": "efficiency", "date": "2019-01-12 00:00:00 +0000", "snippet": "这次《Zabbix架构分享&amp;Promethues架构初探》培训交流会，我想做一次总结。早在一个月前，老大就请我去调研Zabbix在大型IT架构中的使用，以及初探Promethues监控系统，并对两大监控系统做较详细的对比。我觉得前两者在本次会议中，基本上覆盖到了。第一点：Zabbix在大型IT结构中普遍会应用上Proxy，Agent将监控数据推送到Proxy，然后由Proxy将数据推...", "content": "这次《Zabbix架构分享&amp;Promethues架构初探》培训交流会，我想做一次总结。早在一个月前，老大就请我去调研Zabbix在大型IT架构中的使用，以及初探Promethues监控系统，并对两大监控系统做较详细的对比。我觉得前两者在本次会议中，基本上覆盖到了。第一点：Zabbix在大型IT结构中普遍会应用上Proxy，Agent将监控数据推送到Proxy，然后由Proxy将数据推送到Zabbix Server中。另一张图：第二点：Prometheus is a Cloud Native Computing Foundation member project. 下图是它的架构。让我最震撼的是它的数据获取自由性很高：支持使用别人制作好的Exporters，支持自己编写Exporter，或者使用SpringBoot埋点，还支持Short-lived jobs将metrics push到PushGateway上去。架构这么灵活，难怪能成为“CNCF第二名毕业生”。非常适合后续云化业务的监控。第三点仅以“Zabbix适用于物理机的监控，而Prometheus适用于云等微服务架构；Zabbix将监控数据存储在关系型数据库中，而Prometheus将监控数据存放在了时序性数据库”潦草介绍了下。呼应题目：前两周，断断续续有花过3天左右的时间准备这个PPT和会议。使用docker搭建了Zabbix，Prometheus，Grafana来熟悉这些系统。但是没有搞清楚Prometheus是怎么去定义需要监控的指标项，可怕的是自己也没有想到要去了解这个。培训前和老大预热的时候，老大问的特仔细。问到是怎么配置监控策略的时候，我竟一脸茫然，连相关的资料看到没看过。吓得我赶紧抱佛脚。接着就了解到了有很多人针对不同的场景写好了很丰富的Exporters，如果自己的业务场景并在外面的世界不常见，找不到对应的Exporter的话，也可以使用Go、Python或Java来自行编写自己的Exporter。也可以在Java项目中埋点取指标值，如网站登录人数等。没有交谈前，我没方向去了解，两眼一抹黑。所以所获知识甚少。若我有架构意识，也应该能想到要去查阅各个组件的协作及用法。交谈后，就发现了自己准备的不足。加以查阅，理解，然后组织了一次较为流利的培训交流会。" }, { "title": "Cadence Virtuoso 与主流 EDA 工具集成 101", "url": "/posts/virtuoso-tool-integration-101/", "categories": "icenv", "tags": "analog", "date": "2016-12-31 16:00:00 +0000", "snippet": "在集成电路设计流程中，Cadence Virtuoso 是广泛使用的模拟/混合信号设计平台。为了提升设计效率，常需将其与其他 EDA 工具（如 Calibre、Cliosoft、Empyrean 等）集成。本文将介绍如何通过配置 .cdsinit 文件，实现这些工具的无缝集成。1. 基础配置：编辑 .cdsinit 文件.cdsinit 是 Cadence Virtuoso 启动时加载的初始...", "content": "在集成电路设计流程中，Cadence Virtuoso 是广泛使用的模拟/混合信号设计平台。为了提升设计效率，常需将其与其他 EDA 工具（如 Calibre、Cliosoft、Empyrean 等）集成。本文将介绍如何通过配置 .cdsinit 文件，实现这些工具的无缝集成。1. 基础配置：编辑 .cdsinit 文件.cdsinit 是 Cadence Virtuoso 启动时加载的初始化文件，位于用户主目录下。通过编辑该文件，可加载所需的工具接口脚本，实现工具集成。([National Bureau of Statistics of China][1])vim ~/.cdsinit2. 集成 Siemens/Mentor CalibreCalibre 是业界领先的物理验证工具。集成命令如下：; 检查 CALIBRE_HOME 环境变量cal_home = getShellEnvVar(\"CALIBRE_HOME\")if (cal_home == nil then printf(\"// CALIBRE_HOME 未设置，尝试使用 MGC_HOME\\n\") cal_home = getShellEnvVar(\"MGC_HOME\"))if (cal_home != nil &amp;&amp; isDir(cal_home) &amp;&amp; isReadable(cal_home) then setSkillPath(append1(getSkillPath() strcat(cal_home \"/lib\"))) ; 加载适用于 Cadence 4.4 及以上版本的接口脚本。如果需要集成 Cadence 4.3 或者以下的，则请使用含 4.3 关键字的 skill 脚本。 load(\"calibre.skl\")else printf(\"// Calibre 错误：环境变量 CALIBRE_HOME 设置不正确。\\n\") hiDisplayAppDBox( ?name 'MGCHOMEErrorDlg ?dboxBanner \"Calibre 错误\" ?dboxText \"Calibre Skill 接口未加载。\" ?dialogType hicErrorDialog ?dialogStyle 'modal ?buttonLayout 'Close ))3. 集成 Keysight/Cliosoft SOSCliosoft SOS 是常用的设计数据管理工具。集成命令如下：let (clioDir) clioDir = getShellEnvVar(\"CLIOSOFT_DIR\") load(strcat(clioDir \"/scripts/cds_sosviadfII.il\")))4. 集成 Empyrean Alps 模拟器Empyrean Alps 是高性能模拟电路仿真工具。集成命令如下：alps_home = getShellEnvVar(\"ALPS_HOME\")spectre_path_for_alps_integration = nthelem(1 artSystemWithRead(\"which spectre\"))if (alps_home then path = getShellEnvVar(\"PATH\") path = strcat(strcat(alps_home \"/interface/cds:\") path) setShellEnvVar(strcat(\"PATH=\" path)) loadi(strcat(alps_home \"/interface/cds/alps_method3.ile\") \"empyrean\") println(\"完成 Alps 脚本加载\")else msg = \"未设置 ALPS_HOME，请先设置。\" hiDisplayUserDBox( ?name 'Error ?dboxBanner \"错误\" ?dialogStyle 'modal ?dboxText msg ?buttons list(\"OK\") ))5. 集成 Empyrean IwaveIwave 是 Empyrean 提供的波形查看工具。集成命令如下：load(strcat(getShellEnvVar(\"IWAVE_HOME\") \"/interface/cds/iwave.ile\"))6. 集成 Empyrean Aeolus（可选）Aeolus 是 Empyrean 的另一款仿真工具。集成命令如下（根据需要启用）：aeolus_home = getShellEnvVar(\"AEOLUS_HOME\")if (aeolus_home then path = getShellEnvVar(\"PATH\") path = strcat(strcat(aeolus_home \"/interface/cds:\") path) setShellEnvVar(strcat(\"PATH=\" path)) loadi(strcat(aeolus_home \"/interface/cds/aeolus_spectre.il\"))else msg = \"未设置 AEOLUS_HOME，请先设置。\" hiDisplayUserDBox( ?name 'Error ?dboxBanner \"错误\" ?dialogStyle 'modal ?dboxText msg ?buttons list(\"OK\") ))7. 常见问题与建议 环境变量设置：确保相关工具的环境变量（如 CALIBRE_HOME、CLIOSOFT_DIR 等）已正确设置，并指向有效路径。 文件权限：验证 .cdsinit 文件及加载的脚本文件具有适当的读取权限。 调试信息：利用 printf 等函数输出调试信息，有助于定位问题。8. 结语通过上述配置，您可以在 Cadence Virtuoso 环境中集成多种主流 EDA 工具，提升设计效率和协同能力。建议在版本控制系统中管理 .cdsinit 文件的修改，确保团队协作的一致性。如需进一步的帮助或有特定工具的集成需求，欢迎联系。" }, { "title": "Github Bookmarklet Quickly Generate New Post Link", "url": "/posts/github-bookmarklet-quickly-generate-new-post-link/", "categories": "blog", "tags": "jekyll, github", "date": "2015-04-02 16:00:00 +0000", "snippet": "🚀 在浏览器中快速生成 GitHub 新博客文章链接（使用 Bookmarklet）🎯 背景在使用 GitHub Pages 构建 Jekyll 博客时，每次创建新博客文章都需要手动填写 filename 和 front matter。为了简化这个步骤，我们可以通过 Bookmarklet（书签链接）来自动生成这些内容，快速跳转到 GitHub 创建博客文章页面。通过这种方式，我们不仅提高了...", "content": "🚀 在浏览器中快速生成 GitHub 新博客文章链接（使用 Bookmarklet）🎯 背景在使用 GitHub Pages 构建 Jekyll 博客时，每次创建新博客文章都需要手动填写 filename 和 front matter。为了简化这个步骤，我们可以通过 Bookmarklet（书签链接）来自动生成这些内容，快速跳转到 GitHub 创建博客文章页面。通过这种方式，我们不仅提高了博客发布的效率，还能让这一过程更加简单和快捷。今天我将向大家介绍如何通过 浏览器书签 自动生成并跳转到 GitHub 创建新文章页面的链接。💡 方案概述我使用 Bookmarklet（书签链接），通过在浏览器中点击一个书签链接来生成一个新的 GitHub 页面链接，并且该链接会自动填充： 文件名：自动生成文件名（例如：2015-04-03-my-title.md） 内容：自动填充 Jekyll 标准的 front matter 和模板内容点击生成的链接后，GitHub 将自动为你打开一个新建博客页面，省去了很多繁琐的步骤。🛠️ 步骤一：创建 Bookmarklet 书签1. 打开浏览器的书签栏 在浏览器中，确保书签栏已经打开。如果没有打开，可以按下 Ctrl + Shift + B 来显示书签栏。2. 创建新的书签 右键点击书签栏，选择 添加书签 或者 新建书签。 在弹出的对话框中，填写书签的名称（例如：一键创建新博客），然后在 URL 部分粘贴以下 JavaScript 代码：javascript:(function(){ const date = new Date().toISOString().slice(0, 10); const file = `${date}-my-title.md`; const content = `---\\nlayout: post\\ntitle: \"在此输入标题\"\\ndate: ${date} 00:00:00 +0800\\ncategories: [博客]\\ntags: [jekyll, github]\\n---\\n\\n写点什么吧...`; const url = `https://github.com/icinfra/icinfra-source/new/main/_posts?filename=${encodeURIComponent(file)}&amp;value=${encodeURIComponent(content)}`; window.open(url, '_blank');})();3. 保存书签 点击 保存 按钮，书签就会出现在书签栏中。📝 步骤二：使用 Bookmarklet 生成 GitHub 新博客链接1. 打开书签 访问 GitHub Pages 项目的 _posts 页面创建新文章。 在书签栏中点击刚才创建的书签（例如：一键创建新博客）。2. 自动生成并打开链接 点击书签后，浏览器会自动生成包含文件名和内容的 GitHub 新建页面链接，并在新标签页中打开该链接。3. 修改标题（可选） GitHub 新建页面会自动填充文件名和模板内容，你只需修改文章标题和正文内容。⚡ 提升效率的小窍门📚 自定义文件名和模板内容如果你希望在每次使用时能快速更改文件名或模板内容，可以在 Bookmarklet 代码中进行适当修改，例如：const content = `---layout: posttitle: \"自定义标题\"date: ${date} 00:00:00 +0800categories: [自定义分类]tags: [自定义标签]---`;const filename = `${date}-your-custom-title.md`;🚀 快速发布每次点击书签后，GitHub 会直接跳转到新建文章页面，减少了你重复输入文件名和 front matter 的时间。让博客发布变得更加轻松高效。🌟 总结通过 Bookmarklet（书签链接），我们可以轻松在浏览器中创建 Jekyll 博客文章，并自动填充所需的文件名和模板内容。只需一次配置，今后每次发布博客都能节省大量时间。希望这个小工具能够帮助你提高工作效率。如果你有任何问题，或者希望进一步优化该工具，欢迎在评论区留言讨论！希望这篇指导对你发布博客有帮助！你可以将其直接作为文章发布到你的博客中，帮助更多的读者提高效率！🚀" } ]
